<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>分布式 on 疯子爱淡定</title>
    <link>http://heketong.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/</link>
    <description>Recent content in 分布式 on 疯子爱淡定</description>
    <image>
      <title>疯子爱淡定</title>
      <url>http://heketong.github.io/images/papermod-cover.png</url>
      <link>http://heketong.github.io/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- 0.127.0</generator>
    <language>en</language>
    <lastBuildDate>Wed, 13 May 2020 22:45:46 +0800</lastBuildDate>
    <atom:link href="http://heketong.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>分布式</title>
      <link>http://heketong.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F/</link>
      <pubDate>Wed, 13 May 2020 22:45:46 +0800</pubDate>
      <guid>http://heketong.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F/</guid>
      <description>一些概念回顾 缓存穿透 概念： 缓存没有数据，而且数据库也没有数据。
​	当这种情况大量出现或被恶意攻击时，接口的访问全部透过Redis访问数据库，而数据库中也没有这些数据，我们称这种现象为&amp;quot;缓存穿透&amp;quot;。缓存穿透会穿透Redis的保护，提升底层数据库的负载压力，同时这类穿透查询没有数据返回也造成了网络和计算资源的浪费。
一般解决方案 如果Redis内不存在该数据，则通过布隆过滤器判断数据是否在底层数据库内； 如果布隆过滤器告诉我们该key在底层库内不存在，则直接返回null给客户端即可，避免了查询底层数据库的动作； 如果布隆过滤器告诉我们该key极有可能在底层数据库内存在，那么将查询下推到底层数据库即可 布隆过滤器有误判率，虽然不能完全避免数据穿透的现象，但已经可以将绝大部份的的穿透查询给屏蔽在Redis层了，极大的降低了底层数据库的压力，减少了资源浪费。 缓冲击穿 概念 一般是指缓存没有但是数据库有的数据。 比如热点数据失效，导致大量合法热点请求打向数据库，此时数据库压力山大 一般解决方案： 延长热点key的过期时间或者设置永不过期，如排行榜，首页等一定会有高并发的接口； 利用互斥锁保证同一时刻只有一个客户端可以查询底层数据库的这个数据，一旦查到数据就缓存至Redis内，避免其他大量请求同时穿过Redis访问底层数据库。 缓存雪崩 概念 缓存雪崩时缓存击穿的加强版，大量的key几乎同时过期，然后大量并发查询穿过redis击打到底层数据库上，此时数据库层的负载压力会骤增，我们称这种现象为&amp;quot;缓存雪崩&amp;quot;。
一般解决方案 缓存预热 ​	缓存预热如字面意思，当系统上线时，缓存内还没有数据，如果直接提供给用户使用，每个请求都会穿过缓存去访问底层数据库，
如果并发大的话，很有可能在上线当天就会宕机，因此我们需要在上线前先将数据库内的热点数据缓存至Redis内再提供出去使用，
这种操作就成为&amp;quot;缓存预热&amp;quot;。缓存预热的实现方式有很多，比较通用的方式是写个批任务，在启动项目时或定时去触发将底层数据库内的热点数据加载到缓存内。
缓存更新 ​	缓存服务（Redis）和数据服务（底层数据库）是相互独立且异构的系统，在更新缓存或更新数据的时候无法做到原子性的同时更新两边的数据，因此在并发读写或第二步操作异常时会遇到各种数据不一致的问题。如何解决并发场景下更新操作的双写一致是缓存系统的一个重要知识点。
第二步操作异常：缓存和数据的操作顺序中，第二个动作报错。如数据库被更新， 此时失效缓存的时候出错，缓存内数据仍是旧版本； 缓存更新的设计模式有四种：
Cache aside：查询：先查缓存，缓存没有就查数据库，然后加载至缓存内；更新：先更新数据库，然后让缓存失效；或者先失效缓存然后更新数据库；
Read through：在查询操作中更新缓存，即当缓存失效时，Cache Aside 模式是由调用方负责把数据加载入缓存，而 Read Through 则用缓存服务自己来加载；
Write through：在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后由缓存自己更新数据库；
Write behind caching：俗称write back，在更新数据的时候，只更新缓存，不更新数据库，缓存会异步地定时批量更新数据库；
Cache aside：
为了避免在并发场景下，多个请求同时更新同一个缓存导致脏数据，因此不能直接更新缓存而是另缓存失效。
先更新数据库后失效缓存：并发场景下，推荐使用延迟失效（写请求完成后给缓存设置1s过期时间），在读请求缓存数据时若redis内已有该数据（其他写请求还未结束）则不更新。当redis内没有该数据的时候（其他写请求已另该缓存失效），读请求才会更新redis内的数据。这里的读请求缓存数据可以加上失效时间，以防第二步操作异常导致的不一致情况。
先失效缓存后更新数据库：并发场景下，推荐使用延迟失效（写请求开始前给缓存设置1s过期时间），在写请求失效缓存时设置一个1s延迟时间，然后再去更新数据库的数据，此时其他读请求仍然可以读到缓存内的数据，当数据库端更新完成后，缓存内的数据已失效，之后的读请求会将数据库端最新的数据加载至缓存内保证缓存和数据库端数据一致性；在这种方案下，第二步操作异常不会引起数据不一致，例如设置了缓存1s后失效，然后在更新数据库时报错，即使缓存失效，之后的读请求仍然会把更新前的数据重新加载到缓存内。
推荐使用先失效缓存，后更新数据库，配合延迟失效来更新缓存的模式； 四种缓存更新模式的优缺点：
Cache Aside：实现起来较简单，但需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）； Read/Write Through：只需要维护一个数据存储（缓存），但是实现起来要复杂一些； Write Behind Caching：与Read/Write Through 类似，区别是Write Behind Caching的数据持久化操作是异步的，但是Read/Write Through 更新模式的数据持久化操作是同步的。优点是直接操作内存速度快，多次操作可以合并持久化到数据库。缺点是数据可能会丢失，例如系统断电等。 缓存本身就是通过牺牲强一致性来提高性能，因此使用缓存提升性能，就会有数据更新的延迟性。这就需要我们在评估需求和设计阶段根据实际场景去做权衡了。 缓存降级 ​	缓存降级是指当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，即使是有损部分其他服务，仍然需要保证主服务可用。可以将其他次要服务的数据进行缓存降级，从而提升主服务的稳定性。</description>
    </item>
  </channel>
</rss>
