{"categories":[{"title":"marathons","uri":"http://heketong.github.io/categories/marathons/"},{"title":"sport","uri":"http://heketong.github.io/categories/sport/"},{"title":"技术总结","uri":"http://heketong.github.io/categories/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/"}],"posts":[{"content":" 100-Marathons 1 广州花都半马赛事 2019.2.24 ​ 【广州花都摇滚马组委会】祝贺贺 克通 完成2019广州花都摇滚马拉松半程马拉松项目，参赛号：C11949，枪声成绩：02:17:13，净成绩：02:13:56。此成绩仅供参考，最终成绩以组委会发布成绩证书上为准\n2 清远半马赛事 2019 3.17 ​ 【中体体育】祝贺贺克通完成2019时代中国清远马拉松赛 ，项目：半程马拉松，参赛号：C0085 ，枪声成绩：02:13:22 ，净成绩：02:05:10。此成绩仅供参考，解释权归组委会。\n3 韶关全马赛事 2019.11.24 ​ 第一次全马，竟然没收到短信，😓\n4 阳江海陵岛全马赛事 2019.12.29 ​ 【露营之家】恭喜您完成了十八子作·2019阳江海陵岛环岛国际马拉松赛“全程马拉松”，参赛号A0791，枪声成绩05:03:26，净成绩05:03:07。最终解释权归组委会所有。\n疫情影响取消清远全马赛事 2020.3.22 ​ 【清远马拉松】尊敬的贺克通，恭喜您中签2020时代中国清远马拉松，中签结果同步更新在微信公众号第一赛道，请及时关注。感谢您对清马的关注和支持，谢谢！2020.1.13 15:30，2020年太多事情发生，疫情影响，清远赛事取消，昨天看到消息，说癌症患者贺明发现自己病情后，想跑满100场马拉松，看后非常感动，是啊，每个不曾起舞的日子，都是对生命的辜负，癌症患者尚坚持跑了61场马拉松，自己又有什么不能的呢，当然这件事情也让我觉得更要珍惜自己的生命，不要等到事情真到了无可挽回的时候再决定找寻自己的健康，而应该在现在，此时此刻开始，运动起来，享受自己的人生。\n​ 戒烟这个事情反反复复说了太多遍，到现在还是没能如愿以偿，那就从此时此刻开始继续加油吧\n","id":0,"section":"posts","summary":"100-Marathons 1 广州花都半马赛事 2019.2.24 ​ 【广州花都摇滚马组委会】祝贺贺 克通 完成2019广州花都摇滚马拉松半程马拉松项目，参赛号：C11949，枪声成绩：02","tags":["marathons"],"title":"100场马拉松","uri":"http://heketong.github.io/2020/06/marathons/","year":"2020"},{"content":" 搭建hugo静态博客记录 1 安装Hugo 我这里是imac所以就直接用brew 其它操作系统也很简单 百度一下一把\nbrew install hugo  2 初始化站点目录 先cd到你想放置的磁盘目录 然后执行一下命令即可 会在当前目录创建站点名称同名目录\n$ hugo new site blog Congratulations! Your new Hugo site is created in /Users/ketonghe/blog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \u0026quot;hugo new theme \u0026lt;THEMENAME\u0026gt;\u0026quot; command. 2. Perhaps you want to add some content. You can add single files with \u0026quot;hugo new \u0026lt;SECTIONNAME\u0026gt;/\u0026lt;FILENAME\u0026gt;.\u0026lt;FORMAT\u0026gt;\u0026quot;. 3. Start the built-in live server via \u0026quot;hugo server\u0026quot;. Visit https://gohugo.io/ for quickstart guide and full documentation.  3 安装主题并修改 现在hugo主题商店挺多，我选择了相对干净的hugo-theme-pure 如果没有git环境 可自行百度安装\n$ git clone https://github.com/xiaoheiAh/hugo-theme-pure themes/pure Cloning into 'themes/pure'... remote: Enumerating objects: 13, done. remote: Counting objects: 100% (13/13), done. remote: Compressing objects: 100% (11/11), done. remote: Total 2527 (delta 2), reused 6 (delta 2), pack-reused 2514 Receiving objects: 100% (2527/2527), 4.14 MiB | 519.00 KiB/s, done. Resolving deltas: 100% (1376/1376), done.  config.yml 配置文件主要修改项\nbaseURL 主页 menu 可以将下面的title改为对应的中文 donate 改为自己的微信和支付宝 profile 修改自己头像和介绍  4 写markdown文章 $ hugo new posts/helloworld.md /Users/ketonghe/blog/content/posts/helloworld.md created  用markdown编辑器编辑文章\n5 发布预览 $ hugo server -D | ZH +------------------+----+ Pages | 13 Paginator pages | 0 Non-page files | 0 Static files | 9 Processed images | 0 Aliases | 6 Sitemaps | 1 Cleaned | 0 Total in 91 ms Watching for changes in /Users/ketonghe/blog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /Users/ketonghe/blog/config.yml Environment: \u0026quot;development\u0026quot; Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop  接下来就可以在本地浏览器 输入http://localhost:1313/ 访问了\n这个主题支持站内搜索 还不错\n6 添加评论支持 参考 https://www.smslit.top/2018/07/08/hugo-valine/ 一步步来吧\n7 生成静态页面 ","id":1,"section":"posts","summary":"搭建hugo静态博客记录 1 安装Hugo 我这里是imac所以就直接用brew 其它操作系统也很简单 百度一下一把 brew install hugo 2 初始化站点目录 先cd到你想","tags":["搭建博客"],"title":"create_hugo_blog","uri":"http://heketong.github.io/2020/05/create_hugo_blog/","year":"2020"},{"content":" 相关历史及分成模型 历史介绍  1969年 美国担心敌人会摧毁自己的网络，所以国防部高级研究计划局（Advanced Research Projects Agency，ARPA）下决心要建立一个高可用的网络，即使部分线路或者交换机的故障不会导致整个网络的瘫痪，于是有了后来的ARPANET（Advanced Research Project Agency Network）\u0026mdash;最早只是一个简单的分组交换网 经过不断发展，原始的ARPANET慢慢变成了多个网络互联，逐步促成了互联网的出现。 1983年TCP/IP 协议成为 ARPANET 上的标准协议，现在互联网世界这么繁荣都得意与TCP/IP协议，当然任何一个行业越是繁荣昌盛，就越是有良好的协议标准，接口标准，TCP/IP就是网际互联中最流行的协议标准，也正是因为其流行，互联网才能越发发达。  分层模型  一般都会提到7层 4层 或者 5层，下面给出一张图做个简单对比  ​ 左边是ISO/OSI的7层模型，分的更细，一般我们常说的右边的4层，咱们从上到下分层说\n应用层 Application Layer 应用层的本质是规定了应用程序之间如何相互传递报文，处理特定的应用程序细节\n我们常说的FTP、HTTP、SMTP、NFS、SNMP、Telnet都是应用层的协议，就拿HTTP来说：\n 规定了报文的类型 是请求报文还是应答报文 每段报文具体什么语法 有多少段，怎么才算结束(\\r\\n) 进程应该以什么样的顺序发送或者接收报文 \u0026hellip;\u0026hellip;\u0026hellip;.  大部分应用层协议都有RFC文档定义(Request for Comments，缩写：RFC,由互联网工程任务组（IETF）发布的一系列备忘录。文件收集了有关互联网相关信息，以及UNIX和互联网社群的软件文件，以编号排定。目前RFC文件是由互联网协会（ISOC）赞助发行)\n传输层 Transport Layer 主要为两台主机上的应用程序提供端到端的通信。在TCP/IP协议族中，有两个互不相同的传输协议：TCP（传输控制协议）和UDP（用户数据报协议）。\nTCP为两台主机提供高可靠性的数据通信。它所做的工作包括把应用程序交给它的数据分成合适的小块交给下面的网络层，确认接收到的分组，设置发送最后确认分组的超时时钟等。\n由于传输层TCP提供了高可靠性的端到端的通信，因此应用层可以忽略所有这些细节。为了提供可靠的服务，TCP采用了超时重传、发送和接收端到端的确认分组等机制。\nUDP则为应用层提供一种非常简单的服务。它只是把称作数据报的分组从一台主机发送到另一台主机，但并不保证该数据报能到达另一端。一个数据报是指从发送方传输到接收方的一个信息单元（例如，发送方指定的一定字节数的信息）。UDP协议任何必需的可靠性必须由应用层来提供。\n 端口  这里必须提下端口的概念，主要为了区分一台主机上不同的应用程序，比如80端口一般就是http应用的端口，21一般是ftp应用的端口，知道了端口就知道数据包到时候要送给哪个应用程序   网络层/网际层/网络互联层 Internet Layer 网络互连层提供了主机到主机的通信，将传输层产生的的数据包封装成分组数据包发送到目标主机，并提供路由选择的能力。\n处理分组在网络中的活动，例如分组的选路。\n在TCP/IP协议族中，网络层协议包括IP协议（网际协议），\nICMP协议（Internet互联网控制报文协议），\nIGMP协议（Internet组管理协议）。\nIP是一种网络层协议，提供的是一种不可靠的服务，它只是尽可能快地把分组从源结点送到目的结点，但是并不提供任何可靠性保证。同时被TCP和UDP使用。TCP和UDP的每组数据都通过端系统和每个中间路由器中的IP层在互联网中进行传输。\nICMP是IP协议的附属协议。IP层用它来与其他主机或路由器交换错误报文和其他重要信息。\nIGMP是Internet组管理协议。它用来把一个UDP数据报多播到多个主机。\n链路层/网络接口层/网络访问层 Network Access Layer 也就是上图右边的网络接口层和硬件层，通常包括操作系统中的设备驱动程序和计算机中对应的网络接口卡。它们一起处理与电缆（或其他任何传输媒介）的物理接口细节。ARP（地址解析协议）和RARP（逆地址解析协议）是某些网络接口（如以太网和令牌环网）使用的特殊协议，用来转换IP层和网络接口层使用的地址。\n以太网、Wifi、蓝牙工作在这一层，网络访问层提供了主机连接到物理网络需要的硬件和相关的协议\n为什么要分层 分层的本质是通过分离关注点而让复杂问题简单化，通过分层可以做到：\n 各层独立：限制了依赖关系的范围，各层之间使用标准化的接口，各层不需要知道上下层是如何工作的，增加或者修改一个应用层协议不会影响传输层协议 灵活性更好：比如路由器不需要应用层和传输层，分层以后路由器就可以只用加载更少的几个协议层 易于测试和维护：提高了可测试性，可以独立的测试特定层，某一层有了更好的实现可以整体替换掉 能促进标准化：每一层职责清楚，方便进行标准化  抓个包瞄一瞄  这里抓一个http报文看看 直接后台 curl http://www.baidu.com 用到工具 Wireshark  wireshark设置只抓百度服务器的报文 后台运行curl $ curl http://www.baidu.com \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;!--STATUS OK--\u0026gt;\u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;meta http-equiv=content-type content=text/html;charset=utf-8\u0026gt;\u0026lt;meta http-equiv=X-UA-Compatible content=IE=Edge\u0026gt;\u0026lt;meta content=always name=referrer\u0026gt;\u0026lt;link rel=stylesheet type=text/css href=http://s1.bdstatic.com/r/www/cache/bdorz/baidu.min.css\u0026gt;\u0026lt;title\u0026gt;百度一下，你就知道\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body link=#0000cc\u0026gt; \u0026lt;div id=wrapper\u0026gt; \u0026lt;div id=head\u0026gt; \u0026lt;div class=head_wrapper\u0026gt; \u0026lt;div class=s_form\u0026gt; \u0026lt;div class=s_form_wrapper\u0026gt; \u0026lt;div id=lg\u0026gt; \u0026lt;img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;form id=form name=f action=//www.baidu.com/s class=fm\u0026gt; \u0026lt;input type=hidden name=bdorz_come value=1\u0026gt; \u0026lt;input type=hidden name=ie value=utf-8\u0026gt; \u0026lt;input type=hidden name=f value=8\u0026gt; \u0026lt;input type=hidden name=rsv_bp value=1\u0026gt; \u0026lt;input type=hidden name=rsv_idx value=1\u0026gt; \u0026lt;input type=hidden name=tn value=baidu\u0026gt;\u0026lt;span class=\u0026quot;bg s_ipt_wr\u0026quot;\u0026gt;\u0026lt;input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;bg s_btn_wr\u0026quot;\u0026gt;\u0026lt;input type=submit id=su value=百度一下 class=\u0026quot;bg s_btn\u0026quot;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div id=u1\u0026gt; \u0026lt;a href=http://news.baidu.com name=tj_trnews class=mnav\u0026gt;新闻\u0026lt;/a\u0026gt; \u0026lt;a href=http://www.hao123.com name=tj_trhao123 class=mnav\u0026gt;hao123\u0026lt;/a\u0026gt; \u0026lt;a href=http://map.baidu.com name=tj_trmap class=mnav\u0026gt;地图\u0026lt;/a\u0026gt; \u0026lt;a href=http://v.baidu.com name=tj_trvideo class=mnav\u0026gt;视频\u0026lt;/a\u0026gt; \u0026lt;a href=http://tieba.baidu.com name=tj_trtieba class=mnav\u0026gt;贴吧\u0026lt;/a\u0026gt; \u0026lt;noscript\u0026gt; \u0026lt;a href=http://www.baidu.com/bdorz/login.gif?login\u0026amp;amp;tpl=mn\u0026amp;amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb\u0026gt;登录\u0026lt;/a\u0026gt; \u0026lt;/noscript\u0026gt; \u0026lt;script\u0026gt;document.write('\u0026lt;a href=\u0026quot;http://www.baidu.com/bdorz/login.gif?login\u0026amp;tpl=mn\u0026amp;u='+ encodeURIComponent(window.location.href+ (window.location.search === \u0026quot;\u0026quot; ? \u0026quot;?\u0026quot; : \u0026quot;\u0026amp;\u0026quot;)+ \u0026quot;bdorz_come=1\u0026quot;)+ '\u0026quot; name=\u0026quot;tj_login\u0026quot; class=\u0026quot;lb\u0026quot;\u0026gt;登录\u0026lt;/a\u0026gt;');\u0026lt;/script\u0026gt; \u0026lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style=\u0026quot;display: block;\u0026quot;\u0026gt;更多产品\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div id=ftCon\u0026gt; \u0026lt;div id=ftConw\u0026gt; \u0026lt;p id=lh\u0026gt; \u0026lt;a href=http://home.baidu.com\u0026gt;关于百度\u0026lt;/a\u0026gt; \u0026lt;a href=http://ir.baidu.com\u0026gt;About Baidu\u0026lt;/a\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p id=cp\u0026gt;\u0026amp;copy;2017\u0026amp;nbsp;Baidu\u0026amp;nbsp;\u0026lt;a href=http://www.baidu.com/duty/\u0026gt;使用百度前必读\u0026lt;/a\u0026gt;\u0026amp;nbsp; \u0026lt;a href=http://jianyi.baidu.com/ class=cp-feedback\u0026gt;意见反馈\u0026lt;/a\u0026gt;\u0026amp;nbsp;京ICP证030173号\u0026amp;nbsp; \u0026lt;img src=//www.baidu.com/img/gs.gif\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  观察Wireshark抓包情况 我们针对编号4的http请求报文 点击下面的详细简单看看\nhttp应用层  起始行（start line），起始行根据是请求报文还是响应报文分为「请求行」和「响应行」。这个例子中起始行是GET / HTTP/1.1，表示这是一个 GET 请求，请求的 URL 为/，协议版本为HTTP 1.1，起始行最后会有一个空行CRLF（\\r\\n)与下面的首部分隔开 首部（header），首部采用形如key:value的方式，比如常见的User-Agent、ETag、Content-Length都属于 HTTP 首部，每个首部直接也是用空行分隔 可选的实体（entity），实体是 HTTP 真正要传输的内容，比如下载一个图片文件，传输的一段 HTML等  传输层 传输层两端的端口 代表两端的程序\n网际互联 TCP概述 面向连接  面向连接的协议要求正式发送数据之前需要通过3次「握手」建立一个逻辑连接，结束通信时也是通过有序的四次挥手来断开连接  可靠的 IP 是一种无连接、不可靠的协议：它尽最大可能将数据报从发送者传输给接收者，但并不保证包到达的顺序会与它们被传输的顺序一致，也不保证包是否重复，甚至都不保证包是否会达到接收者。\nTCP 要想在 IP 基础上构建可靠的传输层协议，必须有一个复杂的机制来保障可靠性。 主要有下面几个方面：\n 对每个包提供校验和  每个 TCP 包首部中都有两字节用来表示校验和，防止在传输过程中有损坏。如果收到一个校验和有差错的报文，TCP 不会发送任何确认直接丢弃它，等待发送端重传  包的序列号解决了接收数据的乱序、重复问题  接收端会根据序列号排序 去重  超时重传  TCP 发送数据后会启动一个定时器，等待对端确认收到这个数据包。如果在指定的时间内没有收到 ACK 确认，就会重传数据包，然后等待更长时间，如果还没有收到就再重传，在多次重传仍然失败以后，TCP 会放弃这个包。  流量控制、拥塞控制  待补充   面向字节流的协议  流的含义就是没有边界，所以应用要自己界定边界\n 假设你调用 2 次 write 函数往 socket 里依次写 500 字节、800 字节。write 函数只是把字节拷贝到内核缓冲区，最终会以多少条报文发送出去是不确定的，如下图所示：\n   简单解释：\n 情况 1：分为两条报文依次发出去 500 字节 和 800 字节数据 情况 2：两部分数据合并为一个长度为 1300 字节的报文，一次发送 情况 3：第一部分的 500 字节与第二部分的 500 字节合并为一个长度为 1000 字节的报文，第二部分剩下的 300 字节单独作为一个报文发送 情况 4：第一部分的 400 字节单独发送，剩下100字节与第二部分的 800 字节合并为一个 900 字节的包一起发送。 情况 N：还有更多可能的拆分组合    上面出现的情况取决于诸多因素：路径最大传输单元 MTU、发送窗口大小、拥塞窗口大小等。\n当接收方从 TCP 套接字读数据时，它是没法得知对方每次写入的字节是多少的。接收端可能分2 次每次 650 字节读取，也有可能先分三次，一次 100 字节，一次 200 字节，一次 1000 字节进行读取\n全双工的协议  在 TCP 中发送端和接收端可以是客户端/服务端，也可以是服务器/客户端，通信的双方在任意时刻既可以是接收数据也可以是发送数据，每个方向的数据流都独立管理序列号、滑动窗口大小、MSS 等信息  概述总图： ​ Tcp头部 示意图 源端口号、目标端口号 用wireshare抓包 点击tcp报文 就会出现源端口号( Src Port)和目标端口号(Dst Port), TCP报文是没有ip地址的，ip地址要去IP报文查看，示意图如下：\n TCP连接4元组 源IP、源端口、目标IP、目标端口。一个4元组可以唯一标示一个tcp连接  序列号 Seq Tcp是面向字节流的协议，通过tcp协议传输的字节流都为其分配了序列号，序列号指的是本报文第一个字节的序列号\n序列号+报文长度就可以确定传输的是哪一段数据\n 在SYN报文中 序列号用于交换彼此的初始序列号，在其它报文中，序列号用于保证包的顺序 因为IP层不保证包的顺序，所以这个保证主要是tcp层靠序列号保证的，如果发送方发送的是四个报文序列号分别是1、2、3、4，但到达接收方的顺序是 2、4、3、1，接收方就可以通过序列号的大小顺序组装出原始的数据  连接三次握手 初始化序列号(Initial Sequence Number) ​ 在建立连接之初，通信双方都会各自选择一个序列号，称之为初始序列号。在建立连接时，通信双方通过 SYN 报文交换彼此的 ISN，如下图所示。\n服务端的2、3两步一般合并发送，所以就变成了下面的三次握手过程\n确认号 Ack Ack的含义是告知对方 小于此Ack号的所有字节都已经收到，期望对方下次开始从Ack字节开始发送报文吧。\n关于确认号有几个注意点：\n 不是所有的包都需要确认的 不是收到了数据包就立马需要确认的，可以延迟一会再确认 ACK 包本身不需要被确认，否则就会无穷无尽死循环了 确认号永远是表示小于此确认号的字节都已经收到  校验和 checksum 每个 TCP 包首部中都有两字节用来表示校验和，防止在传输过程中有损坏。如果收到一个校验和有差错的报文，TCP 不会发送任何确认直接丢弃它，等待发送端重传。\nTCP Flags  我们通常所说的 SYN、ACK、FIN、RST 其实只是把 flags 对应的 bit 位置为 1 而已，这些标记可以组合使用，比如 SYN+ACK，FIN+ACK 等  最常见的有下面这几个：\n SYN（Synchronize）：用于发起连接数据包同步双方的初始序列号\n ACK（Acknowledge）：确认数据包\n RST（Reset）：这个标记用来强制断开连接，通常是之前建立的连接已经不在了、包不合法、或者实在无能为力处理\n FIN（Finish）：通知对方我发完了所有数据，准备断开连接，后面我不会再发数据包给你了。\n PSH（Push）：告知对方这些数据包收到以后应该马上交给上层应用，不能缓存起来\n  窗口大小 windows size 可以看到用于表示窗口大小的\u0026rdquo;Window Size\u0026rdquo; 只有 16 位，可能 TCP 协议设计者们认为 16 位的窗口大小已经够用了，也就是最大窗口大小是 65535 字节（64KB）。就像网传盖茨曾经说过：“640K内存对于任何人来说都足够了”一样。\n自己挖的坑当然要自己填，因此TCP 协议引入了「TCP 窗口缩放」选项 作为窗口缩放的比例因子，比例因子值的范围是 0 ~ 14，其中最小值 0 表示不缩放，最大值 14。比例因子可以将窗口扩大到原来的 2 的 n 次方，比如窗口大小缩放前为 1050，缩放因子为 7，则真正的窗口大小为 1050 * 128 = 134400，如下图所示\nwireshark可以抓包看到窗口大小。\n值得注意的是，窗口缩放值在三次握手的时候指定，如果抓包的时候没有抓到 SYN 包，wireshark 是不知道真正的窗口缩放值是多少的\n可选项、填充  格式: 种类(Kind) 1byte,长度(Length)1 byte,值(value) 常用的可选项：\n MSS：最大段大小选项，是 TCP 允许的从对方接收的最大报文段 SACK：选择确认选项 Window Scale：窗口缩放选项  MSS抓包示意图\n  MTU、MSS MTU(Maximum Transmission Unit) 最大传输单元  MTU是在数据链路层限制的，数据链路层按照帧传输，每一帧因为协议限制也有大小限制，所以IP层不能把一个太大的包直接塞给链路层，这个限制叫做MTU。  以太网帧格式  除去14字节头和4字节CRC校验 有效数据荷载范围为 46\u0026mdash;\u0026gt;1500,这个就是以太网的MTU 假设以太网MTU为1500 传输100Kb数据，至少需要(100*1024\u0026frasl;1500)=69帧 不同的数据链路层对应的MTU是不同的，可以通过netstat -i查看对应网卡的mtu，普通以太网一般是1500  IP分段  IP头格式   IPv4数据报最大大小为65535字节，远远大于以太网的MTU，有些网络还会开启巨帧模式(Jumbo Frame)，可以得到9000字节。所以当一个IP数据报大于MTU时，IP层就会把报文切割为多个小的片段(小于MTU)，从而使得这些报文能够在数据链路层传输。  ​ 一个大包\u0026mdash;\u0026ndash;\u0026gt;拆成多个小包 放入数据链路层\n 上面图片有个分片偏移量，就是用来表示该分段在原始数据报文中的位置，如果用wireshark抓报要乘以8.  抓包看下IP分段  ping -s 3000 www.baidu.com  man ping可以看到ping -s命令会增加8个字节的ICMP都，所以其实是发送3008字节\n wireshark抓包截图   第一个包  ​ ​ 这个包是 IP 分段包的第一个分片，More fragments: Set表示这个包是 IP 分段包的一部分，还有其它的分片包，Fragment offset: 0表示分片偏移量为 0，IP 包的 payload 的大小为 1480，加上 20 字节的头部正好是 1500.\n 第2个包\n  同样More fragments处于 set 状态，表示后面还有其它分片，Fragment offset: 185这里并不是表示分片偏移量为 185，wireshark 这里显示的时候除以了 8，真实的分片偏移量为 185 * 8 = 1480\n 第3个包  可以看到More fragments处于 Not set 状态，表示这是最后一个分片了。Fragment offset: 370表示偏移量为 370 * 8 = 2960，包的大小为 68 - 20（IP 头部大小） = 48\n 3个包简单汇总示意   有一种攻击就是IP fragment attack，一直传More fragments = 1的包，导致接收方一直缓存分片，从而可能导致接收方内存耗尽。  路径MTU  一个包从发送端到最后的接收端要经过各种各样的网络，每个网络的MTU都可能不一样，所以整个通道上最小的MTU就称为路径MTU(Path MTU)  Tcp最大段大小 MSS(Max Segment Size)  tcp为了避免被分片，会主动将数据分割成小段后，然后再交给网络层，最大的分段大小称为MSS。\n MSS=MTU-sizeof(ip header)-sizeof(tcp header)\n 以太网中TCP的MSS=1500-20(ip header)-20(tcp header)=1460\n  socket选项 TCP_MAXSEG TCP 有一个 socket 选项 TCP_MAXSEG，可以用来设置此次连接的 MSS，如果设置了这个选项，则 MSS 不能超过这个值\n\tint tcp_maxseg = mss; socklen_t tcp_maxseg_len = sizeof(tcp_maxseg); // 设置 TCP_MAXSEG 选项 if ((err = setsockopt(server_fd, IPPROTO_TCP, TCP_MAXSEG, \u0026amp;tcp_maxseg, tcp_maxseg_len)) \u0026lt; 0) { error_quit(\u0026quot;set TCP_MAXSEG failed, code: %d\\n\u0026quot;, err); }  端口Port  端口主要用来区别一个主机上的各个应用程序，一台主机最大允许65536个端口号 分层结构中 每一层都有一个唯一标示 tcp是端口，ip层是ip地址，链路层为mac地址  熟知端口号(well-known port) ​ 知端口号由专门的机构由 IANA 分配和控制，范围为 0~1023。为了能让客户端能随时找到自己，服务端程序的端口必须要是固定的。很多熟知端口号已经被用就分配给了特定的应用，比如 HTTP 使用 80端口，HTTPS 使用 443 端口，ssh 使用 22 端口。 访问百度http://www.baidu.com/，其实就是向百度服务器之一（163.177.151.110）的 80 端口发起请求.\n​ 在linux上如果要监听这些端口 需要Root权限，熟知端口又是也被称为保留端口\n已登机的端口(registered port) ​ 已登记的端口不受 IANA 控制，不过由 IANA 登记并提供它们的使用情况清单。它的范围为 1024～49151。\n为什么是 49151 这样一个魔数？ 其实是取的端口号最大值 65536 的 3\u0026frasl;4 减 1 （49151 = 65536 * 0.75 - 1）。可以看到已登记的端口占用了大约 75% 端口号的范围。\n已登记的端口常见的端口号有：\n MySQL：3306 Redis：6379 MongoDB：27017  熟知和已登机端口可以在iana官网查到\n临时端口(ephemeral port) ​ 如果应用程序没有调用 bind() 函数将 socket 绑定到特定的端口上，那么 TCP 和 UDP 会为该 socket 分配一个唯一的临时端口。IANA 将 49152～65535 范围的端口称为临时端口（ephemeral port）或动态端口（dynamic port），也称为私有端口（private port），这些端口可供本地应用程序临时分配端口使用。\n不同的操作系统实现会选择不同的范围分配临时端口，在 Linux 上能分配的端口范围由 /proc/sys/net/ipv4/ip_local_port_range 变量决定，一般 Linux 内核端口范围为 32768~60999\ncat /proc/sys/net/ipv4/ip_local_port_range 32768 60999  在需要主动发起大量连接的服务器上（比如网络爬虫、正向代理）可以调整 ip_local_port_range 的值，允许更多的可用端口。\n 调用bind函数 但不指定端口 也会分配临时端口\n 调用connect函数也会分配临时端口\n 临时端口可能耗尽，届时会创建应用失败\n 修改临时端口范围\nketonghe@ubuntu:~$ sudo sysctl -w net.ipv4.ip_local_port_range=\u0026quot;50001 50001\u0026quot; net.ipv4.ip_local_port_range = 50001 50001  启动一个客户端连接\nketonghe@ubuntu:~$ netstat -anpl|grep 8787 (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) tcp 0 0 192.168.3.66:8787 0.0.0.0:* LISTEN 81014/./server tcp 0 0 192.168.3.66:8787 192.168.3.66:50001 ESTABLISHED 81014/./server tcp 0 0 192.168.3.66:50001 192.168.3.66:8787 ESTABLISHED 81016/./client  再启动一个客户端连接\nketonghe@ubuntu:~/code$ ./client connect error,procedure will exit: Cannot assign requested address 没有临时端口 报错 ------调用系统命令 strace 查看程序执行的系统调用 就会发现connect报错 EADDRNOTAVAIL strace ./client|grep connect .... socket(AF_INET, SOCK_STREAM, IPPROTO_IP) = 3 connect(3, {sa_family=AF_INET, sin_port=htons(8787), sin_addr=inet_addr(\u0026quot;192.168.3.66\u0026quot;)}, 16) = -1 EADDRNOTAVAIL (Cannot assign requested address) dup(2) = 4 fcntl(4, F_GETFL) = 0x2 (flags O_RDWR) fstat(4, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 4), ...}) = 0 write(4, \u0026quot;connect error,procedure will exi\u0026quot;..., 67connect error,procedure will exit: Cannot assign requested address ) = 67 close(4) = 0 exit_group(0) = ? +++ exited with 0 +++    端口相关命令  nc telnet 可以查看对应端口是否打开(是否有对应应用已经启动并占用这个端口)\ntelnet 10.211.55.12 6379 Trying 10.211.55.12... Connected to 10.211.55.12. Escape character is '^]'. ------------------- nc -v 10.211.55.12 6379 Ncat: Connected to 10.211.55.12:6379 telnet 10.211.55.12 6380 Trying 10.211.55.12... telnet: connect to address 10.211.55.12: Connection refused nc -v 127.0.0.1 1234 nc: connectx to 127.0.0.1 port 1234 (tcp) failed: Connection refused  netstat lsof 查看端口被什么进程占用\nketonghe@ubuntu:~$ netstat -ltpn | grep 8787 (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) tcp 0 0 192.168.3.66:8787 0.0.0.0:* LISTEN 80550/./server ketonghe@ubuntu:~$ sudo lsof -n -P -i:8787 [sudo] password for ketonghe: COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME server 80550 ketonghe 3u IPv4 1098588 0t0 TCP 192.168.3.66:8787 (LISTEN) ---- 其中 -n 表示不将 IP 转换为 hostname，-P 表示不将 port number 转换为 service name，-i:port 表示端口号为 22 的进程  找到进程监听的端口号\n ps找到进程id\nketonghe@ubuntu:~$ sudo netstat -atpn | grep 80550 tcp 0 0 192.168.3.66:8787 0.0.0.0:* LISTEN 80550/./server ------------------------------------------------------------- sudo lsof -n -P -p 80550 不grep过滤 会显示占用的文件具柄 lsof: WARNING: can't stat() fuse.gvfsd-fuse file system /run/user/1000/gvfs Output information may be incomplete. COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME server 80550 ketonghe cwd DIR 8,1 4096 1184987 /home/ketonghe/code server 80550 ketonghe rtd DIR 8,1 4096 2 / server 80550 ketonghe txt REG 8,1 13792 1184981 /home/ketonghe/code/server server 80550 ketonghe mem REG 8,1 2030544 132349 /lib/x86_64-linux-gnu/libc-2.27.so server 80550 ketonghe mem REG 8,1 170960 132345 /lib/x86_64-linux-gnu/ld-2.27.so server 80550 ketonghe 0u CHR 136,0 0t0 3 /dev/pts/0 server 80550 ketonghe 1u CHR 136,0 0t0 3 /dev/pts/0 server 80550 ketonghe 2u CHR 136,0 0t0 3 /dev/pts/0 server 80550 ketonghe 3u IPv4 1098588 0t0 TCP 192.168.3.66:8787 (LISTEN) server 80550 ketonghe 4u a_inode 0,14 0 11406 [eventpoll] ketonghe@ubuntu:~$ sudo lsof -n -P -p 80550|grep TCP //只看TCP协议 lsof: WARNING: can't stat() fuse.gvfsd-fuse file system /run/user/1000/gvfs Output information may be incomplete. server 80550 ketonghe 3u IPv4 1098588 0t0 TCP 192.168.3.66:8787 (LISTEN) ------------------------------------------------------------- ketonghe@ubuntu:/proc/80550/fd$ l /proc/80550/fd total 0 lrwx------ 1 ketonghe ketonghe 64 Aug 3 21:54 4 -\u0026gt; 'anon_inode:[eventpoll]'//这个为epollfd lrwx------ 1 ketonghe ketonghe 64 Aug 3 21:54 3 -\u0026gt; 'socket:[1098588]'//监听fd 1098588为socket的inode lrwx------ 1 ketonghe ketonghe 64 Aug 3 21:54 2 -\u0026gt; /dev/pts/0 //stderr lrwx------ 1 ketonghe ketonghe 64 Aug 3 21:54 1 -\u0026gt; /dev/pts/0 //stdout lrwx------ 1 ketonghe ketonghe 64 Aug 3 21:54 0 -\u0026gt; /dev/pts/0 //stdin ketonghe@ubuntu:/proc/80550/fd$ cat /proc/net/tcp sl local_address rem_address st tx_queue rx_queue tr tm-\u0026gt;when retrnsmt uid timeout inode 0: 0100007F:A281 00000000:0000 0A 00000000:00000000 00:00000000 00000000 0 0 46378 1 0000000000000000 100 0 0 10 0 1: 4203A8C0:2253 00000000:0000 0A 00000000:00000000 00:00000000 00000000 1000 0 1098588 1 0000000000000000 100 0 0 10 0 2: 3500007F:0035 00000000:0000 0A 00000000:00000000 00:00000000 00000000 101 0 36001 1 0000000000000000 100 0 0 10 0 3: 00000000:0016 00000000:0000 0A 00000000:00000000 00:00000000 00000000 0 0 1097236 1 0000000000000000 100 0 0 10 0 4: 0100007F:0277 00000000:0000 0A 00000000:00000000 00:00000000 00000000 0 0 980905 1 0000000000000000 100 0 0 10 0 5: 4203A8C0:0016 0703A8C0:E447 01 00000000:00000000 02:0009FF18 00000000 0 0 1100461 4 0000000000000000 20 4 31 10 -1 ------可以看到inode为1098588的套接字 也可以看到本地地址 远端地址 st为0A 表示正在监听 为TCP_LISTEN状态    端口安全  redis无密码登录被黑  端口小结 三次握手 经典3次握手示意图  三次握手最重要的是交换彼此的ISN(初始化序列号)，初始序列号的计算要查看内核，可以先掌握变化规律\n 客户端c先发送SYN报文 tcpflags只有SYN置位 报文不携带数据，但也占用一个序列号，因为需要服务端确认Ack\n 凡消耗序列号的tcp报文段，一定要对方确认，如果对方不Ack，发送端则会一直重传到指定次数为止  服务端s收到客户端c的SYN后，将SYN和ACK两个flag都置位，SYN是告诉客户端自己的初始化序列号是多少，Ack为ISN\u0026copy;+1是为了告诉\u0026lt;Ack的报文都已经收到，下次再发请从Ack编号开始，这里的SYN也需要对方(客户端)确认 所以这里也消耗一个序列号\n 客户端c发送最后一个ACK，因为不需要对方再次确认 所以就不消耗序列号\n  初始化序列号(Initial Sequence Number) ​ ISN并不是从0开始的，wireshark可能默认显示的相对序列号，这个linux是有固定的算法，总是是动态的，主要是安全考虑。\n 如果知道了连接的ISN，比较容易构造一个RST包，将连接直接关闭。如果是动态的，比较难构造RST socket也支持 SO_REUSEADDR端口重用，如果ISN固定 收到一个包就不知道是老包重传的还是新的连接包，保证2个连接的ISN不会串包  三次握手状态变化 对于客户端而言：\n 初始的状态是处于 CLOSED 状态。CLOSED 并不是一个真实的状态，而是一个假想的起点和终点。 客户端调用 connect 以后会发送 SYN 同步报文给服务端，然后进入 SYN-SENT 阶段，客户端将保持这个阶段直到它收到了服务端的确认包。 如果在 SYN-SENT 状态收到了服务端的确认包，它将发送确认服务端 SYN 报文的 ACK 包，同时进入 ESTABLISHED 状态，表明自己已经准备好发送数据。  对于服务端而言：\n 初始状态同样是 CLOSED 状态 在执行 bind、listen 调用以后进入 LISTEN状态，等待客户端连接。 当收到客户端的 SYN 同步报文以后，会回复确认同时发送自己的 SYN 同步报文，这时服务端进入 SYN-RCVD 阶段等待客户端的确认。 当收到客户端的确认报文以后，进入ESTABLISHED 状态。这时双方可以互相发数据了  发送syn包 对方没有回复会怎么样  客户端会处于SYN-SENT状态一段时间，会尝试重发SYN包 多少次有开关\n ketonghe@ubuntu:~/code$ cat /proc/sys/net/ipv4/tcp_syn_retries 6 6次重试（65s = 1s+2s+4s+8s+16s+32s)以后放弃重试，connect 调用返回 -1，调用超时，如果是真实客户端  packetdrill 构造SYN_SENT 状态的连接\n```\n   ketonghe@ubuntu:~/packetdrill/pkt$ cat a.pkt // 新建一个 server socket +0 socket(\u0026hellip;, SOCK_STREAM, IPPROTO_TCP) = 3\n// 客户端 connect +0 connect(3, \u0026hellip;, \u0026hellip;) = -1\n\u0026mdash;\u0026mdash;\u0026ndash;执行发包 sudo /home/ketonghe/packetdrill/gtests/net/packetdrill/packetdrill a.pkt\n\u0026mdash;\u0026ndash;tcpdump抓包 ketonghe@ubuntu:~/code$ sudo tcpdump -i any port 8080 -nn -U -vvv -w test.pcap [sudo] password for ketonghe: tcpdump: listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes Got 7\u0026mdash;\u0026mdash;重发6次 然后超时\n6次重试（65s = 1s+2s+4s+8s+16s+32s)以后放弃重试，connect 调用返回 -1，调用超时\n ## TCP同时打开 ![](http://heketong.github.io/donate/tcp同时打开.png) 以其中一方为例，记为 A，另外一方记为 B - 最初的状态是`CLOSED` - A 发起主动打开，发送 `SYN` 给 B，然后进入`SYN-SENT`状态 - A 还在等待 B 回复的 `ACK` 的过程中，收到了 B 发过来的 `SYN`，what are you 弄啥咧，A 没有办法，只能硬着头皮回复`SYN+ACK`，随后进入`SYN-RCVD` - A 依旧死等 B 的 ACK - 好不容易等到了 B 的 ACK，对于 A 来说连接建立成功 # TCP自连接 - 假设一个客户端想要连接的端口是50001 - 客户端启动的时候系统临时端口只有50001 也就是自己连接自己 - 这个时候就会出现自连接现象。 ![](http://heketong.github.io/donate/tcp自连接.png) 1. 作为客户端发送SYN (最后发给了自己) 2. 作为服务端收到自己发送的SYN包 以为对方想连接 所以回复SYN+ACK(回复给了自己) 3. 自己收到自己发送的SYN和ACK 以为是对方回复的，认为握手成功，进入ESTABLISHED状态 ## 模拟自连接 ### 准备客户端程序  int cliSocket=socket(AF_INET,SOCK_STREAM,0); servaddr.sin_addr.s_addr = inet_addr(\u0026ldquo;192.168.3.66\u0026rdquo;); servaddr.sin_port = htons(50001); //连接服务器 if( 0 != connect(cliSocket,(struct sockaddr *)\u0026amp;servaddr,sizeof(servaddr))){ perror(\u0026ldquo;connect error,procedure will exit\u0026rdquo;); return 0; } char readBuffer[1024]; char writeBuffer[1024]=\u0026ldquo;hello srv,i\u0026rsquo;m from client!\u0026rdquo;; if( write(cliSocket,writeBuffer,strlen(writeBuffer) ) 0){ cout\u0026lt;\u0026lt;\u0026ldquo;srv: \u0026ldquo;\u0026lt;\u0026gt;writeBuffer; if( write(cliSocket,writeBuffer,strlen(writeBuffer) ) \u0026lt;0){ perror(\u0026ldquo;write error! procedure will exit!\u0026rdquo;); return 0; } memset(readBuffer,0,sizeof(readBuffer)); memset(writeBuffer,0,sizeof(writeBuffer)); } cout\u0026lt;\u0026lt;\u0026ldquo;srv is close,chat will exit\u0026rdquo;\u0026lt;\u0026lt;endl; close(cliSocket); return 0;\n ### 修改系统临时端口 只剩下50001  ketonghe@ubuntu:~/code$ sudo sysctl -w net.ipv4.ip_local_port_range=\u0026ldquo;50001 50001\u0026rdquo; net.ipv4.ip_local_port_range = 50001 50001 ketonghe@ubuntu:~/code$ netstat -anpl|grep 50001 \u0026mdash;检查没人占用 (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)\n ### 开启tcpdump抓包  sudo tcpdump -i any port 50001 -nn -U -vvv -w tcpSelfConn.pcap\n ### 查看netstat 发现自己连接上自己了  ketonghe@ubuntu:~/code$ netstat -anpl|grep 50001 (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) tcp 0 0 192.168.3.66:50001 192.168.3.66:50001 ESTABLISHED 86363/./client\n ### client程序运行输出  ketonghe@ubuntu:~/code$ ./client srv: hello srv,i\u0026rsquo;m from client! aaaaaaa srv: aaaaaaa ^C\n ### wireshark查看抓包 ![](http://heketong.github.io/donate/tcpSelfConn.png) ## 自连接可能发生的真实场景 - 你写的业务系统 B 会访问本机服务 A，服务 A 监听了 50001 端口 - 业务系统 B 的代码写的稍微比较健壮，增加了对服务 A 断开重连的逻辑 - 如果有一天服务 A 挂掉比较长时间没有启动，业务系统 B 开始不断 connect 重连 - 系统 B 经过一段时间的重试就会出现自连接的情况 - 这时服务 A 想启动监听 50001 端口就会出现地址被占用的异常，无法正常启动 ## 自连接的危害 - 自连接的进程占用了端口，导致真正需要监听端口的服务进程无法监听成功 - 自连接的进程看起来 connect 成功，实际上服务是不正常的，无法正常进行业务数据通信(自己发给自己的) ## 如何避免自然连接 - 让服务监听的端口与客户端随机分配的端口不可能相同即可 - 出现自连接的时候，主动关掉连接 判断是否是自连接的逻辑是判断源 IP 和目标 IP 是否相等，源端口号和目标端口号是否相等 如果都相等 直接close掉 # 断开四次挥手 ## 最常见的断开4次挥手 ![](http://heketong.github.io/donate/tcp断开最常见的4次挥手.png) 1. 客户端调用 `close` 方法，执行「主动关闭」，会发送一个 FIN 报文给服务端，从这以后客户端不能再发送数据给服务端了，客户端进入`FIN-WAIT-1`状态。FIN 报文其实就是将 FIN 标志位设置为 1,此时客户端需要等待服务端的ACK和FIN包，close发送的FIN包可以携带数据，也可以不携带，但都消耗序列号，因为需要对方确认。发送FIN后不能再发送数据，单可以接受服务端的数据。也就是半关闭状态(half--close) 2. 服务端收到客户端的FIN包，立马发送ACK给客户端，然后自己进入CLOSE_WAIT状态 3. 客户端收到服务端的ACK后 客户端进入FIN_WAIT2状态(等待服务端发送FIN) 这个时候还可以收数据。 4. 服务端确认没有数据发送了 就发送FIN包，然后进入LAST_ACK状态(最后等待客户端发送ACK)，这个时候服务端也不能再发送数据了 5. 客户端收到服务端的FIN，自己也发送ACK给服务端，然后客户端进入TIME_WAIT状态(等待2个MSL后进入CLOSED状态) 6. 服务端收到客户端最后的ACK 进入CLOSED状态 ## 4次挥手是否可以变成3次 - 如果服务端收到客户端的FIN包后 确认自己没有数据要发送 也是可以将服务端的ACK和FIN包一起发送的(延迟ACK的时候也可能出现这种情况) ## 客户端服务端同时关闭 ![](http://heketong.github.io/donate/tcp断开两端同时关闭.png) 以客户端为例 - 最初客户端和服务端都处于 ESTABLISHED 状态 - 客户端发送 `FIN` 包，等待对端对这个 FIN 包的 ACK，随后进入 `FIN-WAIT-1` 状态 - 处于`FIN-WAIT-1`状态的客户端还没有等到 ACK，收到了服务端发过来的 FIN 包 - 收到 FIN 包以后客户端会发送对这个 FIN 包的的确认 ACK 包，同时自己进入 `CLOSING` 状态 - 继续等自己 FIN 包的 ACK - 处于 `CLOSING` 状态的客户端终于等到了ACK，随后进入`TIME-WAIT` - 在`TIME-WAIT`状态持续 2*MSL，进入`CLOSED`状态 --------------------------------------------------------------------------------------------------------------------------------------- ​ 发送FIN包后进入FIN_WAIT1状态(等待对方发送发送ACK和FIN)，如果这个时候对方不发送ACK，先收到对方发送的FIN，就知道对方不会发送数据了 也就进入了CLOSING状态。 ​ 这个时候还要等待对方发送ACK，如果收到了ACK就进入TIME_WAIT状态(等待2个MSL进入CLSOSED状态) ​ 服务端也是一样的。 ​ A方发送FIN包之前，如果有收到对方B的FIN包则只有B会进入TIME_WAIT，否则会出现双方都TIME_WAIT状态 # TCP头部时间戳选项(TCP Timestamps Option，TSopt) TCP协议里面有选项(Options)、填充(Padding),其中TSopt也就是时间戳选项也是一个比较重要的选项 Timestamps 选项最初是在 RFC 1323 中引入的，这个 RFC 的标题是 \u0026quot;TCP Extensions for High Performance\u0026quot;，在这个 RFC 中同时提出的还有 Window Scale、PAWS 等机制 ## 组成部分说明 在 Wireshark 抓包中，常常会看到 TSval 和 TSecr 两个选项，值得注意的是第二个选项 TSecr 不是 secrets 的意思，而是 \u0026quot;TS Echo Reply\u0026quot; 的缩写，TSval 和 TSecr 是 TCP 选项时间戳的一部分。 TCP Timestamps Option 由四部分构成：类别（kind）、长度（Length）、发送方时间戳（TS value）、回显时间戳（TS Echo Reply）。时间戳选项类别（kind）的值等于 8，用来与其它类型的选项区分。长度（length）等于 10。两个时间戳相关的选项都是 4 字节 - 是否使用时间戳选项实在连接的SYN包时候确定的，当然需要双方都支持才行，只要有一方没有回复就都不再发送时间戳选项 - curl github.com抓包结果 ![](http://heketong.github.io/donate/github抓包结果.png) - 发送方发送数据时，将一个发送时间戳 1734581141 放在发送方时间戳`TSval`中 - 接收方收到数据包以后，将收到的时间戳 1734581141 原封不动的返回给发送方，放在`TSecr`字段中，同时把自己的时间戳 3303928779 放在`TSval`中 - 后面的包以此类推 - **TSVal就是发送的时间 TSecr是本次发送的包是回复的对方哪个时间点发送的报文** ## 解决问题 Timestamps 选项的提出初衷是为了解决两个问题： 1、两端往返时延测量（RTTM） ​ 因为知道了一个报文的发送时间和收到应答时间 就可以准确的确定中间经过的时间 2、序列号回绕（PAWS） 内核会为每个连接维护一个 ts_recent 值，记录最后一次通信的的 timestamps 值，如果收到的报文的时间戳小于ts_recent ，则会直接丢弃。 ### 时间戳选项也可能造成RST 三次握手中的第二步，如果服务端回复 SYN+ACK 包中的 TSecr 不等于握手第一步客户端发送 SYN 包中的 TSval，客户端在对 SYN+ACK 回复 RST。示例包如下所示： ![](http://heketong.github.io/donate/tcp时间戳选项导致RST.png) ​ # TCP11种状态变迁图 ## 11状态变迁图 ![](http://heketong.github.io/donate/tcp11种状态变迁图.png) # 半连接队列、全连接队列、backlog ## 基本概念解读 - 当服务端调用listen函数之后，tcp状态有CLOSE变为LISTEN，同时内核创建了2个队列 - 半连接队列(Incomplete connection queue) 又称SYN队列 - 全连接队列(Incomplete connection queue) 又称Accept队列 ![](http://heketong.github.io/donate/tcp半连接全连接队列.jpg) - 当客户端调用connect函数后 内核发送SYN包给服务端，服务端收到后会 回复ACK和自己的SYN，服务器的状态会由listen变为SYN_RCVD（SYN Received），此时会将这条连接信息放入 SYN半连接队列，存储的是“inbound SYN packets”，入境的SYN包 - 服务端回复SYN+ACK后等待客户端回复ACK，也会开启定时器，如果超时收不到客户端的ACK，就会重发SYN+ACK,重发次数为配置参数，tcp_synack_retries，一旦收到客户端的ACK，服务端就尝试将它加入全连接队列(Accept Queue)---除非队列满了 ## 半连接队列大小计算 与三个内容有关系 - 服务端调用listen函数传入的backlog - 系统变量net.ipv4.tcp_max_syn_backlog 默认128 - 系统变量 net.core.somaxconn 具体计算逻辑：  \t1. nr_table_entries= min(backlog、net.ipv4.tcp_max_syn_backlog、net.core.somaxconn) 取3者中最小值 赋值给nr_table_entries 2. nr_table_entries=max(nr_table_entries,8) //跟8比较取最大值 3. nr_table_entries + 1 向上取求最接近的最大 2 的指数次幂 nr_table_entries = roundup_pow_of_two(nr_table_entries + 1); 4. 通过 for 循环找不大于 nr_table_entries 最接近的 2 的对数值 结果为max_qlen_log for (lopt-\u0026gt;max_qlen_log = 3; (1 \u0026lt;\u0026lt; lopt-\u0026gt;max_qlen_log) \u0026lt; nr_table_entries; lopt-\u0026gt;max_qlen_log++); 5. 半连接队列大小为\t2^max_qlen_log\n 例子： ![](http://heketong.github.io/donate/tcp半连接队列计算例子.png) - **在系统参数不修改的情形，盲目调大 listen 的 backlog 对最终半连接队列的大小不会有影响。** - **在 listen 的 backlog 不变的情况下，盲目调大 somaxconn 和 max_syn_backlog 对最终半连接队列的大小不会有影响** ## 如果半连接队列满了会怎么办 当半连接队列溢出时，Server 收到了新的发起连接的 SYN： - 如果不开启 `net.ipv4.tcp_syncookies`：直接丢弃这个 SYN - 如果开启net.ipv4.tcp_syncookies - 如果全连接队列满了，并且 `qlen_young` 的值大于 1：丢弃这个 SYN - 否则，生成 syncookie 并返回 SYN/ACK 包 ## 全连接队列大小计算 - backlog 和 somaxconn 中的较小值 ## 关于ss命令  ss -lnt | grep :9090 State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 51 50 *:9090 :\n - 处于 LISTEN 状态的 socket，Recv-Q 对应 sk_ack_backlog，表示当前 socket 的完成三次握手等待用户进程 accept 的连接个数，Send-Q 对应 sk_max_ack_backlog，表示当前 socket 全连接队列能最大容纳的连接数 - 对于非 LISTEN 状态的 socket，Recv-Q 表示 receive queue 的字节大小，Send-Q 表示 send queue 的字节大小 ## backlog多大才合适 - 你如果的接口处理连接的速度要求非常高，或者在做压力测试，很有必要调高这个值 - 如果业务接口本身性能不好，accept 取走已建连的速度较慢，那么把 backlog 调的再大也没有用，只会增加连接失败的可能性 Nginx 和 Redis 默认的 backlog 值等于 511，Linux 默认的 backlog 为 128。 ## 全连接队列满了怎么办 默认情况下，全连接队列满以后，服务端会忽略客户端的 ACK，随后会重传`SYN+ACK`，也可以修改这种行为，这个值由`/proc/sys/net/ipv4/tcp_abort_on_overflow`决定。 - tcp_abort_on_overflow 为 0 表示三次握手最后一步全连接队列满以后 server 会丢掉 client 发过来的 ACK，服务端随后会进行重传 SYN+ACK。 - tcp_abort_on_overflow 为 1 表示全连接队列满以后服务端直接发送 RST 给客户端。 但是回给客户端 RST 包会带来另外一个问题，客户端不知道服务端响应的 RST 包到底是因为「该端口没有进程监听」，还是「该端口有进程监听，只是它的队列满了」 # SYN flood攻击 客户端大量伪造 IP 发送 SYN 包，服务端回复的 ACK+SYN 去到了一个「未知」的 IP 地址，势必会造成服务端大量的连接处于 SYN_RCVD 状态，而服务器的半连接队列大小也是有限的，如果半连接队列满，也会出现无法处理正常请求的情况。 ![](http://heketong.github.io/donate/SYN_Flood.jpg) ## 如何发现或者监控SYN Flood - 监控日常活跃连接数 如果大幅增加而且大量SYN_RECV状态的连接 可能就是有问题 ## 如何防范及应急 - net.ipv4.tcp_max_syn_backlog调大 同时listen时候的backlog也调大，目的是增大SYN半连接队列内存 - 减少服务端SYN+ACK重试次数 应急时候可以将/proc/sys/net/ipv4/tcp_synack_retries改为0 因为真正的客户端必经还以重发SYN。 - 开启tcp_syncookies ![](http://heketong.github.io/donate/tcp_syncookies.jpg) SYN Cookie 的原理是基于「无状态」的机制，服务端收到 SYN 包以后不马上分配为 `Inbound SYN`分配内存资源，而是根据这个 SYN 包计算出一个 Cookie 值，作为握手第二步的序列号回复 SYN+ACK，等对方回应 ACK 包时校验回复的 ACK 值是否合法，如果合法才三次握手成功，分配连接资源 - 如果发现攻击后能给确定非法ip 也可以直接iptable限制这些ip 效果非常明显 - 外围增加F5等负载均衡利器，只有真正连接上的请求才转发给服务器 # TCP Fast Open TFO TCP快速打开 ​ TFO 是在原来 TCP 协议上的扩展协议，它的主要原理就在发送第一个 SYN 包的时候就开始传数据了， 不过它要求当前客户端之前已经完成过「正常」的三次握手。快速打开分两个阶段：请求 Fast Open Cookie 和 真正开始 TCP Fast Open - TFO与非TFO的对比 ![](http://heketong.github.io/donate/TFO与非TFO的对比.jpg) - 优势就是后续的连接 tcp交互次数更少 效率更快 也可以有一定预防SYN Flood - 代码如果要使用 要调用sendto函数 同时设置MSG_FASTOPEN flag ## 小结 1. 客户端发送一个 SYN 包，头部包含 Fast Open 选项，且该选项的 Cookie 长度为 0 2. 服务端根据客户端 IP 生成 cookie，放在 SYN+ACK 包中一同发回客户端 3. 客户端收到 Cookie 以后缓存在自己的本地内存 4. 客户端再次访问服务端时，在 SYN 包携带数据，并在头部包含 上次缓存在本地的 TCP cookie 5. 如果服务端校验 Cookie 合法，则在客户端回复 ACK 前就可以直接发送数据。如果 Cookie 不合法则按照正常三次握手进行。 # Address already in use SO_REUSEADDR ## 背景 - 如果服务器退出或者崩溃导致服务器先close，那么服务端就会出现TIME_WAIT状态，需要等待2个MSL才能最终释放连接 如果这个时候立马启动服务器程序，就会出现address already in use的错误。 ![](http://heketong.github.io/donate/server_TIME_WAIT示意图.jpg) - 并不是服务端只有处于TimeWait才有用 处于Fin_WAIT2也是可以的 ## 为什么通常不会在客户端出现 因为客户端每次都是随机的临时端口，所以一般不会出现 # SO_REUSEPORT 多个进程监听同一个端口 ​ 默认情况下，一个 IP、端口组合只能被一个套接字绑定，Linux 内核从 3.9 版本开始引入一个新的 socket 选项 SO_REUSEPORT，又称为 port sharding，允许多个套接字监听同一个IP 和端口组合 ​ 充分发挥多核CPU的性能，多进程处理网络请求的方式可以有下面2个方式 - 主进程 + 多个 worker 子进程监听相同的端口 - 多进程 + REUSEPORT 第一种方最常用的一种模式，Nginx 默认就采用这种方式。主进程执行 bind()、listen() 初始化套接字，然后 fork 新的子进程。在这些子进程中，通过 accept/epoll_wait 同一个套接字来进行请求处理，但会带来惊群问题（thundering herd） ## 惊群问题 thundering herd ![](http://heketong.github.io/donate/惊群问题.png) ​ 明明只有一块骨头只够一条小狗吃，五只小狗却一起从睡眠中醒来争抢，对于没有抢到小狗来说，浪费了很多精力 - 计算机中的惊群问题指的是：多进程/多线程同时监听同一个套接字，当有网络事件发生时，所有等待的进程/线程同时被唤醒，但是只有其中一个进程/线程可以处理该网络事件，其它的进程/线程获取失败重新进入休眠 - 惊群问题带来的是 CPU 资源的浪费和锁竞争的开销。根据使用方式的不同，Linux 上的网络惊群问题分为 accept 惊群和 epoll 惊群两种，linux内核2.6 版本中引入了 WQ_FLAG_EXCLUSIVE 选项解决了 accept 调用的惊群问题(非epoll 多进程直接accept) ### epoll惊群 ​ epoll 典型的工作模式是父进程执行 bind、listen 以后 fork 出子进程，使用 epoll_wait 等待事件发生，模式如下图所示： ![](http://heketong.github.io/donate/epoll典型工作模式会accept惊群.png) ## 示例代码  int main(void) { // \u0026hellip; sock_fd = create_and_bind(\u0026ldquo;9090\u0026rdquo;); listen(sock_fd, SOMAXCONN);\nepoll_fd = epoll_create(1); event.data.fd = sock_fd; event.events = EPOLLIN; epoll_ctl(epoll_fd, EPOLL_CTL_ADD, sock_fd, \u0026amp;event); events = calloc(MAXEVENTS, sizeof(event)); for (int i = 0; i \u0026lt; 4; i++) { if (fork() == 0) { while (1) { int n = epoll_wait(epoll_fd, events, MAXEVENTS, -1); printf(\u0026ldquo;return from epoll_wait, pid is %d\\n\u0026rdquo;, getpid()); sleep(2); for (int j = 0; j \u0026lt; n; j++) { if ((events[i].events \u0026amp; EPOLLERR) || (events[i].events \u0026amp; EPOLLHUP) || (!(events[i].events \u0026amp; EPOLLIN))) { close(events[i].data.fd); continue; } else if (sock_fd == events[j].data.fd) { struct sockaddr sock_addr; socklen_t sock_len; int conn_fd; sock_len = sizeof(sock_addr); conn_fd = accept(sock_fd, \u0026amp;sock_addr, \u0026amp;sock_len); if (conn_fd == -1) { printf(\u0026ldquo;accept failed, pid is %d\\n\u0026rdquo;, getpid()); break; } printf(\u0026ldquo;accept success, pid is %d\\n\u0026rdquo;, getpid()); close(conn_fd); } } } } }\n - 查看进程打开具柄情况  ls -l /proc/24735/fd lrwx\u0026mdash;\u0026mdash;. 1 ya ya 64 Jan 28 06:20 0 -\u0026gt; /dev/pts/2 lrwx\u0026mdash;\u0026mdash;. 1 ya ya 64 Jan 28 06:20 1 -\u0026gt; /dev/pts/2 lrwx\u0026mdash;\u0026mdash;. 1 ya ya 64 Jan 28 00:10 2 -\u0026gt; /dev/pts/2 lrwx\u0026mdash;\u0026mdash;. 1 ya ya 64 Jan 28 06:20 3 -\u0026gt; \u0026lsquo;socket:[72919]\u0026rsquo; listen套接字 lrwx\u0026mdash;\u0026mdash;. 1 ya ya 64 Jan 28 06:20 4 -\u0026gt; \u0026lsquo;anon_inode:[eventpoll]\u0026rsquo; epollfd\n 为了表示打开文件，linux 内核维护了三种数据结构，分别是： - 内核为每个进程维护了一个其打开文件的「描述符表」（file descriptor table），我们熟知的 fd 为 0 的 stdin 就是属于文件描述符表。 - 内核为所有打开文件维护了一个系统级的「打开文件表」（open file table），这个打开文件表存储了当前文件的偏移量，状态信息和对 inode 的指针等信息，父子进程的 fd 可以指向同一个打开文件表项。 - 最后一个是文件系统的 inode 表（i-node table） 经过 for 循环的 fork，会生成 4 个子进程，这 4 个子进程会继承父进程的 fd。在这种情况下，对应的进程文件描述符表、打开文件表和 inode 表的关系如下图所示： ![](http://heketong.github.io/donate/epoll惊群原因分析具柄.png) 子进程的 epoll_wait 等待同一个底层的 open file table 项，当有事件发送时，会通知到所有的子进程 - 开启一个客户端连接  return from epoll_wait, pid is 25410 return from epoll_wait, pid is 25411 return from epoll_wait, pid is 25409 return from epoll_wait, pid is 25412 accept success, pid is 25410 accept failed, pid is 25411 accept failed, pid is 25409 accept failed, pid is 25412\n 可以看到当有新的网络事件发生时，阻塞在 epoll_wait 的多个进程同时被唤醒。在这种情况下，epoll 的惊群还是存在，有不少的措施可以解决 epoll 的惊群。Nginx 为了处理惊群问题，在应用层增加了 accept_mutex 锁 当然也可以使用**SO_REUSEPORT** 选项 ## SO_REUSEPORT 选项 - 如果不加一个选项 同一个server程序 只能启动一次，否则机会提示失败 - 但加了这个选项 可以多个进程监听同一个端口  int optval = 1; setsockopt(sock_fd, SOL_SOCKET, SO_REUSEPORT, \u0026amp;optval, sizeof(optval));\n - 启动2个服务器进程 查看端口情况  ketonghe@ubuntu:~/code$ ss -tlnpe | grep -i 8787 LISTEN 0 5 192.168.3.66:8787 0.0.0.0:* users:((\u0026ldquo;server\u0026rdquo;,pid=88296,fd=3)) uid:1000 ino:1215520 sk:34b \u0026lt;-\u0026gt;\nLISTEN 0 5 192.168.3.66:8787 0.0.0.0:* users:((\u0026ldquo;server\u0026rdquo;,pid=88294,fd=3)) uid:1000 ino:1215512 sk:34c \u0026lt;-\u0026gt;\nketonghe@ubuntu:~/code$ netstat -anp|grep 8787 (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) tcp 0 0 192.168.3.66:8787 0.0.0.0:* LISTEN 88296/./server\ntcp 0 0 192.168.3.66:8787 0.0.0.0:* LISTEN 88294/./server\n - ss命令介绍  -t, \u0026ndash;tcp 显示 TCP 的 socket -l, \u0026ndash;listening 只显示 listening 状态的 socket，默认情况下是不显示的。 -n, \u0026ndash;numeric 显示端口号而不是映射的服务名 -p, \u0026ndash;processes 显示进程名 -e, \u0026ndash;extended 显示 socket 的详细信息\n ### 客户端连接来了分给谁？ ​ linux4.5、4.6版本引入了SO_REUSEPORT group概念，在查找匹配的 socket 时，就不用遍历整条冲突链，对于设置了 SO_REUSEPORT 选项的 socket 经过二次哈希找到对应的 SO_REUSEPORT group 简单理解可以说是随机的。 ## SO_REUSEPORT与安全性 试想下面的场景，你的进程进程监听了某个端口，不怀好意的其他人也可以监听相同的端口来“窃取”流量信息，这种方式被称为端口劫持（port hijacking）。SO_REUSEPORT 在安全性方面的考虑主要是下面这两点。 1、只有第一个启动的进程启用了 SO_REUSEPORT 选项，后面启动的进程才可以绑定同一个端口。 2、后启动的进程必须与第一个进程的有效用户ID（effective user ID）匹配才可以绑定成功 ## SO_REUSEPORT 的应用 SO_REUSEPORT 带来了两个明显的好处： - 实现了内核级的负载均衡 - 支持滚动升级（Rolling updates） ![](http://heketong.github.io/donate/linux_SO_REUSEPORT滚动升级.png) 步骤如下所示。 1. 新启动一个新版本 v2 ，监听同一个端口，与 v1 旧版本一起处理请求。 2. 发送信号给 v1 版本的进程，让它不再接受新的请求 3. 等待一段时间，等 v1 版本的用户请求都已经处理完毕时，v1 版本的进程退出，留下 v2 版本继续服务 # SO_LINGER选项 ![](http://heketong.github.io/donate/SO_LINGER图解.png) # TimeWait状态 ## MSL Max Segment lifetime MSL（报文最大生存时间）是 TCP 报文在网络中的最大生存时间。这个值与 IP 报文头的 TTL 字段有密切的关系。 IP 报文头中有一个 8 位的存活时间字段（Time to live, TTL）如下图。 这个存活时间存储的不是具体的时间，而是一个 IP 报文最大可经过的路由数，每经过一个路由器，TTL 减 1，当 TTL 减到 0 时这个 IP 报文会被丢弃。 ![](http://heketong.github.io/donate/IP层TTL示意图.png) 从上面可以看到 TTL 说的是「跳数」限制而不是「时间」限制，尽管如此我们依然假设**最大跳数的报文在网络中存活的时间不可能超过 MSL 秒**。Linux 的套接字实现假设 MSL 为 30 秒，因此在 Linux 机器上 TIME_WAIT 状态将持续 60秒 ## 为什么要TIME_WAIT状态 ### 避免当前关闭连接与后续连接混淆（让旧连接的包在网络中消逝） ​ 数据报文可能在发送途中延迟但最终会到达，因此要等老的“迷路”的重复报文段在网络中过期失效，这样可以避免用**相同**源端口和目标端口创建新连接时收到旧连接姗姗来迟的数据包，造成数据错乱。 ![](http://heketong.github.io/donate/TIME_WAIT迷途包问题.png) 假设客户端 10.211.55.2 的 61594 端口与服务端 10.211.55.10 的 8080 端口一开始建立了一个 TCP 连接。 假如客户端发送完 FIN 包以后不等待直接进入 CLOSED 状态，老连接 SEQ=3 的包因为网络的延迟。过了一段时间**相同**的 IP 和端口号又新建了另一条连接，这样 TCP 连接的四元组就完全一样了。恰好 SEQ 因为回绕等原因也正好相同，那么 SEQ=3 的包就无法知道到底是旧连接的包还是新连接的包了，造成新连接数据的混乱。 TIME_WAIT 等待时间是 2 个 MSL，已经足够让一个方向上的包最多存活 MSL 秒就被丢弃，保证了在创建新的 TCP 连接以后，老连接姗姗来迟的包已经在网络中被丢弃消逝，不会干扰新的连接 ### 确保可靠实现TCP全双工终止连接 - 关闭连接的四次挥手中，最终的 ACK 由主动关闭方发出，如果这个 ACK 丢失，对端（被动关闭方）将重发 FIN，如果主动关闭方不维持 TIME_WAIT 直接进入 CLOSED 状态，则无法重传 ACK，被动关闭方因此不能及时可靠释放 ![](http://heketong.github.io/donate/TIME_WAIT确保全双工断开连接.png) - 如果上述情况没有TIME_WAIT等待 直接CLOSED ![](http://heketong.github.io/donate/NO_TIME_WAIT_异常情况.png) ​ 主动关闭方如果马上进入 `CLOSED` 状态，被动关闭方这个时候还处于`LAST-ACK`状态，主动关闭方认为连接已经释放， 端口可以重用了，如果使用相同的端口三次握手发送 SYN 包，会被处于 `LAST-ACK`状态状态的被动关闭方返回一个 `RST`，三次握手失败 #### 为什么要2个MSL - 1 个 MSL 确保四次挥手中主动关闭方最后的 ACK 报文最终能达到对端 - 1 个 MSL 确保对端没有收到 ACK 重传的 FIN 报文可以到达 2MS = 去向 ACK 消息最大存活时间（MSL) + 来向 FIN 消息的最大存活时间（MSL） ## TIME_WAIT的问题 在一个非常繁忙的服务器上，如果有大量 TIME_WAIT 状态的连接会怎么样呢？ - 连接表无法复用 - socket 结构体内存占用 **连接表无法复用** 因为处于 TIME_WAIT 的连接会存活 2MSL（60s），意味着相同的TCP 连接四元组（源端口、源 ip、目标端口、目标 ip）在一分钟之内都没有办法复用，通俗一点来讲就是“占着茅坑不拉屎”。 在一台 Linux 机器上，端口最多是 65535 个（ 2 个字节）。如果客户端与服务器通信全部使用短连接，不停的创建连接，接着关闭连接，客户端机器会造成大量的 TCP 连接进入 TIME_WAIT 状态，很有可能出现端口不够用的情况 ## 应对TIME_WAIT ### tcp_tw_reuse 选项 缓解紧张的端口资源，一个可行的方法是重用“浪费”的处于 TIME_WAIT 状态的连接，当开启 net.ipv4.tcp_tw_reuse 选项时，处于 TIME_WAIT 状态的连接可以被重用。下面把主动关闭方记为 A， 被动关闭方记为 B，它的原理是： - 如果主动关闭方 A 收到的包时间戳比当前存储的时间戳小，说明是一个迷路的旧连接的包，直接丢弃掉 - 如果因为 ACK 包丢失导致被动关闭方还处于`LAST-ACK`状态，并且会持续重传 FIN+ACK。这时 A 发送SYN 包想三次握手建立连接，此时 A 处于`SYN-SENT`阶段。当收到 B 的 FIN 包时会回以一个 RST 包给 B，B 这端的连接会进入 CLOSED 状态，A 因为没有收到 SYN 包的 ACK，会重传 SYN，后面就一切顺利了。 ![](http://heketong.github.io/donate/TIME_WAIT_tcp_tw_reuse.png) # RST创建的几种情况 - 在tcp协议中，RST表示复位，用来异常的关闭连接，发送 RST 关闭连接时，不必等缓冲区的数据都发送出去，直接丢弃缓冲区中的数据，连接释放进入`CLOSED`状态。而接收端收到 RST 段后，也不需要发送 ACK 确认。 ## 端口未监听 - 这种情况很常见，比如 web 服务进程断电挂掉或者未启动，客户端使用 connect 建连，都会出现 \u0026quot;Connection Reset\u0026quot; 或者\u0026quot;Connection refused\u0026quot; 错误 - 这样机制可以用来检测对端端口是否打开，发送 SYN 包对指定端口，看会不会回复 SYN+ACK 包。如果回复了 SYN+ACK，说明监听端口存在，如果返回 RST，说明端口未对外监听，如下图所示 - 如果调用了close函数，设置SO_LINGER为true 也会出现close后丢掉缓冲区 直接发送RST包 重置连接，立马进入CLOSED状态 ## 如果RST中途丢失了怎么办 - 如果另外一方没有收到RST会重试一定次数后 再次放弃。 ![](http://heketong.github.io/donate/RST_LOST.png) ## Broken Pipe和Connection reset by peer Broken pipe 与 Connection reset by peer 错误在网络编程中非常常见，出现的前提都是连接已关闭。 - Connection reset by peer 这个错误很好理解，就是对方已经关闭连接了 - Broken pipe出现时机是：在一个RST的套接字中继续写数据，因为连接已经关闭了，再写数据，内核就直接返回这个异常。 - 当一个进程向某个已收到 RST 的套接字执行写操作时，内核向该进程发送一个 SIGPIPE 信号。该信号的默认行为是终止进程，因此进程一般会捕获这个信号进行处理。不论该进程是捕获了该信号并从其信号处理函数返回，还是简单地忽略该信号，写操作都将返回 EPIPE 错误（也就Broken pipe 错误）,这也是 Broken pipe 只在写操作中出现的原因 # 重传相关： ## 重传示意 ![](http://heketong.github.io/donate/重传示意1.png) ## Ack延迟确认 ​ 如果发送 5000 个字节的数据包，因为 MSS 的限制每次传输 1000 个字节，分 5 段传输 1. 包1 (序列号1 长度1000) 2. 包2 (序列号1001 长度1000) 3. 包3 (序列号2001 长度1000) 4. 包4 (序列号3001 长度1000) 5. 包2 (序列号4001 长度1000) 数据包 1 发送的数据正常到达接收端，接收端回复 ACK 1001，表示 seq 为1001之前的数据包都已经收到，下次从1001开始发。 数据包 2因为某些原因未能到达服务端，其他包(3,4,5)正常到达，这时接收端也不能 ack 3 4 5 数据包，因为数据包 2 还没收到，接收端只能回复 ack 1001 第 2 个数据包重传成功以后服务器会回复5001，表示seq 为 5001 之前的数据包都已经收到了,这就是Ack延迟确认 简单示意图如下： ![](http://heketong.github.io/donate/ACK延迟确认.png) ## 快速重传机制和SACK ​ 网络协议设计者们想到了一种方法：**「快速重传」** 快速重传的含义是：当发送端收到 3 个或以上重复 ACK，就意识到之前发的包可能丢了，于是马上进行重传，不用傻傻的等到超时再重传 ​ 这就引入了另外一个问题，发送 3、4、5 包收到的全部是 ACK=1001，快速重传解决了一个问题: 需要重传。因为除了 2 号包，3、4、5 包也有可能丢失，那到底是只重传数据包 2 还是重传 2、3、4、5 所有包呢？ - 收到 3 号包的时候在 ACK 包中告诉发送端：喂，小老弟，我目前收到的最大连续的包序号是 **1000**（ACK=1001），[1:1001]、[2001:3001] 区间的包我也收到了 - 收到 4 号包的时候在 ACK 包中告诉发送端：喂，小老弟，我目前收到的最大连续的包序号是 **1000**（ACK=1001），[1:1001]、[2001:4001] 区间的包我也收到了 - 收到 5 号包的时候在 ACK 包中告诉发送端：喂，小老弟，我目前收到的最大连续的包序号是 **1000**（ACK=1001），[1:1001]、[2001:5001] 区间的包我也收到了 这样发送端就清楚知道只用重传 2 号数据包就可以了，数据包 3、4、5已经确认无误被对端收到。这种方式被称为 SACK（Selective Acknowledgment） ​ 大值流程如下： ![](http://heketong.github.io/donate/SACK快速重传.png) ![](http://heketong.github.io/donate/SACK快速重传WireShark抓包1.png) 打开单个包的详情，在 ACK 包的 option 选项里，包含了 SACK 的信息，如下图： ![](http://heketong.github.io/donate/SACK快速重传WireShark抓包2.png) ## 隔多久重传？ ### 经典方法（适用 RTT 波动较小的情况） ​ 一个最简单的想法就是取平均值，比如第一次 RTT 为 500ms，第二次 RTT 为 800ms，那么第三次发送时，各让一步取平均值 RTO 为 650ms。经典算法的思路跟取平均值是一样的，只不过系数不一样而已。 ​ 经典算法引入了「平滑往返时间」（Smoothed round trip time，SRTT）的概念：经过平滑后的RTT的值，每测量一次 RTT 就对 SRTT 作一次更新计算。  SRTT = ( α * SRTT ) + ((1- α) * RTT)\n ## 标准方法（Jacobson / Karels 算法） 传统方法最大的问题是RTT 有大的波动时，很难即时反应到 RTO 上，因为都被平滑掉了。标准方法对 RTT 的采样增加了一个新的因素  SRTT = (1 - α) * SRTT + α * RTT RTTVAR = (1 - β) * RTTVAR + β * (|RTT-SRTT|) RTO= µ * SRTT + ∂ * RTTVar\n ## 重传二义性与 Karn / Partridge 算法 前面的算法都很精妙，但是有一个最基本的问题还没解决，如何重传情况下计算 RTT，下面列举了三种常见的场景 ![](http://heketong.github.io/donate/重传二义性.png) Karn / Partridge 算法就是为了解决重传二义性的。它的思路也是很奇特，解决问题的最好办法就是不解决它： - 既然不能确定 ACK 包到底对应重传包还是非重传包，那这次就忽略吧，这次重传的 RTT 不会被用来更新 SRTT 及后面的 RTO - 只有当收到未重传过的某个请求的 ACK 包时，才更新 SRTT 等变量并重新计算RTO 仅仅有上面的规则是远远不够的，放弃掉重传那次不管看起来就像遇到危险把头埋在沙子里的鸵鸟。如果网络抖动，倒是突然出现大量重传，但这个时候 RTO 没有更新，就很坑了，本身 RTO 就是为了自适应网络延迟状况的，结果出问题了没有任何反应。这里 Karn 算法采用了出现重传就将 RTO 翻倍的方法，这就是我们前面看到过的指数级退避（Exponential backoff）。这种方式比较粗暴，但是非常简单。 # 滑动窗口 ## 背景 ![](http://heketong.github.io/donate/滑动窗口引入背景.png) 从socket的角度看TCP，大概如上面所示，TCP 会把要发送的数据放入发送缓冲区（Send Buffer)，接收到的数据放入接收缓冲区（Receive Buffer），应用程序会不停的读取接收缓冲区的内容进行处理。 **流量控制做的事情就是**，**如果接收缓冲区已满，发送端应该停止发送数据**。那发送端怎么知道接收端缓冲区是否已满呢？ 为了控制发送端的速率，接收端会告知客户端自己接收窗口（rwnd），也就是接收缓冲区中空闲的部分。 ![](http://heketong.github.io/donate/TCP_Receive_Buffer.png) TCP 在收到数据包回复的 ACK 包里会带上自己接收窗口的大小，接收端需要根据这个值调整自己的发送策略。 ## 抓包中的win是什么？ ![](http://heketong.github.io/donate/抓包中的Win.png) 这里的Win是告诉对方，自己接收窗口的大小。这里的Win=29312是告诉对方自己当前能接收数据最大为29312，对方收到以后，会把自己的「发送窗口」限制在 29312 大小之内。如果自己的处理能力有限，导致自己的接收缓冲区满，接收窗口大小为 0，发送端应该停止发送数据。 ## TCP包状态分类 ![](http://heketong.github.io/donate/tcp包状态分类.png) - 粉色部分#1 (Bytes Sent and Acknowledged)：表示已发送且已收到 ACK 确认的数据包。 - 蓝色部分#2 (Bytes Sent but Not Yet Acknowledged)：表示已发送但未收到 ACK 的数据包。发送方不确定这部分数据对端有没有收到，如果在一段时间内没有收到 ACK，发送端需要重传这部分数据包。 - 绿色部分#3 (Bytes Not Yet Sent for Which Recipient Is Ready)：表示未发送但接收端已经准备就绪可以接收的数据包（有空间可以接收） - 黄色部分#4 (Bytes Not Yet Sent，Not Ready to Receive)：表示还未发送，且这部分接收端没有空间接收 ## 发送窗口(send window)与可用窗口(usable window) 首先这两个概念都是站在发送数据方说的，需要考虑接收方的Win窗口大小。 - **发送窗口**是 TCP 滑动窗口的核心概念，它表示了在某个时刻一端能拥有的最大未确认的数据包大小（最大在途数据），发送窗口是发送端被允许发送的最大数据包大小，其大小等于上图中 #2 区域和 #3 区域加起来的总大小，说白了就是发送数据方最多能发送多少数据(包括已发送但是没有被Ack的数据) - **可用窗口**是发送端还能发送的最大数据包大小，它等于发送窗口的大小减去在途数据包大小，是发送端还能发送的最大数据包大小，对应于上图中的 #3 号区域。说白了就是发送方当前实际最多能发送多少数据(发送窗口大小**减掉**已发送但未Ack的大小) - 窗口的左边界表示**成功发送并已经被接收方确认的最大字节序号**，窗口的右边界是**发送方当前可以发送的最大字节序号**，滑动窗口的大小等于右边界减去左边界，如下图： ![](http://heketong.github.io/donate/滑动窗口示意.png) ​ 当上图中的可用区域的6个字节（46~51）发送出去，可用窗口区域减小到 0，这个时候除非收到接收端的 ACK 数据，否则发送端将不能发送数据。 ![](http://heketong.github.io/donate/滑动窗口用光示意.png) ## 利用packetdrill模拟滑动窗口用光 ### 脚本  \u0026ndash;tolerance_usecs=100000 0 socket(\u0026hellip;, SOCK_STREAM, IPPROTO_TCP) = 3 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0 // 禁用 nagle 算法 +0 setsockopt(3, SOL_TCP, TCP_NODELAY, [1], 4) = 0 +0 bind(3, \u0026hellip;, \u0026hellip;) = 0 +0 listen(3, 1) = 0 // 三次握手 +0 \u0026lt; S 0:0(0) win 20 +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;\u0026hellip;\u0026gt; +.1 \u0026lt; . 1:1(0) ack 1 win 20 +0 accept(3, \u0026hellip;, \u0026hellip;) = 4 // 演示已经发送并 ACK 前 31 字节数据 +.1 write(4, \u0026hellip;, 15) = 15 +0 \u0026lt; . 1:1(0) ack 16 win 20 +.1 write(4, \u0026hellip;, 16) = 16 +0 \u0026lt; . 1:1(0) ack 32 win 20 +0 write(4, \u0026hellip;, 14) = 14 +0 write(4, \u0026hellip;, 6) = 6 +.1 \u0026lt; . 1:1(0) ack 52 win 20 +0 sleep 1000000\n **解析如下：** - 一开始我们禁用了 Nagle 算法以便后面可以连续发送包。 - 三次握手以后，客户端声明自己的窗口大小为 20 字节 - 通过两次发包和确认前 31 字节的数据 - 发送端发送(32,46)部分的 14 字节数据，滑动窗口的可用窗口变为 6 - 发送端发送(46,52)部分的 6 字节数据，滑动窗口的可用窗口变为 0，此时发送端不能往接收端发送任何数据了，除非有新的 ACK 到来 - 接收端确认(32,52)部分 20 字节的数据，可用窗口重现变为 20. ### wireshark抓包 ![](http://heketong.github.io/donate/滑动窗口用光wireshark抓包.png) - 1---\u0026gt;3 为三次握手 客户端声明自己Win为20(缓冲区最多存放20字节 也就是服务端的发送窗口为20) - 4为服务端发送15字节 然后5为客户端ack这15自己已经收到 - 6为服务端发送16字节 然后7为客户端ack这16自己已经收到 - 8为服务端发送14字节，然后客户端没有ack(所以服务端的可用窗口由20----\u0026gt;6) - 9为服务端再次发送6个字节 把可用窗口用光 这个时候 不能再发送数据了 - 10为客户端回复ack，8、9发送的20字节都已经收到，这个是Win又变为20，也就是告诉服务端可以继续发送数据了 抓包显示的 **TCP Window Full**不是一个 TCP 的标记，而是 wireshark 智能帮忙分析出来的，表示**包的发送方已经把对方所声明的接收窗口耗尽了**，三次握手中客户端声明自己的接收窗口大小为 20，这意味着发送端最多只能给它发送 20 个字节的数据而无需确认，**在途字节数**最多只能为 20 个字。 ### 滑动窗口变化示意图 ![](http://heketong.github.io/donate/滑动窗口用尽变化流程示意.png) ## 利用packetdrill模拟滑动窗口为0 继续发包会出现什么情况  \u0026ndash;tolerance_usecs=100000 0 socket(\u0026hellip;, SOCK_STREAM, IPPROTO_TCP) = 3 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0 +0 bind(3, \u0026hellip;, \u0026hellip;) = 0 +0 listen(3, 1) = 0 +0 \u0026lt; S 0:0(0) win 4000 +0 \u0026gt; S. 0:0(0) ack 1 \u0026lt;\u0026hellip;\u0026gt; // 三次握手确定客户端接收窗口大小为 360 +.1 \u0026lt; . 1:1(0) ack 1 win 360 +0 accept(3, \u0026hellip;, \u0026hellip;) = 4 // 第一步：往客户端（接收端）写 140 字节数据 +0 write(4, \u0026hellip;, 140) = 140 // 第二步：模拟客户端回复 ACK，接收端滑动窗口减小为 260 +.01 \u0026lt; . 1:1(0) ack 141 win 260 // 第四步：服务端（发送端）接续发送 180 字节数据给客户端（接收端） +0 write(4, \u0026hellip;, 180) = 180 // 第五步：模拟客户端回复 ACK，接收端滑动窗口减小到 80 +.01 \u0026lt; . 1:1(0) ack 321 win 80 // 第七步：服务端（发送端）继续发送 80 字节给客户端（接收端） +0 write(4, \u0026hellip;, 80) = 80 // 第八步：模拟客户端回复 ACK，接收端滑动窗口减小到 0 +.01 \u0026lt; . 1:1(0) ack 401 win 0 // 这一步很重要，写多少数据没关系，一定要有待发送的数据。如果没有待发的数据，不会进行零窗口探测 // 这 100 字节数据实际上不会发出去 +0 write(4, \u0026hellip;, 100) = 100 +0 sleep 1000000\n ### wireshark抓包结果 ![](http://heketong.github.io/donate/tcp滑动窗口用光继续发包.png) - No = 8 的包，发送端发送 80 以后，自己已经把接收端声明的接收窗口大小耗尽了，wireshark 帮我们把这种行为识别为了 TCP Window Full。 - No = 9 的包，是接收端回复的 ACK，携带了 win=0，wireshark 帮忙把这个包标记为了 TCP Zero window - No = 10 ~ 25 的包就是我们前面提到的TCP Zero Window Probe(**零窗口探测包**)，但是 wireshark 这里识别这个包为了 Keep-Alive，之所以被识别为Keep-Alive 是因为这个包跟 Keep-Alive 包很像。这个包的特点是：**一个长度为 0 的 ACK 包，Seq 为当前连接 Seq 最大值减一**。因为发出的探测包一直没有得到回应，所以会一直发送端会一直重试。重试的策略跟前面介绍的超时重传的机制一样，时间间隔遵循指数级退避，最大时间间隔为 120s，重试了 16，总共花费了 16 分钟 ## 利用零窗口探测搞死服务器 有等待重试的地方就有攻击的可能，上面的零窗口探测也会成为攻击的对象。试想一下，一个客户端利用服务器上现有的大文件，向服务器发起下载文件的请求，在接收少量几个字节以后把自己的 window 设置为 0，不再接收文件， 服务端就会开始漫长的十几分钟时间的零窗口探测，如果有大量的客户端对服务端执行这种攻击操作，那么服务端资源很快就被消耗殆尽。 ## TCP window full 与 TCP zero window 这两者都是发送速率控制的手段， - TCP Window Full 是站在**发送端**角度说的，表示在途字节数等于对方接收窗口的情况，此时发送端不能再发数据给对方直到发送的数据包得到 ACK。 - TCP zero window 是站在**接收端**角度来说的，是接收端接收窗口满，告知对方不能再发送数据给自己。 # TCP拥塞控制 - 滑动窗口只关注了发送端和接收端自身的情况，并没有考虑整个网络的情况，所以就有了拥塞控制 - TCP的拥塞控制主要涉及3个处理机制 - 慢启动(Slow Start) - 拥塞避免(Congestion Avoidance) - 快速重传(Fast Retransmit)、快速恢复(Fast Recovery) 为了实现这三个机制，每个TCP链接都有2个核心状态值 - 拥塞窗口(Congestion Window)---cwnd - 慢启动阀值(Slow Start Threshold)---ssthresh ## 拥塞窗口 （Congestion Window，cwnd） - 拥塞窗口指的是在收到对端 ACK 之前自己还能传输的最大 **MSS 段数**。 - 接收窗口（rwnd）是**接收端**的限制，是接收端还能接收的数据量大小 - 拥塞窗口（cwnd）是**发送端**的限制，是发送端在还未收到对端 ACK 之前还能发送的数据量大小 - 前面滑动窗口讲的发送窗口是单纯不考虑网络的情况，考虑网络，真正的发送窗口大小 = 「接收端接收窗口大小」 与 「发送端自己拥塞窗口大小」 两者的最小值 发送端能发送多少数据，取决于两个因素： - 对方能接收多少数据（接收窗口） - 自己为了避免网络拥塞主动控制不要发送过多的数据（拥塞窗口） TCP不会在双方数据交互过程中，交换彼此的cwnd，这个值是维护在本地内存中的一个值。 拥塞控制的核心就是控制拥塞窗口的大小变化(cwnd) ## 慢启动Slow Start - 所谓慢启动指的是 刚开始拥塞窗口很小，不至于让网络瘫痪，然后测试看看是否丢跑，如果对端及时Ack了，说明网络ok，慢慢增加拥塞窗口，多发送数据，持续这个过程，直到拥塞避免阶段(拥塞窗口达到慢启动阀值)。 - 大致过程如下： - 第一步，三次握手以后，双方通过 ACK 告诉了对方自己的接收窗口（rwnd）的大小，之后就可以互相发数据了 - 第二步，通信双方各自初始化自己的「拥塞窗口」（Congestion Window，cwnd）大小。 - 第三步，cwnd 初始值较小时，每收到一个 ACK，每经过一个 RTT，cwnd 变为之前的两倍。 - - linux现在默认初始cwnd为10(根据 Google 的研究，90% 的 HTTP 请求数据都在 16KB 以内，约为 10 个 TCP 段。再大比如 16，在某些地区会出现明显的丢包，因此 10 是一个比较合理的值) ![](http://heketong.github.io/donate/拥塞窗口变化曲线1.png) - 因此可以得到拥塞窗口到达N所花费时间为:  time(cwnd到达N)=RTT * (log ( N/initcwnd) )//这里假设RTT稳定 假设RTT为50ms，客户端和服务端的接收窗口为65535字节（64KB），初始拥塞窗口为10个MSS。 这里的N我们要先换算为MSS段数 MSS按照1460算 N=65535\u0026frasl;1460=45 所以到达65536字节，也就是到达64K的吞吐量需要的时间为： 50ms * log(45\u0026frasl;10)=50ms*2.12=106ms,如果RTT更小 那么这个时间也会相应变小 甚至可以忽略\n ## 慢启动阈值（Slow Start Threshold，ssthresh） 慢启动拥塞窗口（cwnd）肯定不能无止境的指数级增长下去，否则拥塞控制就变成了「拥塞失控」了，它的阈值称为「慢启动阈值」（Slow Start Threshold，ssthresh），这是文章开头介绍的拥塞控制的第二个核心状态值。ssthresh 就是一道刹车，让拥塞窗口别涨那么快。 - 当 cwnd \u0026lt; ssthresh 时，拥塞窗口按指数级增长（慢启动） - 当 cwnd \u0026gt;= ssthresh 时，拥塞窗口按线性增长（拥塞避免） ## 拥塞避免（Congestion Avoidance） 当 cwnd \u0026gt; ssthresh 时，拥塞窗口进入「拥塞避免」阶段，在这个阶段，每一个往返 RTT，拥塞窗口大约增加 1 个 MSS 大小，直到检测到拥塞为止(三次重复Ack)。 ![](http://heketong.github.io/donate/拥塞避免阶段_拥塞窗口变化.png) 与慢启动的区别在于 - 慢启动的做法是 RTT 时间内每收到一个 ACK，也就是每经过 1 个 RTT，cwnd 翻倍 - 拥塞避免的做法保守的多，每经过一个RTT 才将拥塞窗口加 1，不管期间收到多少个 ACK ## 快速重传与快速恢复 - 当发送方收到3次或者更多次重复的Ack，就认为网络已经轻度拥塞了，这个时候会进行快速重传(只传SACK里面没有的包)，同时进入快速恢复阶段： - 拥塞阈值 ssthresh 降低为 cwnd 的一半：ssthresh = cwnd / 2 - 拥塞窗口 cwnd 设置为 ssthresh - 拥塞窗口线性增加 (直到再次出现重复Ack，然后再次进行快速重发和快速恢复 如此循环) ![](http://heketong.github.io/donate/TCP_RENO版本拥塞窗口变化图.gif) 现在的initcwnd已经不是1了 上图还是1 # Nagle 算法  if there is new data to send if the window size \u0026gt;= MSS and available data is \u0026gt;= MSS send complete MSS segment now else if there is unconfirmed data still in the pipe enqueue data in the buffer until an acknowledge is received else send data immediately end if end if end if\n - Nagle 算法的作用是减少小包在客户端和服务端直接传输，一个包的 TCP 头和 IP 头加起来至少都有 40 个字节，如果携带的数据比较小的话，那就非常浪费了。就好比开着一辆大货车运一箱苹果一样 - Nagle 算法在通信时延较低的场景下意义不大。在 Nagle 算法中 ACK 返回越快，下次数据传输就越早 - 假设 RTT 为 10ms 且没有延迟确认，那么你敲击键盘的间隔大于 10ms 的话就不会触发 Nagle 的条件：只有接收到所有的在传数据的 ACK 后才能继续发数据，也即如果所有的发出去的包 ACK 都收到了，就不用等了。如果你想触发 Nagle 的停等（stop-wait）机制，1s 内要输入超过 100 个字符。因此如果在局域网内，Nagle 算法基本上没有什么效果 ## 关闭Nagle算法 TCP_NODELAY选项设置为true ## 小结 Nagle 算法，这个算法可以有效的减少网络上小包的数量。Nagle 算法是应用在发送端的，简而言之就是，对发送端而言： - 当第一次发送数据时不用等待，就算是 1byte 的小包也立即发送 - 后面发送数据时需要累积数据包直到满足下面的条件之一才会继续发送数据： - 数据包达到最大段大小MSS - 接收端收到之前数据包的确认 ACK 不过 **Nagle 算法是时代的产物**，可能会导致较多的性能问题，尤其是与ack延迟确认一起使用的时候。很多组件为了高性能都默认禁用掉了这个特性 Nagle 算法出现的时候网络带宽都很小，当有大量小包传输时，很容易将带宽占满，出现丢包重传等现象。因此对 ssh 这种交互式的应用场景，选择开启 Nagle 算法可以使得不再那么频繁的发送小包，而是合并到一起，代价是稍微有一些延迟。现在的 ssh 客户端已经默认关闭了 Nagle 算法。 # Ack延迟确认 delayed ack - 不是每个数据包都对应一个 ACK 包，因为可以合并确认。 - 也不是接收端收到数据以后必须立刻马上回复确认包 如果收到一个数据包以后暂时没有数据要分给对端，它可以等一段时间（Linux 上是 40ms）再确认。如果这段时间刚好有数据要传给对端，ACK 就可以随着数据一起发出去了。如果超过时间还没有数据要发送，也发送 ACK，以免对端以为丢包了。这种方式成为「延迟确认」 这个原因跟 Nagle 算法其实一样，回复一个空的 ACK 太浪费了。 - 如果接收端这个时候恰好有数据要回复客户端，那么 ACK 搭上顺风车一块发送。 - 如果期间又有客户端的数据传过来，那可以把多次 ACK 合并成一个立刻发送出去 - 如果一段时间没有顺风车，那么没办法，不能让接收端等太久，一个空包也得发。 ## 什么场景立马回复Ack - 如果接收到了大于一个frame 的报文，且需要调整窗口大小 - 处于 quickack 模式（tcp_in_quickack_mode） - 收到乱序包（We have out of order data.） 其它情况一律采用Delayed ack - pingpong就是有来有回 一般是R-W-R-W... - 延迟确认出现的最多的场景是 `W-W-R`（写写读） ## Delayed ack例子 - 服务端 readLine 有返回非空字符串（读到`\\n 或 \\r`）就把字符串原样返回给客户端  public class DelayAckServer { private static final int PORT = 8888; public static void main(String[] args) throws IOException { ServerSocket serverSocket = new ServerSocket(); serverSocket.bind(new InetSocketAddress(PORT)); System.out.println(\u0026ldquo;Server startup at \u0026rdquo; + PORT); while (true) { Socket socket = serverSocket.accept(); InputStream inputStream = socket.getInputStream(); OutputStream outputStream = socket.getOutputStream(); int i = 1; while (true) { BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream)); String line = reader.readLine(); if (line == null) break; System.out.println((i++) + \u0026ldquo; : \u0026ldquo; + line); outputStream.write((line + \u0026ldquo;\\n\u0026rdquo;).getBytes()); } } } }\n - 客户端分两次调用 write 方法，模拟 http 请求的 header 和 body。第二次 write 包含了换行符（\\n)，然后测量 write、write、read 所花费的时间  public class DelayAckClient { public static void main(String[] args) throws IOException { Socket socket = new Socket(); socket.connect(new InetSocketAddress(\u0026ldquo;server_ip\u0026rdquo;, 8888)); InputStream inputStream = socket.getInputStream(); OutputStream outputStream = socket.getOutputStream(); BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream)); String head = \u0026ldquo;hello, \u0026ldquo;; String body = \u0026ldquo;world\\n\u0026rdquo;;\n for (int i = 0; i \u0026lt; 10; i++) { long start = System.currentTimeMillis(); outputStream.write((\u0026quot;#\u0026quot; + i + \u0026quot; \u0026quot; + head).getBytes()); // write outputStream.write((body).getBytes()); // write String line = reader.readLine(); // read System.out.println(\u0026quot;RTT: \u0026quot; + (System.currentTimeMillis() - start) + \u0026quot;: \u0026quot; + line); } inputStream.close(); outputStream.close(); socket.close(); }  }\n - 运行结果:  javac DelayAckClient.java; java -cp . DelayAckClient RTT: 1: #0 hello, world RTT: 44: #1 hello, world RTT: 46: #2 hello, world RTT: 44: #3 hello, world RTT: 42: #4 hello, world RTT: 41: #5 hello, world RTT: 41: #6 hello, world RTT: 44: #7 hello, world RTT: 44: #8 hello, world RTT: 44: #9 hello, world\n 除了第一次，剩下的 RTT 全为 40 多毫秒。这刚好是 Linux 延迟确认定时器的时间 40ms . 对包逐个分析一下 1 ~ 3：三次握手 4 ~ 9：第一次 for 循环的请求，也就是 W-W-R 的过程 - 4：客户端发送 \u0026quot;#0 hello, \u0026quot; 给服务端 - 5：因为服务端只收到了数据还没有回复过数据，tcp 判断不是 pingpong 的交互式数据，属于 quickack 模式，立刻回复 ACK - 6：客户端发送 \u0026quot;world\\n\u0026quot; 给服务端 - 7：服务端因为还没有回复过数据，tcp 判断不是 pingpong 的交互式数据，服务端立刻回复 ACK - 8：服务端读到换行符，readline 函数返回，会把读到的字符串原样写入到客户端。TCP 这个时候检测到是 pingpong 的交互式连接，进入延迟确认模式 - 9：客户端收到数据以后回复 ACK 10 ~ 14：第二次 for 循环 - 10：客户端发送 \u0026quot;#1 hello, \u0026quot; 给服务端。服务端收到数据包以后，因为处于 pingpong 模式，开启一个 40ms 的定时器，奢望在 40ms 内有数据回传 - 11：很不幸，服务端等了 40ms 定期器到期都没有数据回传，回复确认 ACK 同时取消 pingpong 状态 - 12：客户端发送 \u0026quot;world\\n\u0026quot; 给服务端 - 13：因为服务端不处于 pingpong 状态，所以收到数据立即回复 ACK - 14：服务端读到换行符，readline 函数返回，会把读到的字符串原样写入到客户端。这个时候又检测到收发数据了，进入 pingpong 状态。 从第二次 for 开始，后面的数据包都一样了。 整个过程包交互图如下： ![](http://heketong.github.io/donate/delayedAck示意图.png) ## Nagle算法+Dealyed Ack 上面结果其实是默认开启了Nagle算法的，如果将其关闭 每次RTT都差不多，几乎为0. 禁用 Nagle 的情况下，不用等一个包发完再发下一个，而是几乎同时把两次写请求发送出来了。服务端收到带换行符的包以后，立马可以返回结果，ACK 可以捎带过去，就不会出现延迟 40ms 的情况 # TCP的keepalive ## 背景 络故障或者系统宕机都将使得对端无法得知这个消息。如果应用程序不发送数据，可能永远无法得知该连接已经失效。假设应用程序是一个 web 服务器，客户端发出三次握手以后故障宕机或被踢掉网线，对于 web 服务器而已，下一个数据包将永远无法到来，但是它一无所知。TCP 不会采用类似于轮询的方式来询问：小老弟你有什么东西要发给我吗？  这一个情况就是如果在未告知另一端的情况下通信的一端关闭或终止连接，那么就认为该条TCP连接处于半打开状态。 这种情况发现在通信的一方的主机崩溃、电源断掉的情况下。 只要不尝试通过半开连接来传输数据，正常工作的一端将不会检测出另外一端已经崩溃。 那么有一段将一直有一个ESTABLISHED状态的连接 占用资源\n ## linux tcp keepalive相关参数  // 多少秒 没有数据包交互发送keepalive探测包 默认 ketonghe@ubuntu:~/code$ cat /proc/sys/net/ipv4/tcp_keepalive_time 7200 //每次keepalive探测时间间隔 单位秒 ketonghe@ubuntu:~/code$ cat /proc/sys/net/ipv4/tcp_keepalive_intvl 75 //最多探测多少次 ketonghe@ubuntu:~/code$ cat /proc/sys/net/ipv4/tcp_keepalive_probes 9\n ## 为什么大部分应用程序都没有开启 keepalive 选项 现在大部分应用程序）都没有开启 keepalive 选项，一个很大的原因就是默认的超时时间太长了，从没有数据交互到最终判断连接失效，需要花 2.1875 小时（7200 + 75 * 9），显然太长了。但如果修改这个值到比较小，又违背了 keepalive 的设计初衷（为了检查长时间死连接） ## 生产实践 - 一般都有心跳包：比如服务端针对每个连接计时，如果长时间没有收到客户端的数据就直接close掉这个连接。客户端如果想要维持长连接就间隔一定时间发送心跳包。 # TCP的定时器 ## 连接建立定时器（connection establishment） 当发送端发送 SYN 报文想建立一条新连接时，会开启连接建立定时器，如果没有收到对端的 ACK 包将进行重传。 时间变化规律为: 间隔 1s、2s、4s、8s、16s、32s。。。。重传次数为配置: /proc/sys/net/ipv4/tcp_syn_retries 默认6 ![](http://heketong.github.io/donate/SYN重发定时器.png) ## 重传定时器（retransmission） 如果在发送数据包的时候没有收到 ACK 呢？这就是这里要讲的第二个定时器重传定时器。重传定时器在时间是动态计算的，取决于 RTT 和重传的次数。 /proc/sys/net/ipv4/tcp_retries2 配置最大重传次数 默认15 ![](http://heketong.github.io/donate/重传示意1.png) ## 延迟 ACK 定时器 TCP 收到数据包以后在没有数据包要回复时，不马上回复 ACK。这时开启一个定时器，等待一段时间看是否有数据需要回复。如果期间有数据要回复，则在回复的数据中捎带 ACK，如果时间到了也没有数据要发送，则也发送 ACK。linux很多默认40ms，这个可以参见上面的delayed ack章节 ## 坚持计时器（persist timer） 专门为零窗口探测而准备的，我们都知道 TCP 利用滑动窗口来实现流量控制，当接收端 B 接收窗口为 0 时，发送端 A 此时不能再发送数据，发送端A此时开启 Persist 定时器，超时后发送一个特殊的报文给接收端看对方窗口是否已经恢复，这个特殊的报文只有一个字节 ![](http://heketong.github.io/donate/persist定时器.png) ## 保活定时器（keepalive timer） 通信以后一段时间有再也没有传输过数据，怎么知道对方是不是已经挂掉或者重启了呢？于是 TCP 提出了一个做法就是在连接的空闲时间超过 2 小时，会发送一个探测报文，如果对方有回复则表示连接还活着，对方还在，如果经过几次探测对方都没有回复则表示连接已失效，客户端会丢弃这个连接。 ## FIN_WAIT_2 定时器 四次挥手过程中，主动关闭的一方收到 ACK 以后从 FIN_WAIT_1 进入 FIN_WAIT_2 状态等待对端的 FIN 包的到来，FIN_WAIT_2 定时器的作用是防止对方一直不发送 FIN 包，防止自己一直傻等。这个值由`/proc/sys/net/ipv4/tcp_fin_timeout` 决定 ![](http://heketong.github.io/donate/Fin_WAIT2定时器.png) ## TIME_WAIT 定时器 ![](http://heketong.github.io/donate/TIME_WAIT定时器.png) TIME_WAIT存在的意义有两个： - 可靠的实现 TCP 全双工的连接终止（处理最后 ACK 丢失的情况） - 避免当前关闭连接与后续连接混淆（让旧连接的包在网络中消逝） # 一些工具使用 ## telnet  //检查端口是否打开\ntelnet [domainname or ip] [port] //发送http请求 telnet www.baidu.com 80 GET / HTTP/1.1\nHost: www.baidu.com //连接redis 执行命令 $ telnet 127.0.0.1 6379 Trying 127.0.0.1\u0026hellip; Connected to localhost. Escape character is \u0026lsquo;^]\u0026rsquo;. set hello world +OK get hello $5 world\n ## netcat  //快速启动监听 或者聊天 nc -l 9090 //快速启动进程 监听9090端口 l为监听listen的意思\nnc localhost 9090 //连接本机的9090端口 接下来2端就可以聊天了 //可以跟telnet一样 发送http请求 $ nc www.baidu.com 80 GET / HTTP/1.1 host: www.baidu.com\nHTTP/1.1 200 OK Accept-Ranges: bytes Cache-Control: no-cache Connection: keep-alive Content-Length: 14615\n\u0026hellip;. //用unix管道的形式 发送http请求 echo -ne \u0026ldquo;GET / HTTP/1.1\\r\\nhost:www.baidu.com\\r\\n\\r\\n\u0026rdquo; | nc www.baidu.com 80 echo 的 -n 参数很关键，echo 默认会在输出的最后增加一个换行，加上 -n 参数以后就不会在最后自动换行了。\n执行上面的命令，可以看到也返回了百度的首页 html //查看远端端口是否打开 -z 参数表示不发送任何数据包，tcp 三次握手完后自动退出进程。有了 -v 参数则会输出更多详细信息（verbose） nc -zv [host or ip] [port] $ nc -zv www.baidu.com 80\nConnection to www.baidu.com port 80 [tcp/http] succeeded! //也可以访问redis nc localhost 6379 \u0026hellip; 然后就可以执行命令了 $ echo get hello | nc localhost 6379 //也可以这样直接执行一个命令 $5\nworld  ## netstat  //参数说明 -a 列出所有套接字 包括各种协议 各种状态的 -t 列出tcp相关的 -u 列出udp相关的 -l 列出处于监听状态的 -n 禁用端口和ip映射 -p 显示进程\n-i 显示所有网卡信息 //查看某个状态处于某个状态的连接 同时打印相关进程信息 ketonghe@ubuntu:~/code$ netstat -tnp|grep 8787|grep xxx (Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.) tcp 0 0 192.168.3.66:8787 192.168.3.66:43072 ESTABLISHED 88296/./server\ntcp 0 0 192.168.3.66:43072 192.168.3.66:8787 ESTABLISHED 88303/./client //统计某个端口处于各个状态的连接个数 ketonghe@ubuntu:~/code$ netstat -ant | grep 8787|awk \u0026lsquo;{print $6}\u0026rsquo; | sort | uniq -c | sort -n 2 LISTEN 4 ESTABLISHED\n ## tcpdump  //常用参数说明 另外一般都要root权限 -i 指定网卡 tcpdump -i any就是所有网卡 ifconfig可以查看网卡信息 -i en1就是只监控en1网卡的 host 指定主机 sudo tcpdump -i en1 host 10.211.55.2 //监控en1网卡 主机是xxx的信息 这里没有指定src dst所以可以是源ip或者目标ip sudo tcpdump -i any src 10.211.55.10//只抓取主机xx发出的包 sudo tcpdump -i any dst 10.211.55.1//只抓去主机xx收到的包\nport选项 指定端口 sudo tcpdump -i any dst port 80 //只抓取80端口收到的包 tcpdump portrange 21-23 //抓取 21 到 23 区间所有端口的流量 限定端口范围\n-n 禁止ip映射 显示真实ip -nn 显示真实ip和端口 都不映射 sudo tcpdump -i any -nn udp //过滤协议 只查看udp\n-A 用 ASCII 打印报文内容，比如常用的 HTTP 协议传输 json 、html 文件等都可以用这个选项 sudo tcpdump -i any -nn port 80 -A 输出如下： 11:04:25.793298 IP 183.57.82.231.80 \u0026gt; 10.211.55.10.40842: Flags [P.], seq 1:1461, ack 151, win 16384, length 1460 HTTP/1.1 200 OK Server: Tengine Content-Type: application/javascript\n-X 命令，用来同时用 HEX 和 ASCII 显示报文内容。 sudo tcpdump -i any -nn port 80 -X\n11:33:53.945089 IP 36.158.217.225.80 \u0026gt; 10.211.55.10.45436: Flags [P.], seq 1:1461, ack 151, win 16384, length 1460 0x0000: 4500 05dc b1c4 0000 8006 42fb 249e d9e1 E\u0026hellip;\u0026hellip;\u0026hellip;B.$\u0026hellip; 0x0010: 0ad3 370a 0050 b17c 3b79 032b 8ffb cf66 ..7..P.|;y.+\u0026hellip;f 0x0020: 5018 4000 9e9e 0000 4854 5450 2f31 2e31 P.@\u0026hellip;..HTTP/1.1 0x0030: 2032 3030 204f 4b0d 0a53 6572 7665 723a .200.OK..Server: 0x0040: 2054 656e 6769 6e65 0d0a 436f 6e74 656e .Tengine..Conten 0x0050: 742d 5479 7065 3a20 6170 706c 6963 6174 t-Type:.applicat\n-s 选项 限制包大小 当包体很大，可以用 -s 选项截取部分报文内容，一般都跟 -A 一起使用。查看每个包体前 500 字节可以用下面的命令 sudo tcpdump -i any -nn port 80 -A -s 500 -s 0 就是显示包的所有内容\n-c 选项 抓取固定个数的报文 可以抓取 number 个报文后退出。在网络包交互非常频繁的服务器上抓包比较有用，可能运维人员只想抓取 1000 个包来分析一些网络问题，就比较有用了\nsudo tcpdump -i any -nn port 80 -c 5\n-w 报文输出到文件 sudo tcpdump -i any port 80 -w test.pcap 生成的 pcap 文件就可以用 wireshark 打开进行更详细的分析了 也可以加上 -U 强制立即写到本地磁盘。性能较差\n-S 显示绝对的序列号 不加都是默认从0开始 也就是相对的\n ### 相关布尔运算使用  tcpdump 真正强大的是可以用布尔运算符and（或\u0026amp;\u0026amp;）、or（或||）、not（或!）来组合出任意复杂的过滤器\n抓取 ip 为 10.211.55.10 到端口 3306 的数据包 sudo tcpdump -i any host 10.211.55.10 and dst port 3306\n抓取源 ip 为 10.211.55.10，目标端口除了22 以外所有的流量 sudo tcpdump -i any src 10.211.55.10 and not dst port 22\n复杂分组问题 如果要抓取：来源 ip 为 10.211.55.10 且目标端口为 3306 或 6379 的包，按照前面的描述，我们会写出下面的语句 sudo tcpdump -i any src 10.211.55.10 and (dst port 3306 or 6379) \u0026mdash;-上面这个是错误的 因为有特殊符号() 解决办法是使用单引号把复杂的组合条件包起来\nsudo tcpdump -i any \u0026lsquo;src 10.211.55.10 and (dst port 3306 or 6379)\u0026rsquo; \u0026mdash;这个是正确的\n - 如果想显示所有的 RST 包，要如何来写 tcpdump 的语句呢？答案如下:  tcpdump \u0026lsquo;tcp[13] \u0026amp; 4 != 0\u0026rsquo;\n ![](http://heketong.github.io/donate/tcp头部结构图.png) tcp[13] 表示 tcp 头部中偏移量为 13 字节，如上图中红色框的部分， `!=0` 表示当前 bit 置 1，即存在此标记位，跟 4 做与运算是因为 RST 在 TCP 的标记位的位置在第 3 位(00000100) 如果想过滤 SYN + ACK 包，那就是 SYN 和 ACK 包同时置位（00010010），写成 tcpdump 语句就是  tcpdump \u0026lsquo;tcp[13] \u0026amp; 18 != 0\u0026rsquo;\n ### tcpdump输出解读 A机器用`nc -l 8080`启动一个 tcp 的服务器，然后启动 tcpdump 抓包（`sudo tcpdump -i any port 8080 -nn -A` ） B机器 用 `nc 10.211.55.10 8080`进行连接，然后输入\u0026quot;hello, world\u0026quot;回车 过一段时间 ctrl-c结束连接 整个抓包过程如下  1 16:46:22.722865 IP 10.211.55.5.45424 \u0026gt; 10.211.55.10.8080: Flags [S], seq 3782956689, win 29200, options [mss 1460,sackOK,TS val 463670960 ecr 0,nop,wscale 7], length 0\n2 16:46:22.722903 IP 10.211.55.10.8080 \u0026gt; 10.211.55.5.45424: Flags [S.], seq 3722022028, ack 3782956690, win 28960, options [mss 1460,sackOK,TS val 463298257 ecr 463670960,nop,wscale 7], length 0\n3 16:46:22.723068 IP 10.211.55.5.45424 \u0026gt; 10.211.55.10.8080: Flags [.], ack 1, win 229, options [nop,nop,TS val 463670960 ecr 463298257], length 0\n4 16:46:25.947217 IP 10.211.55.5.45424 \u0026gt; 10.211.55.10.8080: Flags [P.], seq 1:13, ack 1, win 229, options [nop,nop,TS val 463674184 ecr 463298257], length 12 hello world\n5 16:46:25.947261 IP 10.211.55.10.8080 \u0026gt; 10.211.55.5.45424: Flags [.], ack 13, win 227, options [nop,nop,TS val 463301481 ecr 463674184], length 0\n6 16:46:28.011057 IP 10.211.55.5.45424 \u0026gt; 10.211.55.10.8080: Flags [F.], seq 13, ack 1, win 229, options [nop,nop,TS val 463676248 ecr 463301481], length 0\n7 16:46:28.011153 IP 10.211.55.10.8080 \u0026gt; 10.211.55.5.45424: Flags [F.], seq 1, ack 14, win 227, options [nop,nop,TS val 463303545 ecr 463676248], length 0\n8 16:46:28.011263 IP 10.211.55.5.45424 \u0026gt; 10.211.55.10.8080: Flags [.], ack 2, win 229, options [nop,nop,TS val 463676248 ecr 463303545], length 0\n - 第 1~3 行是 TCP 的三次握手的过程 - 第 1 行 中，第一部分是这个包的时间（16:46:22.722865），显示到微秒级。接下来的 \u0026quot;10.211.55.5.45424 \u0026gt; 10.211.55.10.8080\u0026quot; 表示 TCP 四元组：包的源地址、源端口、目标地址、目标端口，中间的大于号表示包的流向。接下来的 \u0026quot;Flags [S]\u0026quot; 表示 TCP 首部的 flags 字段，这里的 S 表示设置了 SYN 标志，其它可能的标志有 - F：FIN 标志 - R：RST 标志 - P：PSH 标志 - U：URG 标志 - . ：没有标志，ACK 情况下使用 接下来的 \u0026quot;seq 3782956689\u0026quot; 是 SYN 包的序号。需要注意的是默认的显示方式是在 SYN 包里的显示真正的序号，在随后的段中，为了方便阅读，显示的序号都是相对序号。 接下来的 \u0026quot;win 29200\u0026quot; 表示自己声明的接收窗口的大小 接下来用[] 包起来的 options 表示 TCP 的选项值，里面有很多重要的信息，比如 MSS、window scale、SACK 等 最后面的 length 参数表示当前包的长度 - 第 2 行是一个 SYN+ACK 包，如前面所说，SYN 包中包序号用的是绝对序号，后面的 win = 28960 也声明的发送端的接收窗口大小。 - 从第 3 行开始，后面的包序号都用的是相对序号了。第三行是客户端 B 向服务端 A 发送的一个 ACK 包。注意这里 win=229，实际的窗口并不是 229，因为窗口缩放（window scale） 在三次握手中确定，后面的窗口大小都需要乘以 window scale 的值 2^7（128），比如这里的窗口大小等于 229 * 2^7 = 229 * 128 = 29312 - 第 4 行是客户端 B 向服务端 A 发送\u0026quot;hello world\u0026quot;字符串，这里的 flag 为`P.`,表示 PSH+ACK。发送包的 seq 为 1:13，长度 length 为 12。窗口大小还是 229 * 128 - 第 5 行是服务端 A 收到\u0026quot;hello world\u0026quot;字符串以后回复的 ACK 包，可以看到 ACK 的值为 13，表示序号为 13 之前的所有的包都已经收到，下次发包从 13 开始发 - 第 6 行是客户端 B 执行 Ctrl+C 以后nc 客户端准备退出时发送的四次挥手的第一个 FIN 包，包序号还是 13，长度为 0 - 第 7 行是服务端 A 对 B 发出的 FIN 包后，也同时回复 FIN + ACK，因为没有往客户端传输过数据包，所以这里的 SEQ 还是 1 - 第 8 行是客户端 A 对 服务端 B 发出的 FIN 包回复的 ACK 包 #### 当然可以用-w选项 输出到文件 然后用wireshark分析就更方便了 ## wireshark 图形化界面抓包工具，对应命令行版本是 tshark 用的比较少 ### 抓包过滤 ​ 抓包的过程很耗 CPU 和内存资源而且大部分情况下我们不是对所有的包都感兴趣，因此可以只抓取满足特定条件的包，丢弃不感兴趣的包，比如只想抓取 ip 为172.18.80.49 端口号为 3306 的包，可以输入`host 172.18.80.49 and port 3306`，语法跟tcpdump差不多 可以在抓包之前设置 ### 显示结果过滤 Display fliter 显示过滤可以算是 wireshark 最常用的功能了，与抓包过滤不一样的是，显示过滤不会丢弃包的内容，不符合过滤条件的包被隐藏起来，方便我们阅读。 ![](http://heketong.github.io/donate/wireshark显示过滤1.png) 过滤的方式常见的有以下几种： - 协议、应用过滤器（ip/tcp/udp/arp/icmp/ dns/ftp/nfs/http/mysql) - 字段过滤器（http.host/dns.qry.name） 比如我们只想看 http 协议报文，在过滤器中输入 http 即可 ![](http://heketong.github.io/donate/wireshark显示过滤_过滤只要http协议.jpg) 字段过滤器可以更加精确的过滤出想要的包，比如我们只想看锤科网站`t.tt`域名的 dns 解析，可以输入`dns.qry.name == t.tt` 再比如，我只想看访问锤科的 http 请求，可以输入`http.host == t.tt` 可以随便找一个 dns 的查询，找到查询报文，展开详情里面的内容，然后鼠标选中想过滤的字段，最下面的状态码就会出现当前 wireshark 对应的查看条件，比如下图中的`dns.qry.name` ![](http://heketong.github.io/donate/wireshark字段过滤技巧1.jpg) #### 常用的查询条件有： ##### tcp 相关过滤器 - tcp.flags.syn==1：过滤 SYN 包 - tcp.flags.reset==1：过滤 RST 包 - tcp.analysis.retransmission：过滤重传包 - tcp.analysis.zero_window：零窗口 ##### http 相关过滤器 - http.host==t.tt：过滤指定域名的 http 包 - http.response.code==302：过滤http响应状态码为302的数据包 - http.request.method==POST：过滤所有请求方式为 POST 的 http 请求包 - http.transfer_encoding == \u0026quot;chunked\u0026quot; 根据transfer_encoding过滤 - http.request.uri contains \u0026quot;/appstock/app/minute/query\u0026quot;：过滤 http 请求 url 中包含指定路径的请求 ##### 通信延迟常用的过滤器 - `http.time\u0026gt;0.5`：请求发出到收到第一个响应包的时间间隔，可以用这个条件来过滤 http 的时延 - tcp.time_delta\u0026gt;0.3：tcp 某连接中两次包的数据间隔，可以用这个来分析 TCP 的时延 - dns.time\u0026gt;0.5：dns 的查询耗时 wireshakr 所有的查询条件在这里可以查到：https:/ /www.wireshark.org/docs/dfref/ ### 比较预算符 wireshark 支持比较运算符和逻辑运算符。这些运算符可以灵活的组合出强大的过滤表达式。 - 等于：== 或者 eq - 不等于：!= 或者 ne - 大于：\u0026gt; 或者 gt - 小于：\u0026lt; 或者 lt - 包含 contains - 匹配 matches - 与操作：AND 或者 \u0026amp;\u0026amp; - 或操作：OR 或者 || - 取反：NOT 或者 ! 比如想过滤 ip 来自 10.0.0.10 且是 TCP 协议的数据包：  ip.addr == 10.0.0.10 and tcp\n ### 协议分层解释 - Frame：物理层的数据帧 - Ethernet II：数据链路层以太网帧头部信息 - Internet Protocol Version 4：互联网层IP包头部信息 - Transmission Control Protocol：传输层的数据段头部信息，此处是TCP协议 - Hypertext Transfer Protocol：应用层 HTTP 的信息 ## 跟踪 TCP 数据流（Follow TCP Stream） 在实际使用过程中，跟踪 TCP 数据流是一个很高频的使用。我们通过前面介绍的那些过滤条件找到了一些包，大多数情况下都需要查看这个 TCP 连接所有的包来查看上下文。 ![](http://heketong.github.io/donate/跟踪tcp流1.jpg) 这样就可以查看整个连接的所有包交互情况了，如下图所示，三次握手、数据传输、四次挥手的过程一目了然 ![](http://heketong.github.io/donate/跟踪tcp流2.jpg) ## 解密HTTPS包 随着 https 和 http2.0 的流行，https 正全面取代 http，这给我们抓包带来了一点点小困难。Wireshark 的抓包原理是直接读取并分析网卡数据。 下图是访问 [www.baidu.com](https://www.baidu.com/) 的部分包截图，传输包的内容被加密了。 ![](http://heketong.github.io/donate/揭秘https_1.jpg) 要想让它解密 HTTPS 流量，要么拥有 HTTPS 网站的加密私钥，可以用来解密这个网站的加密流量，但这种一般没有可能拿到。要么某些浏览器支持将 TLS 会话中使用的对称加密密钥保存在外部文件中，可供 Wireshark 解密流量。 在启动 Chrome 时加上环境变量 SSLKEYLOGFILE 时，chrome 会把会话密钥输出到文件。  SSLKEYLOGFILE=/tmp/SSLKEYLOGFILE.log /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome\n wireshark 可以在`Wireshark -\u0026gt; Preferences... -\u0026gt; Protocols -\u0026gt; SSL`打开Wireshark 的 SSL 配置面板，在`(Pre)-Master-Secret log filename`选项中输入 SSLKEYLOGFILE 文件路径。 ![](http://heketong.github.io/donate/揭秘https_2.jpg) # 抓包的一些应用实战(转载) ## JDBC批量插入问题排查 几年前遇到过一个问题，使用 jdbc 批量插入，插入的性能总是上不去，看代码又查不出什么结果。代码简化以后如下：  java public static void main(String[] args) throws ClassNotFoundException, SQLException { Class.forName(\u0026ldquo;com.mysql.jdbc.Driver\u0026rdquo;); String url = \u0026ldquo;jdbc:mysql://localhost:3306/test?useSSL=false\u0026rdquo;; Connection connection = DriverManager.getConnection(url, \u0026ldquo;root\u0026rdquo;, \u0026ldquo;\u0026rdquo;); PreparedStatement statement = connection.prepareStatement(\u0026ldquo;insert into batch_insert_test(name)values(?)\u0026ldquo;); for (int i = 0; i \u0026lt; 10; i++) { statement.setString(1, \u0026ldquo;name#\u0026rdquo; + System.currentTimeMillis() + \u0026ldquo;#\u0026rdquo; + i); statement.addBatch(); } statement.executeBatch(); }\n 通过 wireshark 抓包，结果如下 ![](http://heketong.github.io/donate/JDBC批量插入问题排查抓包1.png) 可以看到 jdbc 实际上是发送了 10 次 insert 请求，既不能降低网络通信的成本，也不能在服务器上批量执行。 单步调试，发现调用到了`executeBatchSerially` 看源码发现跟`connection.getRewriteBatchedStatements()`有关，当等于 true 时，会进入批量插入的流程，等于 false 时，进入逐条插入的流程。 修改 sql 连接的参数，增加`rewriteBatchedStatements=true`  java // String url = \u0026ldquo;jdbc:mysql://localhost:3306/test?useSSL=false\u0026rdquo;; String url = \u0026ldquo;jdbc:mysql://localhost:3306/test?useSSL=false\u0026amp;rewriteBatchedStatements=true\u0026rdquo;;\n wireshark 抓包情况如下，可以确认批量插入生效了 ![](http://heketong.github.io/donate/JDBC批量插入问题排查抓包1.jpg) rewriteBatchedStatements 参数将  insert into batch_insert_test(name)values(\u0026lsquo;name#1554175696958#0\u0026rsquo;) insert into batch_insert_test(name)values(\u0026lsquo;name#1554175696958#1\u0026rsquo;) insert into batch_insert_test(name)values(\u0026lsquo;name#1554175696958#2\u0026rsquo;) insert into batch_insert_test(name)values(\u0026lsquo;name#1554175696958#3\u0026rsquo;) insert into batch_insert_test(name)values(\u0026lsquo;name#1554175696958#4\u0026rsquo;) insert into batch_insert_test(name)values(\u0026lsquo;name#1554175696958#5\u0026rsquo;) insert into batch_insert_test(name)values(\u0026lsquo;name#1554175696958#6\u0026rsquo;) insert into batch_insert_test(name)values(\u0026lsquo;name#1554175696958#7\u0026rsquo;) insert into batch_insert_test(name)values(\u0026lsquo;name#1554175696958#8\u0026rsquo;) insert into batch_insert_test(name)values(\u0026lsquo;name#1554175696958#9\u0026rsquo;)\n 改写为真正的批量插入  insert into batch_insert_test(name)values (\u0026lsquo;name#1554175696958#0\u0026rsquo;),(\u0026lsquo;name#1554175696958#1\u0026rsquo;), (\u0026lsquo;name#1554175696958#2\u0026rsquo;),(\u0026lsquo;name#1554175696958#3\u0026rsquo;), (\u0026lsquo;name#1554175696958#4\u0026rsquo;),(\u0026lsquo;name#1554175696958#5\u0026rsquo;), (\u0026lsquo;name#1554175696958#6\u0026rsquo;),(\u0026lsquo;name#1554175696958#7\u0026rsquo;), (\u0026lsquo;name#1554175696958#8\u0026rsquo;),(\u0026lsquo;name#1554175696958#9\u0026rsquo;)\n ### 思考 我们经常会用很多第三方的库，这些库我们一般没有精力把每行代码都读通读透，遇到问题时，抓一些包也许就可以很快确定问题的所在，这就是抓包网络分析的魅力所在。 ## Nginx 频繁出现 OOM问题排查 在最近的一次百万长连接压测中，32C 128G 的四台 Nginx 频繁出现 OOM(内存耗尽) ### 现象描述 这是一个 websocket 百万长连接收发消息的压测环境，客户端 jmeter 用了上百台机器，经过四台 Nginx 到后端服务，简化后的部署结构如下图所示。 ![](http://heketong.github.io/donate/nginxOOM排查_部署图.jpg) 在维持百万连接不发数据时，一切正常，Nginx 内存稳定。在开始大量收发数据时，Nginx 内存开始以每秒上百 M 的内存增长，直到占用内存接近 128G，woker 进程开始频繁 OOM 被系统杀掉。32 个 worker 进程每个都占用接近 4G 的内存。dmesg -T 的输出如下所示  [Fri Mar 13 18:46:44 2020] Out of memory: Kill process 28258 (nginx) score 30 or sacrifice child [Fri Mar 13 18:46:44 2020] Killed process 28258 (nginx) total-vm:1092198764kB, anon-rss:3943668kB, file-rss:736kB, shmem-rss:4kB\n work 进程重启后，大量长连接断连，压测就没法继续增加数据量 ### 排查过程分析 - 拿到这个问题，首先查看了 Nginx 和客户端两端的网络连接状态，使用 `ss -nt` 命令可以在 Nginx 看到大量 ESTABLISH 状态连接的 Send-Q 堆积很大，客户端的 Recv-Q 堆积很大。Nginx 端的 ss 部分输出如下所示  State Recv-Q Send-Q Local Address:Port Peer Address:Port ESTAB 0 792024 1.1.1.1:80 2.2.2.2:50664 \u0026hellip;\n如果不是listen套接字 这里的Send-Q就是发送缓冲区的大小 说明nginx发给客户端的缓冲区太大了\n - 在 jmeter 客户端抓包偶尔可以看到较多零窗口，如下所示。 ![](http://heketong.github.io/donate/nginxOOM_排查客户端抓包分析.jpg) 到了这里有了一些基本的方向，首先怀疑的就是 jmeter 客户端处理能力有限，有较多消息堆积在中转的 Nginx 这里。 - 为了验证想法，想办法 dump 一下 nginx 的内存看看。因为在后期内存占用较高的状况下，dump 内存很容易失败，这里在内存刚开始上涨没多久的时候开始 dump。 首先使用 pmap 查看其中任意一个 worker 进程的内存分布，这里是 4199，使用 pmap 命令的输出如下所示。  pmap -x 4199 | sort -k 3 -n -r 00007f2340539000 475240 461696 461696 rw\u0026mdash; [ anon ] \u0026hellip;\n 随后使用 `cat /proc/4199/smaps | grep 7f2340539000` 查找某一段内存的起始和结束地址，如下所示。  cat /proc/3492/smaps | grep 7f2340539000\n7f2340539000-7f235d553000 rw-p 00000000 00:00 0\n 随后使用 gdb 连上这个进程，dump 出这一段内存。  gdb -pid 4199\ndump memory memory.dump 0x7f2340539000 0x7f235d553000\n 随后使用 strings 命令查看这个 dump 文件的可读字符串内容，可以看到是大量的请求和响应内容。 这样坚定了是因为缓存了大量的消息导致的内存上涨。随后看了一下 Nginx 的参数配置  location / { proxy_pass http://xxx; proxy_set_header X-Forwarded-Url \u0026ldquo;$scheme://$host$request_uri\u0026rdquo;; proxy_redirect off; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026ldquo;upgrade\u0026rdquo;; proxy_set_header Cookie $http_cookie; proxy_set_header Host $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 512M; client_body_buffer_size 64M; proxy_connect_timeout 900; proxy_send_timeout 900; proxy_read_timeout 900; proxy_buffer_size 64M; proxy_buffers 64 16M; proxy_busy_buffers_size 256M; proxy_temp_file_write_size 512M; }\n 可以看到 proxy_buffers 这个值设置的特别大。可以模拟重现： ![](http://heketong.github.io/donate/nginxOOM问题排查_重现.jpg) ### 解决方案 因为要支持上百万的连接，针对单个连接的资源配额要小心又小心。一个最快改动方式是把 proxy_buffering 设置为 off，如下所示。  proxy_buffering off; ```\n经过实测，在压测环境修改了这个值以后，以及调小了 proxy_buffer_size 的值以后，内存稳定在了 20G 左右，没有再飙升过.\n后面可以开启 proxy_buffering，调整 proxy_buffers 的大小可以在内存消耗和性能方面取得更好的平衡\n Nginx 的 buffering 机制设计的初衷确实是为了解决收发两端速度不一致问题的，没有 buffering 的情况下，数据会直接从后端服务转发到客户端，如果客户端的接收速度足够快，buffering 完全可以关掉。但是这个初衷在海量连接的情况下，资源的消耗需要同时考虑进来，如果有人故意伪造比较慢的客户端，可以使用很小的代价消耗服务器上很大的资源。 其实这是一个非阻塞编程中的典型问题，接收数据不会阻塞发送数据，发送数据不会阻塞接收数据。如果 Nginx 的两端收发数据速度不对等，缓冲区设置得又过大，就会出问题了。  思考 有过程中一些辅助的判断方法，比如通过 strace、systemtap 工具跟踪内存的分配、释放过程，这里没有展开，这些工具是分析黑盒程序的神器。\n除此之外，在这次压测过程中还发现了 worker_connections 参数设置不合理导致 Nginx 启动完就占了 14G 内存等问题，这些问题在没有海量连接的情况下是比较难发现的。\n最后，底层原理是必备技能，调参是门艺术。\n","id":2,"section":"posts","summary":"相关历史及分成模型 历史介绍 1969年 美国担心敌人会摧毁自己的网络，所以国防部高级研究计划局（Advanced Research Projects Agency，ARPA）下决","tags":["TCP/IP"],"title":"TCP/IP","uri":"http://heketong.github.io/2020/05/tcp_ip/","year":"2020"},{"content":" 一些概念回顾 缓存穿透 概念： 缓存没有数据，而且数据库也没有数据。\n​ 当这种情况大量出现或被恶意攻击时，接口的访问全部透过Redis访问数据库，而数据库中也没有这些数据，我们称这种现象为\u0026rdquo;缓存穿透\u0026rdquo;。缓存穿透会穿透Redis的保护，提升底层数据库的负载压力，同时这类穿透查询没有数据返回也造成了网络和计算资源的浪费。\n一般解决方案  如果Redis内不存在该数据，则通过布隆过滤器判断数据是否在底层数据库内； 如果布隆过滤器告诉我们该key在底层库内不存在，则直接返回null给客户端即可，避免了查询底层数据库的动作； 如果布隆过滤器告诉我们该key极有可能在底层数据库内存在，那么将查询下推到底层数据库即可\n布隆过滤器有误判率，虽然不能完全避免数据穿透的现象，但已经可以将绝大部份的的穿透查询给屏蔽在Redis层了，极大的降低了底层数据库的压力，减少了资源浪费。   缓冲击穿 概念  一般是指缓存没有但是数据库有的数据。 比如热点数据失效，导致大量合法热点请求打向数据库，此时数据库压力山大  一般解决方案：  延长热点key的过期时间或者设置永不过期，如排行榜，首页等一定会有高并发的接口； 利用互斥锁保证同一时刻只有一个客户端可以查询底层数据库的这个数据，一旦查到数据就缓存至Redis内，避免其他大量请求同时穿过Redis访问底层数据库。  缓存雪崩 概念 缓存雪崩时缓存击穿的加强版，大量的key几乎同时过期，然后大量并发查询穿过redis击打到底层数据库上，此时数据库层的负载压力会骤增，我们称这种现象为\u0026rdquo;缓存雪崩\u0026rdquo;。\n一般解决方案 缓存预热 ​ 缓存预热如字面意思，当系统上线时，缓存内还没有数据，如果直接提供给用户使用，每个请求都会穿过缓存去访问底层数据库，\n如果并发大的话，很有可能在上线当天就会宕机，因此我们需要在上线前先将数据库内的热点数据缓存至Redis内再提供出去使用，\n这种操作就成为\u0026rdquo;缓存预热\u0026rdquo;。缓存预热的实现方式有很多，比较通用的方式是写个批任务，在启动项目时或定时去触发将底层数据库内的热点数据加载到缓存内。\n缓存更新 ​ 缓存服务（Redis）和数据服务（底层数据库）是相互独立且异构的系统，在更新缓存或更新数据的时候无法做到原子性的同时更新两边的数据，因此在并发读写或第二步操作异常时会遇到各种数据不一致的问题。如何解决并发场景下更新操作的双写一致是缓存系统的一个重要知识点。\n第二步操作异常：缓存和数据的操作顺序中，第二个动作报错。如数据库被更新， 此时失效缓存的时候出错，缓存内数据仍是旧版本；  缓存更新的设计模式有四种：\nCache aside：查询：先查缓存，缓存没有就查数据库，然后加载至缓存内；更新：先更新数据库，然后让缓存失效；或者先失效缓存然后更新数据库；\nRead through：在查询操作中更新缓存，即当缓存失效时，Cache Aside 模式是由调用方负责把数据加载入缓存，而 Read Through 则用缓存服务自己来加载；\nWrite through：在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后由缓存自己更新数据库；\nWrite behind caching：俗称write back，在更新数据的时候，只更新缓存，不更新数据库，缓存会异步地定时批量更新数据库；\nCache aside：\n 为了避免在并发场景下，多个请求同时更新同一个缓存导致脏数据，因此不能直接更新缓存而是另缓存失效。\n 先更新数据库后失效缓存：并发场景下，推荐使用延迟失效（写请求完成后给缓存设置1s过期时间），在读请求缓存数据时若redis内已有该数据（其他写请求还未结束）则不更新。当redis内没有该数据的时候（其他写请求已另该缓存失效），读请求才会更新redis内的数据。这里的读请求缓存数据可以加上失效时间，以防第二步操作异常导致的不一致情况。\n 先失效缓存后更新数据库：并发场景下，推荐使用延迟失效（写请求开始前给缓存设置1s过期时间），在写请求失效缓存时设置一个1s延迟时间，然后再去更新数据库的数据，此时其他读请求仍然可以读到缓存内的数据，当数据库端更新完成后，缓存内的数据已失效，之后的读请求会将数据库端最新的数据加载至缓存内保证缓存和数据库端数据一致性；在这种方案下，第二步操作异常不会引起数据不一致，例如设置了缓存1s后失效，然后在更新数据库时报错，即使缓存失效，之后的读请求仍然会把更新前的数据重新加载到缓存内。\n 推荐使用先失效缓存，后更新数据库，配合延迟失效来更新缓存的模式；   四种缓存更新模式的优缺点：\n Cache Aside：实现起来较简单，但需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）； Read/Write Through：只需要维护一个数据存储（缓存），但是实现起来要复杂一些； Write Behind Caching：与Read/Write Through 类似，区别是Write Behind Caching的数据持久化操作是异步的，但是Read/Write Through 更新模式的数据持久化操作是同步的。优点是直接操作内存速度快，多次操作可以合并持久化到数据库。缺点是数据可能会丢失，例如系统断电等。\n缓存本身就是通过牺牲强一致性来提高性能，因此使用缓存提升性能，就会有数据更新的延迟性。这就需要我们在评估需求和设计阶段根据实际场景去做权衡了。   缓存降级 ​\t缓存降级是指当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，即使是有损部分其他服务，仍然需要保证主服务可用。可以将其他次要服务的数据进行缓存降级，从而提升主服务的稳定性。\n降级的目的是保证核心服务可用，即使是有损的。如去年双十一的时候淘宝购物车无法修改地址只能使用默认地址，这个服务就是被降级了，这里阿里保证了订单可以正常提交和付款，但修改地址的服务可以在服务器压力降低，并发量相对减少的时候再恢复。\n降级可以根据实时的监控数据进行自动降级也可以配置开关人工降级。是否需要降级，哪些服务需要降级，在什么情况下再降级，取决于大家对于系统功能的取舍。\nCAP CAP定理是加州大学的计算机科学家 Eric Brewer 在 1998年提出，也就是下面的3个英文单词， 原始的CAP理论有非常精准的定义，讨论的范围其实也有非常有局限性，现在大家讨论的CAP其实跟原始的有不少地方是不一致，下面讨论的也是被大家讨论的一些内容。\nCAP更多的是关注数据，而不是整个系统，实际项目中往往要处理各种数据，有些数据要求更多的一致性，有些数据要求更多的可用性，如果武断的说要CP还是AP往往是比较难的。\n Consistency 一致性 (读写数据的一致性)   简单理解就是多个数据实例的数据要保证一致，这里又可以用很多个粒度，比如强一致性，最终一致性等等\n 实际数据同步时候往往不能忽略网络延迟，相同机房可能几毫秒同步完成，远距离的跨机房可能要几十毫秒甚至更多，所以有些非常关键的数据要求必须一致的时候往往把P扔了，只能单点写入，其它节点做备份。\n Availability 可用性(服务高可用性)\n 客户端发送一个请求，必须给出正确回应，所以说起高可用，往往不是单点的，是多节点的服务，因为单点如果出现故障则整个系统挂掉，根本没法向外提供服务 对应上面的图来说 也就是往往有G1 G2 往往还会有Gn等多个实例提供服务   Partition tolerance 分区容错性\n 分布式系统，正常情况下多个节点之间是可以互通的，但不是讨论的范围，P讨论的如果出现故障，节点之间不能互通，所以整个网络就被分成了多块区域，而数据就是分散在这些不能连通的区域中，这个称为分区。容错的意思就是分区了(不能互相连通)也要能给提供服务，让客户端正常访问，不能出现单点故障。   为什么要P非要在C和A之间做取舍\n 拿上面的G1 G2例子来说，如果必须A：要求必须实现一致性，则网络不通G2就要停止对外提供服务  因为要C，G1改为v1 G2也必须改为v1,但是如果说P 也就是G1不能给G2发消息的情况(网络不通)，G2无法实现数据同步而保持一致性，所以这个时候就要让G2停止对外提供服务，因为数据不一致了，不能对外提供服务。\n如果G2不能对外提供服务，此时G1挂掉了，就没有节点能给对外提供服务了，也就是没有高可用了 也就是没有了A\n 反过来说也是一样的 如果就是要A，也就是不要一致性了，必须保证服务高可用，G1挂掉了 G2数据虽然数据不是最新的(存在数据不一致)，也必须让G2对外提供服务，所以这个时候就是舍弃了C(放弃数据一致性)  实际项目往往不是非常粗暴的舍弃A或者C，这里的舍弃往往只是非常短时间的舍弃。因为讨论舍弃C/A的前提是P出错了，也就是节点之间不能互通了，分区出现故障了，这个时间往往是比较短暂的，等分区故障恢复后往往就可以CA了。另外针对不同的数据往往也会选择不同的策略。\n  比如一般用户账号数据(id 密码)往往是要求一致性更多点，但其它一些信息数据(昵称、兴趣)等可能要求可用性更多些\nACID ACID 是数据库管理系统为了保证事务的正确性而提出来的一个理论，ACID 包含四个约束，下面我来解释一下。\nAtomicity（原子性）\n一个事务中的所有操作，要么全部完成，要么全部不完成，不会在中间某个环节结束。事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样。\nConsistency（一致性）\n在事务开始之前和事务结束以后，数据库的完整性没有被破坏。\nIsolation（隔离性）\n数据库允许多个并发事务同时对数据进行读写和修改的能力。隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。\nDurability（持久性）\n事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。\n可以看到，ACID 中的 A（Atomicity）和 CAP 中的 A（Availability）意义完全不同，而 ACID 中的 C 和 CAP 中的 C 名称虽然都是一致性，但含义也完全不一样。ACID 中的 C 是指数据库的数据完整性，而 CAP 中的 C 是指分布式节点中的数据一致性。再结合 ACID 的应用场景是数据库事务，CAP 关注的是分布式系统数据读写这个差异点来看，其实 CAP 和 ACID 的对比就类似关公战秦琼，虽然关公和秦琼都是武将，但其实没有太多可比性。\nBASE BASE 是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency），核心思想是即使无法做到强一致性（CAP 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性。\n基本可用（Basically Available）\n分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。\n这里的关键词是“部分”和“核心”，具体选择哪些作为可以损失的业务，哪些是必须保证的业务，是一项有挑战的工作。例如，对于一个用户管理系统来说，“登录”是核心功能，而“注册”可以算作非核心功能。因为未注册的用户本来就还没有使用系统的业务，注册不了最多就是流失一部分用户，而且这部分用户数量较少。如果用户已经注册但无法登录，那就意味用户无法使用系统。例如，充了钱的游戏不能玩了、云存储不能用了……这些会对用户造成较大损失，而且登录用户数量远远大于新注册用户，影响范围更大。\n软状态（Soft State）\n允许系统存在中间状态，而该中间状态不会影响系统整体可用性。这里的中间状态就是 CAP 理论中的数据不一致。\n最终一致性（Eventual Consistency）\n系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。\n这里的关键词是“一定时间” 和 “最终”，“一定时间”和数据的特性是强关联的，不同的数据能够容忍的不一致时间是不同的。举一个微博系统的例子，用户账号数据最好能在 1 分钟内就达到一致状态。因为用户在 A 节点注册或者登录后，1 分钟内不太可能立刻切换到另外一个节点，但 10 分钟后可能就重新登录到另外一个节点了，而用户发布的最新微博，可以容忍 30 分钟内达到一致状态。因为对于用户来说，看不到某个明星发布的最新微博，用户是无感知的，会认为明星没有发布微博。“最终”的含义就是不管多长时间，最终还是要达到一致性的状态。\nBASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。前面在剖析 CAP 理论时，提到了其实和 BASE 相关的两点：\n CAP 理论是忽略延时的，而实际应用中延时是无法避免的。  这一点就意味着完美的 CP 场景是不存在的，即使是几毫秒的数据复制延迟，在这几毫秒时间间隔内，系统是不符合 CP 要求的。因此 CAP 中的 CP 方案，实际上也是实现了最终一致性，只是“一定时间”是指几毫秒而已。\n AP 方案中牺牲一致性只是指分区期间，而不是永远放弃一致性。  这一点其实就是 BASE 理论延伸的地方，分区期间牺牲一致性，但分区故障恢复后，系统应该达到最终一致性\n分布式锁 Mysql锁 方式 ​\t使用数据库的唯一索引特性，获取锁就是插入一条记录(唯一索引保证只能插入一次)，释放锁就是删除这条记录\n优点 ​\t使用非常简单 开发难度很低\n缺点  锁没有失效时间 如果应用拿到锁之后挂掉，导致锁无法正常释放，那么其它应用就再也拿不到锁，业务无法开展。 没有拿到锁的应用需要不停的检查锁是否已经释放(记录是否存在)，这样比较浪费cpu资源，也会给数据库压力\n 如果搞一个监控程序监视锁，控制超时时间，超过时间就强制删除锁，一来这里的超时时间不好控制，而来监控程序也可能挂掉 还是存在锁无法释放的风险。\n  Redis分布式锁 方式1__setnx key value \u0026gt; setnx lock:codehole true //使用setnx(set if not exists) 指令。在redis里面占坑 谁占到了就是抢锁成功 OK ... do something critical ... \u0026gt; del lock:codehole //使用del 命令释放锁 (integer) 1 ------------------------问题-------------------- 1. 中间的处理逻辑如果出现异常，比如程序死掉了，会导致无法调用del命令，也就是锁无法释放 2. 应用可以强制抢锁，因为谁都可以上来直接del 这本身是不安全了 3. 锁释放了 其它应用不知道，所以只能不停的查询锁释放还在，浪费资源  方式2__set key value ex timeout nx \u0026gt; set lock:codehole true ex 5 nx //setnx升级版 加上了设置超时时间 而且redis支持这2个功能为原子操作 过了一定时间应用不释放 redis强制释放锁 ... do something critical ... \u0026gt; del lock:codehole ------------------------问题-------------------- 1. 超时时间不好设置 如果过长 会导致一旦持有锁的应用挂掉了 很长一段时间 业务无法继续 2. 超时时间太短 业务逻辑还没有执行完成，锁就被redis强制释放，其它应用就会重新持有这把锁，这样就没法保证临界区的代码严格串行 ---比如秒杀商品超买问题 3. 应用可以强制抢锁，因为谁都可以上来直接del 这本身是不安全了(应用超时后业务逻辑处理完毕 也会误删锁 下面有例子) 4. 锁释放了 其它应用不知道，所以只能不停的查询锁释放还在，浪费资源     时间线 线程1 线程2 线程3     时刻1 执行 setnx mylock val1 加锁 执行 setnx mylock val2 加锁 执行 setnx mylock val2 加锁   时刻2 加锁成功 加锁失败 加锁失败   时刻3 执行任务\u0026hellip; 尝试加锁\u0026hellip; 尝试加锁\u0026hellip;   时刻4 任务继续（锁超时，自动释放了） setnx 获得了锁（因为线程1的锁超时释放了） 仍然尝试加锁\u0026hellip;   时刻5 任务完毕，del mylock 释放锁 执行任务中\u0026hellip; 获得了锁（因为线程1释放了线程2的）    方式3__set lockKey randomNum ex timeout nx 删除的时候匹配随机数 其它应用误删锁 大致逻辑如下： 1. 线程1 准备释放锁 ， 锁的key 为 mylock 锁的 value 为 thread1_magic_num 2. 查询当前锁 current_value = get mylock 3. 判断 if current_value == thread1_magic_num -- \u0026gt; 是 我（线程1）的锁 else -- \u0026gt;不是 我（线程1）的锁 4. 是我的锁就释放，否则不能释放（而是执行自己的其他逻辑）。   因为上述的逻辑直接使用redis命令无法做到原子性 所以直接使用比较危险 可以用lua脚本实现(redis执行lua脚本是原子的 要么都成功 要么都失败)\nif redis.call('get', lockKey) == randomNum加锁时候的随机数 then return redis.call('del', lockKey) else return 0 end  问题：\n 超时时间还是不好设置的问题，还是无法解决逻辑执行时间长，导致锁超时被redis强制释放，其它线程抢锁成功，同时执行临界区代码的问题   方式4: redlock ​\t上述3种方式都有一个共同的问题 就是如果redis是单点的，不是集群的，一旦redis节点挂点就不能够对外提供服务了。\n如果是集群的话，例如redis sentinel集群中，我们具有多台redis，他们之间有着主从的关系，例如一主二从，set命令对应的数据写到主库，然后同步到从库。当我们申请一个锁的时候，对应就是一条命令 setnx mykey myvalue ，在redis sentinel集群中，这条命令先是落到了主库。假设这时主库down了，而这条数据还没来得及同步到从库，sentinel将从库中的一台选举为主库了。这时，我们的新主库中并没有mykey这条数据，若此时另外一个client执行 setnx mykey hisvalue , 也会成功，即也能得到锁。这就意味着，此时有两个client获得了锁。虽然这个情况发生的记录很小，只会在主从failover的时候才会发生，大多数情况下、大多数系统都可以容忍，但是不是所有的系统都能容忍这种瑕疵。\n原理： 为了解决故障转移情况下的缺陷，Antirez 发明了 Redlock 算法，使用redlock算法，需要多个redis实例，加锁的时候，它会想多半节点发送 setex mykey myvalue 命令，只要过半节点成功了，那么就算加锁成功了。释放锁的时候需要想所有节点发送del命令。这是一种基于【大多数都同意】的一种机制。感兴趣的可以查询相关资料。在实际工作中使用的时候，我们可以选择已有的开源实现，python有redlock-py，java 中有Redisson redlock。\nredlock确实解决了上面所说的“不靠谱的情况”。但是，它解决问题的同时，也带来了代价。你需要多个redis实例，你需要引入新的库 代码也得调整，性能上也会有下降。\n总结 ​\t总体来讲方式3用的比较多，相对比较安全，但要根据实际业务场景适当设置超时时间，过长过短都不好。\n​ 应用一定要捕捉异常，如果出现异常一定要释放锁。\n​\t如果因为业务逻辑执行过长，redis超时强制删除了锁，自己释放锁的时候发现不是自己的锁了，也要根据实际情况做相应的处理，比如回滚之类的。\nZookeeper分布式锁 Zookeeper节点类型  永久性节点(有序和无序)  不会因为会话结束或者超时而消失，\n有序的话 会在节点名的后面加一个数字后缀，并且是有序的，例如生成的有序节点为 /lock/node-0000000000，它的下一个有序节点则为 /lock/node-0000000001，依次类推\n 临时性节点(有序和无序)  如果会话结束或者超时就会消失。\n​\tZookeeper有节点变化通知其它客户端的特性  客户端可以针对某一个zk节点(目录 但可以有数据)设置监控事件(可以是节点变更、删除等等)和对应处理方法 当对应的zk节点发生变化 会通知客户端进行影响处理  利用临时有序节点和事件通知特性实现分布式锁  创建一个锁目录 /lock； 在 /lock 下创建临时的且有序的子节点\n Client1对应的子节点为/lock/lock-0000000000,Clinet2为/lock/lock-0000000001 \u0026hellip;..\n 每个client都查询目录下的所有节点列表 判断自己释放为数字最小的节点\n  3.1 是则加锁成功 进行业务处理，处理完毕 删除对应lock下的子节点\n3.2 不是最小节点 则监听自己的前一个节点 等待前一个节点处理完毕后通知自己\n 如果持有锁的节点死掉了 会话超时临时节点会被zk删除 也就是释放了锁  redis 5种数据类型 ​\t内部使用一个redisObject对象来表示所有的key和value，redisObject最主要的信息如上图所示：type代表一个value对象具体是何种数据类型，encoding是不同数据类型在redis内部的存储方式，比如：type=string代表value存储的是一个普通字符串，那么对应的encoding可以是raw或者是int，如果是int则代表实际redis内部是按数值型类存储和表示这个字符串的，当然前提是这个字符串本身可以用数值表示，比如:\u0026ldquo;123\u0026rdquo; \u0026ldquo;456\u0026rdquo;这样的字符串。\nstring 字符串类型 最基本的数据类型，可以保存字符串、数字、二进制，本身是二进制安全的。\n常用操作命令 保存为字符串操作相关：\nset key value #设置字符串key的值为value append key value #在原先字符串后面追加 strlen key #查看key这个字符串的长度 setrange key offset value #Overwrite part of a string at key starting at the specified offset 改变字符串某一位的值 getrange key start end #Get a substring of the string stored at a key 获取子串 setnx key value 如果不存在则设置kv 存在不设置 SET key value [expiration EX seconds|PX milliseconds] [NX|XX] #设置kv 并且设置超时时间 往往用在分布式锁 NX表示如果存在则不能设置 不覆盖 mset mget一次设置多个kv 一次获取多个kv  保存为数字的操作相关\nincr key # Increment the integer value of a key by one INCRBY key increment #Increment the integer value of a key by the given amount DECR key #Decrement the integer value of a key by one DECRBY key decrement # Decrement the integer value of a key by the given number  保存为二进制位的相关操作\nsetbit key offset value #Sets or clears the bit at offset in the string value stored at key #offset如果超过本身长度 会动态的扩 非offset的位置都是0 如果要get的话 可能出现乱码 BITCOUNT key [start end] #Count set bits in a string 这里的start end指的是字节 不是每个自己里面的offset BITOP operation destkey key [key ...] #位操作 127.0.0.1:6379\u0026gt; setbit k1 1 1 127.0.0.1:6379\u0026gt; setbit k1 7 1 127.0.0.1:6379\u0026gt; get k1 k1的二进制位 0100 0001 \u0026quot;A\u0026quot; 127.0.0.1:6379\u0026gt; setbit k2 1 1 127.0.0.1:6379\u0026gt; setbit k2 6 1 127.0.0.1:6379\u0026gt; get k2 k1的2的二进制位 0100 0010 \u0026quot;B\u0026quot; 想执行 k1\u0026amp;k2 127.0.0.1:6379\u0026gt; bitop and result k1 k2 (integer) 1 127.0.0.1:6379\u0026gt; get result \u0026quot;@\u0026quot; result是@ 对应二进制位 0100 0000 bitop and|or|xor|not  应用场景  session共享 kv缓冲 计数器：微博数、粉丝数 小文件系统 key：文件名 value: 具体数据 bitmap的一些使用场景：  布隆过滤器 记录一个人一年的登录情况 可以用365个位表示 哪一天登陆了就设置为1 等等 统计活跃用户数之类的 每天一个key 记录每一天每个用户登陆请求(映射到每一位) 然后每一天的key通过或运算   list ​\tredis实现的是双向循环链表 所以非常容易实现分布式队列或者分布式栈，也就是字符串链表，插入本身是有顺序的，第一个插入，取出第一个还是这个元素。\n常用操作命令 LPUSH key value [value ...] # Prepend one or multiple values to a list 每次都从左边头部压入链表 可以一次压入多个元素 LPOP key # Remove and get the first element in a list 从左边出弹出一个元素 对应的右端操作就是 RPUSH RPOP 只是每次都从右端操作 LRANGE key start stop #Get a range of elements from a list 获取某一个区间的元素列表 最右端支持为下标-1的下标计数 LTRIM key start stop #Trim a list to the specified range 删除 【start,stop】左边和右边的元素  应用场景  分布式队列和栈\n 将redis用作日志容器器 多个client将日志写入redis list，搞一个进程读取list写入磁盘\n 取最新的N个数据操作 比如最新的10条评论 最新登陆的10个用户id列表 超过这个范围的从数据库获取\n /把当前登录人添加到链表里 ret = r.lpush(\u0026quot;login:last_login_times\u0026quot;, uid) //保持链表只有N位 ret = redis.ltrim(\u0026quot;login:last_login_times\u0026quot;, 0, N-1) //获得前N个最新登陆的用户Id列表 last_login_list = r.lrange(\u0026quot;login:last_login_times\u0026quot;, 0, N-1)  分布式任务分发器\n 多个任务派发进程 将单个任务请求写入redis list\n 多个任务处理进程 从list中pop取任务处理\n  hash ​\t存放的value本身是是个hashmap 也就是一个string 类型的 field 和 value 的映射表\n​\t对数据的修改和存取都可以直接通过其内部Map的Key(Redis里称内部Map的key为field), 也就是通过 key(用户ID) + field(属性标签) 就可以操作对应属性数据了，既不需要重复存储数据，也不会带来序列化和并发修改控制的问题。\n​\t实现方式：上面已经说到Redis Hash对应Value内部实际就是一个HashMap，实际这里会有2种不同实现，这个Hash的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，对应的value redisObject的encoding为zipmap，当成员数量增大时会自动转成真正的HashMap，此时encoding为ht\n常用操作命令 ```\n  127.0.0.1:6379\u0026gt; hset infoid name hkt age 20 #key:infoid 对应value为map[name:hkt,age:20] HSET key field value #这里的infoid可以理解成c++语言的map名字 field理解为map的key value就是map[key]的值 127.0.0.1:6379\u0026gt; hget infoid name #获取infoid这个hashmap对应key为name的值 string name=infoid[name] \u0026ldquo;hkt\u0026rdquo; 127.0.0.1:6379\u0026gt; hget infoid age #获取infoid这个hashmap对应key为age的值 int age=infoid[age] \u0026ldquo;20\u0026rdquo; 127.0.0.1:6379\u0026gt; hset infoid age 30 #修改infoid这个hashmap对应key为age的值 infoid[age]=30 127.0.0.1:6379\u0026gt; hget infoid age \u0026ldquo;30\u0026rdquo; 127.0.0.1:6379\u0026gt; hgetall infoid #获取infoid这个hashmap所有的key和value 现实项目不常用 因为比较耗时 1) \u0026ldquo;name\u0026rdquo; 2) \u0026ldquo;hkt\u0026rdquo; 3) \u0026ldquo;age\u0026rdquo; 4) \u0026ldquo;30\u0026rdquo; 127.0.0.1:6379\u0026gt; hkeys infoid #获取infoid这个hashmap对应的所有key 1) \u0026ldquo;name\u0026rdquo; 2) \u0026ldquo;age\u0026rdquo; 127.0.0.1:6379\u0026gt; hvals infoid #获取infoid这个hashmap对应的所有value 1) \u0026ldquo;hkt\u0026rdquo; 2) \u0026ldquo;30\u0026rdquo;\n #### 应用场景 - 聚集一些相关的数据做缓存(频繁访问不怎么修改的，但彼此有相关 比如用户信息 粉丝 关注等等) - 商品详情页的多个tab页面也可以缓存到hash中 ### set ​\t集合、无序(插入也是没有顺序)、没有重复 ，底层就是hashmap 只是value为null,可以支持数学上的交集、并集、查集操作 #### 常用命令  127.0.0.1:6379\u0026gt; sadd set1 a b c d 添加元素 a b c d到集合set1 (integer) 4 127.0.0.1:6379\u0026gt; sadd set2 b c d e (integer) 4 127.0.0.1:6379\u0026gt; scard set1 #获取set1集合数量 (integer) 4 127.0.0.1:6379\u0026gt; smembers set1 #获取集合set1中所有的成员 1) \u0026ldquo;b\u0026rdquo; 2) \u0026ldquo;a\u0026rdquo; 3) \u0026ldquo;d\u0026rdquo; 4) \u0026ldquo;c\u0026rdquo; 127.0.0.1:6379\u0026gt; sinter set1 set2 #取2个集合的交集 1) \u0026ldquo;b\u0026rdquo; 2) \u0026ldquo;d\u0026rdquo; 3) \u0026ldquo;c\u0026rdquo; 127.0.0.1:6379\u0026gt; sdiff set1 set2 #取2个集合的差集 set1有 set2没有 1) \u0026ldquo;a\u0026rdquo; 127.0.0.1:6379\u0026gt; sdiff set2 set1 #取2个集合的差集 set2有 set1没有 1) \u0026ldquo;e\u0026rdquo; 127.0.0.1:6379\u0026gt; sunion set1 set2 #取2个集合的并集 不保存到redis 1) \u0026ldquo;b\u0026rdquo; 2) \u0026ldquo;a\u0026rdquo; 3) \u0026ldquo;d\u0026rdquo; 4) \u0026ldquo;c\u0026rdquo; 5) \u0026ldquo;e\u0026rdquo; 127.0.0.1:6379\u0026gt; sunionstore set3 set1 set2 #取2个集合的并集 保存到redis (integer) 5 127.0.0.1:6379\u0026gt; smembers set3 1) \u0026ldquo;b\u0026rdquo; 2) \u0026ldquo;a\u0026rdquo; 3) \u0026ldquo;d\u0026rdquo; 4) \u0026ldquo;c\u0026rdquo; 5) \u0026ldquo;e\u0026rdquo; 127.0.0.1:6379\u0026gt; sismember set1 a #是否在某个集合当中 (integer) 1 127.0.0.1:6379\u0026gt; srandmember set3 #随机返回集合中的某一个元素 \u0026ldquo;c\u0026rdquo; 127.0.0.1:6379\u0026gt; srandmember set3 3 #随机返回集合中的多个元素 如果大于集合总个数 也只能返回集合总个数 1) \u0026ldquo;b\u0026rdquo; 2) \u0026ldquo;a\u0026rdquo; 3) \u0026ldquo;e\u0026rdquo; 127.0.0.1:6379\u0026gt; srandmember set3 -7 #随机返回集合中的多个元素 如果大于集合个数 会出现重复 但个数是你所要求的 1) \u0026ldquo;a\u0026rdquo; 2) \u0026ldquo;b\u0026rdquo; 3) \u0026ldquo;a\u0026rdquo; 4) \u0026ldquo;a\u0026rdquo; 5) \u0026ldquo;c\u0026rdquo; 6) \u0026ldquo;e\u0026rdquo; 7) \u0026ldquo;e\u0026rdquo; 127.0.0.1:6379\u0026gt; spop set1 #随机删除一个元素 \u0026ldquo;d\u0026rdquo; 127.0.0.1:6379\u0026gt; srem set1 b #指定删除某一个元素 (integer) 1\n #### 应用场景 - 分布式去重 向redis某个set里面不断扔数据就可以了 - 分布式并查集计算 - 案例：在微博中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis还为集合提供了求交集、并集、差集等操作，可以非常方便的实现如共同关注、共同喜好、二度好友等功能，对上面的所有集合操作，你还可以使用不同的命令选择将结果返回给客户端还是存集到一个新的集合中 - 随机抽奖 随机验证码等等 ### zset ​\t集合、不重复、有序，sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，如果需要一个有序的不重复的集合可以选择zset。和Set相比，**Sorted Set关联了一个double类型权重参数score**，使得集合中的元素能够按score进行有序排列，redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复 ​\t实现方式：Redis sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序，HashMap里放的是成员到score的映射，而跳跃表里存放的是所有的成员，排序依据是HashMap里存的score,使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单 #### 常用命令  127.0.0.1:6379\u0026gt; zadd zset 100 hkt 99 wxl 98 hyx #往zset有序集合添加3个内容 hkt 100分 wxl 99分 hyx 98分 (integer) 3 127.0.0.1:6379\u0026gt; zrange zset 0 -1 #列出全部元素 也可以加上withscores就会把分数返回 1) \u0026ldquo;hyx\u0026rdquo; 2) \u0026ldquo;wxl\u0026rdquo; 3) \u0026ldquo;hkt\u0026rdquo; 127.0.0.1:6379\u0026gt; zscore zset hkt #获取某个成员的分数 \u0026ldquo;200\u0026rdquo; ZREM key member #删除某个成员 ZREVRANGE key start stop # with scores ordered from high to low 也就是将序 默认是升序 127.0.0.1:6379\u0026gt; zpopmin zset #弹出最小的元素 1) \u0026ldquo;hyx\u0026rdquo; 2) \u0026ldquo;98\u0026rdquo; 127.0.0.1:6379\u0026gt; zpopmax zset #弹出最大的元素 1) \u0026ldquo;hkt\u0026rdquo; 2) \u0026ldquo;200\u0026rdquo;\n127.0.0.1:6379\u0026gt; zrangebyscore zset 60 80 withscores #列出某个分数范围的元素集合 1) \u0026ldquo;dsds\u0026rdquo; 2) \u0026ldquo;77\u0026rdquo; zincrby zset 10 hkt #给hkt加10分 zincrby zset -10 hkt #给hkt减10分 127.0.0.1:6379\u0026gt; zrank zset hkt #从小到大升序 查看排名情况 (integer) 3 127.0.0.1:6379\u0026gt; zrevrank zset hkt #从大到小 降序查看排名情况 (integer) 0\n #### 应用场景 - 排行榜 - 带权重的消息队列 ## 常用命令  nc localhost 6379 #如果没有cli脚本 可以直接使用nc命令与redis交互 keys * #列出所有的key 生产一般不用 help @generic #查看帮助 flushall #删除所有数据 help @string #查看字符串的相关本地方法帮助文档 help @list help @hash help @set help @sorted_set 127.0.0.1:6379\u0026gt; type k1 #查看类型 string 127.0.0.1:6379\u0026gt; object encoding k1 #查看编码 \u0026ldquo;raw\u0026rdquo; ```\n","id":3,"section":"posts","summary":"一些概念回顾 缓存穿透 概念： 缓存没有数据，而且数据库也没有数据。 ​ 当这种情况大量出现或被恶意攻击时，接口的访问全部透过Redis访问数据库，而","tags":["分布式"],"title":"分布式","uri":"http://heketong.github.io/2020/05/%E5%88%86%E5%B8%83%E5%BC%8F/","year":"2020"},{"content":" 时间复杂度 常数时间操作O(1)  操作时间是固定的次数，跟数据量本身没有关系，就是其时间复杂度是O(1),比如总是比较1次或者3次，比如总是累加3次，总是赋值3次等等，无论样本数据量是多少，总是如此，我们就说起操作时间是常数时间，也就是O(1)\n 实际评估过程中一般是循环多多少次，比较了多少次等等计算出一个表达式，然后对于表达式只要高阶项，不要低阶项，也不要高阶项的系数，剩下的部分 如果记为f(N)，那么时间复杂度为O(f(N)). N为样本量\n 一个简单的例子：\n  比如计算出的表达式为f(N)=2$N^2$+3N+3 这里面的高阶项就是$N^2$，对应高阶项的系数就是2 低阶项就是3N和3 最后f(N)=$N^2$\n 算法流程的好坏，先看时间复杂度的指标，然后再分 析不同数据样本下的实际运行时间，也就是常数项时间  例子  一个有序数组A，另一个无序数组B，请打印B中的所有不在A中的数，A数 组长度为N，B数组长度为M。  算法流程1:对于数组B中的每一个数，都在A中通过遍历的方式找一下;\n算法流程2:对于数组B中的每一个数，都在A中通过二分的方式找一下;\n算法流程3:先把数组B排序，然后用类似外排的方式打印所有在A中出现 的数;\n代码实现及算法时间复杂度分析  三种算法代码实现 二分有递归和非递归 排序用的是归并递归实现\n// 一个**有序**数组A，另一个**无序**数组B，请打印B中的所有不在A中的数，A数 组长度为N，B数组长度为M。 // 算法流程1:对于数组B中的每一个数，都在A中通过遍历的方式找一下; // 算法流程2:对于数组B中的每一个数，都在A中通过二分的方式找一下; // 算法流程3:先把数组B排序，然后用类似外排的方式打印所有在A中出现 的数; #include\u0026lt;iostream\u0026gt; using namespace std; //打印数组 void printArray(int a[],int la){ cout\u0026lt;\u0026lt;\u0026quot;[\u0026quot;; for(int i=0;i\u0026lt;la;++i){ cout\u0026lt;\u0026lt;a[i]; if(i!=la-1) cout\u0026lt;\u0026lt;\u0026quot;,\u0026quot;; } cout\u0026lt;\u0026lt;\u0026quot;]\u0026quot;\u0026lt;\u0026lt;endl; } //二分查找toFind元素是否在A数组中 递归版本 bool binarySearchIsInARecur(int A[],int l,int r,int toFind){ //这里简单期间没做边界检查 if (l==r){//base case 如果区间只有一个元素 不用递归 直接返回是否是否相等即可 return A[l]==toFind; } bool isIn=false;//先初始化为不在数组中 int mid=l + ( (r-l)\u0026gt;\u0026gt;1 ); if (toFind\u0026lt;A[mid]){//如果小于A[mid] 那么就去A数组中 l---\u0026gt;mid-1区间查找 isIn=binarySearchIsInARecur(A,l,mid-1,toFind); }else if (toFind\u0026gt;A[mid]) { //如果大于A[mid] 那么就去A数组中 mid+1---\u0026gt;r 区间查找 isIn=binarySearchIsInARecur(A,mid+1,r,toFind); }else{ return true;//等于A[mid]直接返回true } return isIn; } //二分查找toFind元素是否在A数组中 非递归版本 bool binarySearchIsInA(int A[],int l,int r,int toFind){ //这里简单期间没做边界检查 while ( l \u0026lt;= r){ int mid=l + ( (r-l)\u0026gt;\u0026gt;1 ); if (toFind\u0026lt;A[mid]){//如果小于A[mid] 那么就去A数组中 l---\u0026gt;mid-1区间查找 r=mid-1; }else if ( toFind\u0026gt;A[mid]){//如果大于A[mid] 那么就去A数组中 mid+1--\u0026gt;r 区间查找 l=mid+1; }else{ return true; } } return false; } void printBNotInA1(int A[],int B[],int lenA,int lenB){ //暴力搜索 这里简单期间没做边界检查 for (int i=0;i\u0026lt;lenB;++i){ bool isInA=false; for (int j=0;j\u0026lt;lenA;++j){ if (B[i]==A[j]){ isInA=true; } } if(!isInA){ cout\u0026lt;\u0026lt;\u0026quot;use printBNotInA1:\u0026quot;\u0026lt;\u0026lt;B[i]\u0026lt;\u0026lt;\u0026quot; is not in A\u0026quot;\u0026lt;\u0026lt;endl; } } } void printBNotInA2(int A[],int B[],int lenA,int lenB){ //用二分查找的办法 判断是否在A数组中 for (int i=0;i\u0026lt;lenB;++i){ bool isInA=binarySearchIsInA(A,0,lenA-1,B[i]); if(!isInA){ cout\u0026lt;\u0026lt;\u0026quot;use printBNotInA2:\u0026quot;\u0026lt;\u0026lt;B[i]\u0026lt;\u0026lt;\u0026quot; is not in A\u0026quot;\u0026lt;\u0026lt;endl; } } } //将数组的 l---\u0026gt;mid mid+1---\u0026gt;r 2个排好序的分片合并 void merge2Slice(int a[],int l,int mid,int r){ int *help= new int[r-l+1];//声明1个辅助数组 合并后先放入help数组 然后在copy回原数组 int l1=l,r1=mid,l2=mid+1,r2=r;//便于理解 分割成为2个区间 l1--r1 l2--r2 int cur1=l1,cur2=l2,hIndex=0;//刚开始下标分别指向2个区间的开始位置 辅助数组的下标刚开始赋值为0 while (cur1\u0026lt;=r1 \u0026amp;\u0026amp; cur2\u0026lt;=r2 ){//任意1个区间遍历完成退出循环 if (a[cur1]\u0026lt;a[cur2]){ help[hIndex++]=a[cur1++];//谁小谁进辅助数组 同时下标++ }else{ help[hIndex++]=a[cur2++]; } } while (cur1\u0026lt;=r1){//区间1 还有数据没有复制到help数组 把剩下的全部复制到辅助数组 help[hIndex++]=a[cur1++]; } while ( cur2\u0026lt;=r2){//区间1 还有数据没有复制到help数组 把剩下的全部复制到辅助数组 help[hIndex++]=a[cur2++]; } //将help数组复制回原数组 for (int i=0;i\u0026lt;=(r-l);++i){ a[l+i]=help[i]; } delete[] help; return; } //归并排序递归实现 没做边界检查版本 void mergeSortRecur(int A[],int l,int r){ //base case 如果l==r 则直接返回即可 if (l==r){ return; } int mid=l + ( (r-l)\u0026gt;\u0026gt;1 ); mergeSortRecur(A,l,mid);//左半边归并排序 mergeSortRecur(A,mid+1,r);//右半边归并排序 merge2Slice(A,l,mid,r);//将2个分片合并 } void printBNotInA3(int A[],int B[],int lenA,int lenB){ //先用归并排序实现B数组的排序 再用外排的思想快速判断是否在A中 mergeSortRecur(B,0,lenB-1);//先归并排序 //外排 int curA=0,curB=0;//分别指向数组的第一个元素 while ( curB\u0026lt;=(lenB-1) \u0026amp;\u0026amp; curA\u0026lt;=(lenA-1)){ if ( B[curB]\u0026lt;A[curA]){//如果小于A数组的元素 那么肯定在A中不存在 打印并将B的下标往下移动 A下标不动 cout\u0026lt;\u0026lt;\u0026quot;use printBNotInA3:\u0026quot;\u0026lt;\u0026lt;B[curB]\u0026lt;\u0026lt;\u0026quot; is not in A\u0026quot;\u0026lt;\u0026lt;endl; curB++; }else if(B[curB]==A[curA]){//相等说明存在不打印 AB数组的下标都往下移动 curB++; curA++; }else{//如果大于A数组的元素 将A的下标往下移动 B的下标不动 curA++; } } } int main(){ int A[]={1,2,3,4,5,6,7,8,9}; int B[]={8,7,0,6,2,4,-1}; int l=0,mid=2,r=5; mergeSortRecur(B,0,6); // printArray(B,7); //cout\u0026lt;\u0026lt;binarySearchIsInA(A,0,8,0)\u0026lt;\u0026lt;endl; printBNotInA1(A,B,9,7); printBNotInA2(A,B,9,7); printBNotInA3(A,B,9,7); }  \n算法1  2层循环遍历 O(M*N)  算法2  也是2层循环 只不过第二层循环用二分查找 所以二分的复杂度为logN 总体为O(M*logN)  算法3  B归并排序 O(M*logM) 外排O(M+N) 总体为O(M*logM)+O(M+N)  算法1肯定是最差 算法2、3要看AB数组的样本量差距才能决定\nMaster公式计算递归时间复杂度 递归求数组中的最大值 #include\u0026lt;iostream\u0026gt; using namespace std; //master公式求解常见递归的时间复杂度 //求一个数组的最大值 递归实现 l为最小下标 r为最大下标 int getMax(int A[],int l,int r){ //base case 如果l==r 只有一个元素 直接返回该元素即可 if(l==r) return A[l]; int mid=l + ( (r-l)\u0026gt;\u0026gt;1 ); int maxL=getMax(A,l,mid);//得到左边的区间的最大值 int maxR=getMax(A,mid+1,r);//得到右边区间的最大值 return maxL\u0026gt;maxR?maxL:maxR; } int main(){ int A[]={8,7,0,6,2,4,-1}; cout\u0026lt;\u0026lt;\u0026quot;max in A=\u0026quot;\u0026lt;\u0026lt;getMax(A,0,6)\u0026lt;\u0026lt;endl; }  master公式T(N) = a*T(N/b) + O(N^d)\n log(b,a) \u0026gt; d -\u0026gt; 复杂度为O(N^log(b,a))\n log(b,a) = d -\u0026gt; 复杂度为O(N^d * logN)\n log(b,a) \u0026lt; d -\u0026gt; 复杂度为O(N^d)\n  N为样本量 b为每次把样本量分成多少分 在这里每次都分成2份 b=2\na为递归函数在逻辑代码中调用了几次，在本例中得到左边右边区间的最大值分别发生一次 总共为2次\n递归完成后的处理对应的时间复杂度为N的d次方，在这里递归完成后也就比较了一下maxL和maxR 返回器最大值 所以时间复杂为常数也就是N的d次方为1 所以d为0\n满足master公式1条件 所以时间复杂度为 N^log(2,2)=N 也就是O(N)\n冒泡排序 介绍 冒泡排序是一种比较简单的排序，之所以叫冒泡，是因为在两两比较的过程中较大的数就像冒泡一样被换到后面。详细解释：依次比较相邻的两个数，前面的数大于后面的数，则交换，将较大的数挪动到后面   第1轮: 比较1 \u0026ndash; N 经过依次相邻两两比较交换 最大的数则放到了最后 第2轮: 比较1 \u0026ndash;N-1 经过依次相邻两两比较交换 第2大的数则放到了N-1的位置 第N-1轮:比较1 \u0026ndash; 2 前2个数两两比较交换 整个过程完成  代码  BubbleSort\nfunc BubbleSort(a []int) { if len(a) \u0026lt; 2 { //一个数或者为空 不用排序 return } //外层循环控控制每轮循环两两比较的最大下标 第1次为N-1 最后一次为1(也就是最前面的2个元素) for endPos := len(a) - 1; endPos \u0026gt; 0; endPos-- { //内层循环完成两两比较交换 for i := 0; i \u0026lt; endPos; i++ { if a[i] \u0026gt; a[i+1] { a[i], a[i+1] = a[i+1], a[i] } } } }  \n时间复杂度 O($N^2$)  稳定性 **稳定** 因为如果2个数相等 则他们的相对位置 并没有发生改变  优化 看内层循环 如果并没有发生数据交换 则证明所有数据已经排序完成，这个时候直接结束即可 加一个标志判断即可   BubbleSortOpt\nfunc BubbleSort(a []int) { if len(a) \u0026lt; 2 { //一个数或者为空 不用排序 return } isChg := false //外层循环控控制每轮循环两两比较的最大下标 第1次为N-1 最后一次为1(也就是最前面的2个元素) for endPos := len(a) - 1; endPos \u0026gt; 0; endPos-- { //内层循环完成两两比较交换 for i := 0; i \u0026lt; endPos; i++ { if a[i] \u0026gt; a[i+1] { a[i], a[i+1] = a[i+1], a[i] isChg = true } } if !isChg { //如果内层循环没有发生数据交换 则表明所有数据都已经排序完成 直接退出循环即可 break } } }  \n网搜图解 摘自: https://www.cnblogs.com/onepixel/p/7674659.html  插入排序 介绍 插入排序顾名思义就是将一个待排序的元素，插入到一组已经排好序的元素中，如果形象比喻下，可以想象一下打牌，拿起来第一张牌自然就是排好序的，拿起第二张则跟第一张进行比较，插入到合适的位置。接下来拿第三张 跟前面2张已经排好序的比较，插入合适的位置，依次类推，拿完所有的牌，顺序自然也排好了。 将待排序的元素分为有序区和无序区，按照顺序每次从无序区拿一个元素，插入插入到有序区，直到所有无序区的元素都插入有序区，整个排序过程结束。第一次有序区为第1个元素，无序区为第2---N个元素，拿出第2个元素插入到有序区。  代码  InsertSort\nfunc InsertSort(a []int) { if len(a) \u0026lt; 2 { //一个数或者为空 不用排序 return } //j为无序区的第一个元素 对应下标从1开始，每次后移一个位置 for j := 1; j \u0026lt; len(a); j++ { //内层循环完成比较插入 倒序依次跟有序区的元素进行比较，如果小于有序区的元素 则交换 for i := j; i \u0026gt; 0; i-- { if a[i] \u0026lt; a[i-1] { a[i], a[i-1] = a[i-1], a[i] } } } }  \n时间复杂度 O($N^2$)  算法稳定性 **稳定** 没有改变两个相等元素的相对位置  优化 上面代码内层循环在查找待插入位置时是倒序逐个比较的，在查找待插入位置时候是可以优化的，**采用二分查找可以有效减少比较次数**，但**优化后的插入算法则变为不稳定的**   InsertSortOpt\n//BinSerachInsertIndex 二分查找在a数组 begin到end区间 key元素的插入位置 func BinSerachInsertIndex(a []int, begin int, end int, key int) int { pos := -1 //需要插入的位置 for begin \u0026lt;= end { mid := begin + (end-begin)/2 if a[mid] == key { //如果等于key 则找到位置 pos = mid + 1 break } else if a[mid] \u0026lt; key { begin = mid + 1 } else { end = mid - 1 } } if pos == -1 { pos = begin } return pos } func InsertSortOpt(a []int) { if len(a) \u0026lt; 2 { //一个数或者为空 不用排序 return } for j := 1; j \u0026lt; len(a); j++ { begin, end, key := 0, j-1, a[j] //找到插入的位置 pos := BinSerachInsertIndex(a, begin, end, key) //将pos到end区间的元素逐个后移 for index := j; index \u0026gt; pos; index-- { a[index] = a[index-1] } //插入待排序元素 a[pos] = key } }  \n网搜图解 摘自:https://www.cnblogs.com/onepixel/p/7674659.html  归并排序 介绍 MergeSort 合并两个有序的序列为1的大的有序的序列，最典型的归并排序可以分2个大的步骤：  1 采用递归思想 将一个大的序列:二分为大致平均的子序列，然后针对每个子序列都再递归二分(最后每个子序列长度都为1)\n2 两两子序列合并为有序序列 直到所有子序列合并完成\n整体归并排序也用到了很重要的分治思想，也就是将大的问题分为小的问题 逐个解决  代码  MergeSort\nfunc MergeSort(a []int, left int, right int) { //校验 if len(a) \u0026lt; 2 || left \u0026lt; 0 || right \u0026gt; len(a) || left \u0026gt;= right { return } mid := left + (right-left)/2 //数组中间位置 MergeSort(a, left, mid) //左边归并排序 MergeSort(a, mid+1, right) //右边递归排序 MergeSlice(a, left, mid, right) //合并2个子序列为大的有序序列 } func MergeSlice(a []int, left int, mid int, right int) { //先生成1个辅助空间 长度 容量都是right-left+1 help := make([]int, right-left+1, right-left+1) helpIndex := 0 //help数组起始位置 填入一个数值 往后移动一位 //定义2个下标 开始分别指向2个子区间的最开始位置 然后逐个遍历 LIndex := left RIndex := mid + 1 for LIndex \u0026lt;= mid \u0026amp;\u0026amp; RIndex \u0026lt;= right { if a[LIndex] \u0026lt;= a[RIndex] { //左边区间数值较小 左边进辅助空间 help[helpIndex] = a[LIndex] LIndex++ } else { help[helpIndex] = a[RIndex] RIndex++ } helpIndex++ //不管左边区间进辅助还是右边区间 辅助数组下标下移一个位置 因为必定进了一个数 } for LIndex \u0026lt;= mid { //如果遍历完成 左边区间还有数没放进辅助数组 那就说明剩下的左边区间数较大 依次cp进辅助 help[helpIndex] = a[LIndex] LIndex++ helpIndex++ } for RIndex \u0026lt;= right { //如果遍历完成 左边区间还有数没放进辅助数组 那就说明剩下的左边区间数较大 依次cp进辅助 help[helpIndex] = a[RIndex] RIndex++ helpIndex++ } //辅助空间已经排好序 覆盖填回原数组 for i := 0; i \u0026lt; helpIndex; i++ { a[left+i] = help[i] } }  \n时间复杂度 O( NLogN)  算法稳定性 稳定 需要merge合并的时候 左边区域\u0026lt;=右边区域的时候 先copy左边  优化 规模较小的时候 不用归并，改为插排 递归其实非常消耗性能 规模较小的时候可以不再递归 较少递归调用次数   MergeSortOpt\nfunc MergeSortOpt(a []int, left int, right int) { //一个数 为空 下标不合法 拆分完成 if len(a) \u0026lt; 2 || left \u0026lt; 0 || right \u0026gt; len(a) || left \u0026gt;= right { return } if left+20 \u0026gt;= right {//这里增加几行代码 规模较小 改为插排 InsertSort(a[left : right+1]) return } mid := left + (right-left)/2 //数组中间位置 MergeSort(a, left, mid) //左边归并排序 MergeSort(a, mid+1, right) //右边递归排序 MergeSlice(a, left, mid, right) //合并2个子序列为大的有序序列 }  \n检查合并前两个数组是否已经有序 没有必要再调用合并了  MergeSortOpt2\nfunc MergeSortOpt2(a []int, left int, right int) { //一个数 为空 下标不合法 拆分完成 if len(a) \u0026lt; 2 || left \u0026lt; 0 || right \u0026gt; len(a) || left \u0026gt;= right { return } if left+20 \u0026gt;= right {//这里增加几行代码 规模较小 改为插排 InsertSort(a[left : right+1]) return } mid := left + (right-left)/2 //数组中间位置 MergeSort(a, left, mid) //左边归并排序 MergeSort(a, mid+1, right) //右边递归排序 if a[mid]\u0026lt;=a[mid+1]{//如果2个子序列本身已经有序 无需再合并 return } MergeSlice(a, left, mid, right) //合并2个子序列为大的有序序列 }  \n网搜图解 选择排序 介绍 每轮都选择一个极值(最大或者最小)放到数组的某一端，其实也是分为有序区和无序区，刚开始全是无序区，  第1轮 遍历N个数 挑选极值放到数组最左侧 有序区有1个数\n第2轮 遍历剩下的N-1个数，挑选极值放入数组第2个位置，也就是依次放入有序区\n\u0026hellip;\n直到剩下最后一个元素 这个元素自然是整个数组的极值 整个数组排序完成\n代码  SelectSort\nfunc SelectSort(a []int) { if len(a) \u0026lt; 2 { //一个数或者为空 不用排序 return } for j := 0; j \u0026lt; len(a)-1; j++ {//控制每轮循环 遍历比较的元素个数 min := j\t//min记录最小元素下标 for i := j + 1; i \u0026lt; len(a); i++ { if a[min] \u0026gt; a[i] { min = i } } a[j], a[min] = a[min], a[j] //将最小元素依次放入有序区 } }  \n时间复杂度 O($N^2$)  算法稳定性 不稳定 会改变两个相等元素本身的相对位置 如 (7) 2 4 8 3 4 [7] 1 第一轮下来(7)会跑到最后  优化 修改内层循环，每一轮遍历 不仅找到最小下标 也要找到最大下标 最小放数组左边，最大放数组右边，减少循环次数，当然外层循环条件也要修改，最开始无序区为整个数组 每一轮下来 数组两端2个元素变为有序，有序区从两端往中间扩大，直到所有元素都为有序   SelectSortOpt\nfunc SelectSortOPT(a []int) { if len(a) \u0026lt; 2 { //一个数或者为空 不用排序 return } //刚开始left right分别为数组最小和最大下标 每轮循环left和rignt分别放置最小和最大值 //终止条件为left==right 每轮循环后left右移 right左移 for left, right := 0, len(a)-1; left \u0026lt; right; left, right = left+1, right-1 { minIndex, maxIndex := left, right for i := left; i \u0026lt;= right; i++ { if a[i] \u0026lt; a[minIndex] { //找到最小值下标 minIndex = i } if a[i] \u0026gt; a[maxIndex] { //找到最大值下标 maxIndex = i } } a[left], a[minIndex] = a[minIndex], a[left]//最小的放当前无序区最左边 if left == maxIndex { //如最大下标就是刚开始的最小下标 因为已经交换到了minIndex位置 所以最大下标也要跟着修改 maxIndex = minIndex } a[maxIndex], a[right] = a[right], a[maxIndex]//最大值放到当前无序区最右边 } }  \n网搜图解 摘自： https://www.cnblogs.com/onepixel/p/7674659.html  堆排序 介绍 二叉堆介绍 堆排序是借助堆这种数据结构进行排序，又分为最大堆和最小堆。堆也分很多种，这里用二叉堆，下面从网上找到的2张图展示下最大堆和最小堆。\n最大堆 所有父节点都**\u0026gt;=**两个子节点 最小堆 所有父节点都**\u0026lt;=**两个子节点 最大堆 可用于升序排序 最小堆可用于降序排序 二叉堆实现方式不止一种，这里选择最简单的数组实现，下图展示二叉堆如何用数组存放以及父子节点关系如何对应到数组下标关系。  堆排序大致过程  首选遍历数组 构建二叉堆(数组实现)\n 交换堆头尾两个元素，也就是数组头尾元素，最大值放到了数组最后一个元素。因为根节点发生变化\n  所以重新堆化，范围不包括最后一个元素，最后一个元素相当于已经输出排序完成，为最大值。\n 对于重新堆化的前面N-1个元素 循环执行第2步 直到输出所有堆节点 完成最终排序  代码 最大堆  MaxHeapSort\nfunc MaxHeapSort(a []int) { size:=len(a)//数组长度 if size \u0026lt; 2 { return } for i := 0; i \u0026lt; len(a); i++ {//遍历数组 构建堆 MaxHeapInsert(a, i) } for size \u0026gt; 0 { a[0], a[size-1] = a[size-1], a[0] //将当前堆顶也就是最大值放到最后 把最后的元素换到堆顶 然后重塑堆 size-- MaxHeapify(a, 0, size) } } func MaxHeapInsert(a []int, index int) { //如果插入节点大于父节点 则需要向上调整 先跟父节点交换 然后再比较上面的父节点 for parentIndex := (index - 1) / 2; a[index] \u0026gt; a[parentIndex]; index, parentIndex = parentIndex, (index-1)/2 { a[index], a[parentIndex] = a[parentIndex], a[index] } } //大堆 重新堆化过程 func MaxHeapify(a []int, index int, size int) { for maxIndex := -1; maxIndex != index; { maxIndex = index leftIndex := 2*index + 1 rightIndex := 2*index + 2 //求当前节点 左孩子 右孩子中最大值对应的下标 if leftIndex \u0026lt; size \u0026amp;\u0026amp; a[maxIndex] \u0026lt; a[leftIndex] { maxIndex = leftIndex } if rightIndex \u0026lt; size \u0026amp;\u0026amp; a[maxIndex] \u0026lt; a[rightIndex] { maxIndex = rightIndex } if maxIndex != index { a[index], a[maxIndex] = a[maxIndex], a[index] //跟左孩子、右孩子中最大的交换 index = maxIndex maxIndex = -1 } } }  \n最小堆  MinHeapSort\nfunc MinHeapSort(a []int) { if len(a) \u0026lt; 2 { return } for i := 0; i \u0026lt; len(a); i++ { MinHeapInsert(a, i) } size := len(a) for size \u0026gt; 0 { a[0], a[size-1] = a[size-1], a[0] //将当前堆顶也就是最大值放到最后 把最后的元素换到堆顶 然后重塑堆 size-- MinHeapify(a, 0, size) } } //MinHeapInsert 创建大堆 数组实现 index为要插入的元素下标 //节点下标为i 对应左孩子为2*i+1 右边孩子为2*i+2 //节点下标为i 对应父节点为(i-1)/2 func MinHeapInsert(a []int, index int) { parentIndex := (index - 1) / 2 for a[index] \u0026lt; a[parentIndex] { //如果插入节点小于父节点 则需要向上调整 先跟父节点交换 然后再比较上面的父节点 a[index], a[parentIndex] = a[parentIndex], a[index] index = parentIndex parentIndex = (index - 1) / 2 } } //MinHeapify 下标index发生了变化 重塑堆 一路向下调整 如果两个孩子中有一个比自己小 则交换 然后继续往下调整找到比自己小的孩子 然后跟其交换 //节点下标为i 对应左孩子为2*i+1 右边孩子为2*i+2 //节点下标为i 对应父节点为(i-1)/2 func MinHeapify(a []int, index int, size int) { for minIndex := -1; minIndex != index; { minIndex = index leftIndex := 2*index + 1 rightIndex := 2*index + 2 //求当前节点 左孩子 右孩子中最小值对应的下标 if leftIndex \u0026lt; size \u0026amp;\u0026amp; a[minIndex] \u0026gt; a[leftIndex] { minIndex = leftIndex } if rightIndex \u0026lt; size \u0026amp;\u0026amp; a[minIndex] \u0026gt; a[rightIndex] { minIndex = rightIndex } if minIndex != index { a[index], a[minIndex] = a[minIndex], a[index] //跟左孩子、右孩子中最小的交换 index = minIndex minIndex = -1 } } }  \n时间复杂度 O(NlogN)  算法稳定性 不稳定 插入的时候就有可能不稳定了  优化 当前实现的就是原地堆排序，没有使用额外的辅助空间，暂无好的优化思路，待补充  网搜图解 其它说明 ​ 堆在c++和java中都有系统级的实现，可以直接使用，只不过如果是自定义的类型，需要重载比较运算符。\n希尔排序 介绍 希尔排序是直接插入排序的优化版本，由一个叫shell的人提出来的，核心思想是按照步长分组，然后每组分组插排，然后缩短步长分组，继续每组插排，最后步长为1，变为直接插排。 关于步长及缩短步长如何选择，有很多种方案，可以直接分半，然后再除以2 最后为1，这里采用的Knuth序列，也就是按照下面的规律递增  gap=1\u0026mdash;\u0026ndash;\u0026gt;\u0026gt;gap=3*gap+1\n代码  ShellSort\nfunc ShellSort(a []int) { //步长采用knuth序列 变化规律为 h=1 ---\u0026gt; h = 3*h+1 h := 1 for h \u0026lt;= len(a)/3 { h = 3*h + 1 } //控制gap递减 最后变为1 for gap := h; gap \u0026gt; 0; gap = (gap - 1) / 3 { //控制分组 for j := gap; j \u0026lt; len(a); j++ { //每组进行直接插排 for i := j; i \u0026gt; gap-1; i = i - gap { if a[i] \u0026lt; a[i-gap] { a[i], a[i-gap] = a[i-gap], a[i] } } } } }  \n时间复杂度 O($N^3\u0026frasl;2$)\n算法稳定性 不稳定  优化 待补充  网搜图解 快速排序 介绍 快速排序主要用到了分治和递归思想，跟归并排序差不多，快速排序一般要选择一个基准值(pivot),然后将小于这个基准的放左边，大于这个基准的放右边，基准值放那边无所谓，这样一轮下来，数组分成了2个区域，左边区域比右边区域小，然后对2个区域用递归的方法继续快排。 这里的快速用荷兰国旗问题分成了3个区域，\u0026lt;pivot | ==pivot | \u0026gt;pivot 然后递归 \u0026lt;pivot 和\u0026gt;pivot的区域 继续分区快排序 关于基准值的选取可以有很多种，可以随机选取，可以最前面的，可以最后面的，这里采用的是最常见(选取最末端元素)  代码  QuickSort\nfunc QuickSort(a []int, left int, right int) { if len(a) \u0026lt; 2 || left \u0026gt;= right { return } base := a[right] //基准选取最末端元素 equalArea := PartitionIntSlice(a, left, right, base) QuickSort(a, left, equalArea[0]-1) //递归快排小于区间 QuickSort(a, equalArea[1]+1, right) //递归快排大于区间 } //PartitionIntSlice 给定一个数组，左边界left 右边界right 比较基准base //返回一个2个数值的int数组 该数组第一个值为等于base的开始位置 第二个值为等于base的结束位置 //所以下标小于该数组第一个值的区间都小于base 下标大于数组第二个值的区间都大于base func PartitionIntSlice(a []int, left int, right int, base int) [2]int { l := left - 1 //l为小于区间的结束下标 刚开始指向最小下标左边 r := right + 1 //l为大于区间的开始下标 刚开始指向最大下标右边 cur := left //当前遍历的数设置为整个区间最左边 for cur \u0026lt; r { if a[cur] \u0026lt; base { //如果当前数小于基数 当前数和小于区间的下一个数交换 小于区间扩一个 a[cur], a[l+1] = a[l+1], a[cur] l++ cur++ } else if a[cur] \u0026gt; base { //如果当前数大于基数 则cur下标++ a[cur], a[r-1] = a[r-1], a[cur] r-- } else { //当前数跟基数相等 不变 cur++ } } return [2]int{l + 1, r - 1} }  \n时间复杂度 O(NlogN)  算法稳定性 不稳定  优化 可以选择双轴快排序，也就是选择2个base(不相同,相同的话就又变成了荷兰国旗) 分区为 \u0026lt;minbase | minbase\u0026lt;= \u0026amp;\u0026amp; \u0026lt;=maxBase | \u0026gt;maxbase  代码后续补充\n网搜图解 计数排序 介绍 计数排序的应用场景比较清晰，也是桶排序的一种。明确的知道一个数组有N的整数，量比较大，但是数据范围比较小 都是[0,MAX), 然后创建一个计数数组，长度为MAX,计数数组值都初始化为0，然后遍历原数组，将原数组的值和计数数组的下标对应起来，比如原数组某个元素值为1，则计数数组下标为1的元素加1，表示1的元素出现过一次，这个步骤可以叫做入桶。然后顺序遍历计数数组，如果该下标的元素出现过(也就是值\u0026gt;0)，数组元素值为多少，则该下标出桶多少次，依次填回原数组即可。  ​\n代码  CountingSort\nfunc CountSort(a []int, max int) { if len(a) \u0026lt; 2 { return } count := make([]int, max, max) //创建计数的桶 for i := 0; i \u0026lt; len(a); i++ { count[a[i]]++ } indexOfa := 0 for i := 0; i \u0026lt; len(count); i++ { for count[i] \u0026gt; 0 { a[indexOfa] = i indexOfa++ count[i]-- } } }  \n时间复杂度 O(N)\n算法稳定性 直接计数排序本身是不稳定的，如果采用累加计数数组，然后倒序遍历原数组结合累加计数数组 则可以实现成稳定的，下面优化版本给出了一个稳定版本  优化 分桶方法可以有很多种，比如0号桶 存放0-9数据 1号桶存放10-19等等都是可以的，每个桶可以再放一个数组 然后对于这个数组进行快排或者插排之类的  如果某个桶数量太大，可以针对这个桶继续分桶等等 这里不再赘述，后续有兴趣再补充。\n这里列出一个稳定版本的计数排序\n CountSortStable\n//CountSortStable 桶排序的一种 应用场景 知道一个数组有N个整数 并且范围都是[0 ,MAX) //也就是量大 但是数据范围比较小 稳定版本 采用累加计数数组+倒序遍历原数组 func CountSortStable(a []int, max int) { if len(a) \u0026lt; 2 { return } count := make([]int, max, max) //创建桶 for i := 0; i \u0026lt; len(a); i++ { count[a[i]]++ } //累加计数数组 从下标1开始 其值等于count[i]+count[i-1] for i := 1; i \u0026lt; len(count); i++ { count[i] += count[i-1] //记录原数组元素在原数组出现的最后一个位置 } //然后倒序遍历原数组 这里要用到一个附加数组 help := make([]int, len(a), len(a)) for k := len(a) - 1; k \u0026gt;= 0; k-- { count[a[k]]-- lastIndex := count[a[k]] //这里为了代码好理解 多写一行 help[lastIndex] = a[k] } for i := 0; i \u0026lt; len(help); i++ { a[i] = help[i] } }  \n网搜图解 基数排序 介绍 基数排序也是桶排序的一种，主要思想是按照低优先级先排序 然后再按照高优先级再排序，最后完成排序。  比如整数排序，先按照个位排序，再按照十位排序 再按照百位、千位排序，可以参看图解，比较一目了然\n代码  RadixSort\n//GetMax 返回数组中的最大值 func GetMax(a []int) int { max := a[0] for i := 1; i \u0026lt; len(a); i++ { if a[i] \u0026gt; max { max = a[i] } } return max } //radixSort 传入按照什么基数排序 1 个位 10十位 100百位... func radixSort(a []int, radix int) { help := make([]int, len(a), len(a)) //无论是个位、十位、百位... 都只有0-9 10个数字 所以准备10个桶 bucket := make([]int, 10, 10) for i := 0; i \u0026lt; len(a); i++ { radixNum := (a[i] / radix) % 10 //得到某个基数位的数字 比如345 传入radix是1 也就是个位数也就是3 bucket[radixNum]++ } //这个for循环完成 也就完成了个位数桶计数 比如bucket[1]=3 也就是个位数是1的数字有3个 for j := 1; j \u0026lt; len(bucket); j++ { bucket[j] += bucket[j-1] } //这个for循环完成 桶计数含义发生改变 bucket[1]=3表示个位数\u0026lt;=1的数字有3个 //倒序遍历原数组 按照基数位排序后输出到辅助数组 for k := len(a) - 1; k \u0026gt;= 0; k-- { bucket[(a[k]/radix)%10]-- help[bucket[(a[k]/radix)%10]] = a[k] } for i := 0; i \u0026lt; len(a); i++ { a[i] = help[i] } } //RadixSort 基数排序 先按照个位排序 再按照10位排序 再按照百位排序 ... func RadixSort(a []int) { max := GetMax(a) for radix := 1; max/radix \u0026gt; 0; radix *= 10 { radixSort(a, radix) //依次按照个位 十位 百位 ...排序 } }  \n时间复杂度 O(X*2N) 这里的X 主要是指分了多少个基数 比如个位、十位、百位 那X=3 对于每个基数 内部都至少需要2N的时间复杂度  算法稳定性 上面实现的是稳定的 就是采用累加计数 然后倒序遍历数组的方法  优化 待补充  网搜图解 桶排序 介绍 计数排序和基数排序是最常见的2种桶排序思想，不是基于比较的排序思想，桶排序的前提假设大致如下：   假设原数据是大值均匀分布的 量也比较大 在原数据上建立1个函数映射关系 将原数据映射到有限个数的桶上 然后针对每个桶再想办法排序(比如插排、快排等) 最后按照桶顺序依次输出桶里的元素 就完成了整个排序  代码 这里不写代码了  时间复杂度 去掉常数项就是O(N)  算法稳定性 可以做到稳定\n优化 待补充\n网搜图解 待补充\n排序简单总结 ​ 排序稳定性也是特别重要的，因为现实生活中就大量实际应用场景就是要这样，最常用的归并和快排，时间复杂度都是N*logN，归并可以很简单的保持稳定，但快排很难做到稳定，所以工程上经常是基本数据类型的，大容量的排序很可能就是快排了，但如果保存的是自定义类型的数据，大部分是归并排序，而且工程上的排序大都是综合排序，比如\u0026lt;60的规模就直接插入排序了，因为这个时候O($N^2$)的劣势根本体现不出来，常数项操作又非常简单。\n​ 工程上往往也不会直接使用递归，因为非常浪费栈空间，很有可能导致栈溢出，还有其它时间浪费问题。\n​ 堆排序更重要的是堆这个数据结构，很多地方都会用到堆，比如数组中位数，优先级队列等等。\n数组 ​ 数组是一种典型的线形数据结构，特点：存放连续的相同数据类型，随机访问速度比较快。随机添加和删除，需要批量移动元素。主流编程语言基本上自身就提供了数组这种数据结构，所以这里不再练习了，数组访问注意边界，动态数组如果是C需要自己实现，C++/go标准库也都提供了动态数组的实现，可以比较方便的访问。\n链表 介绍 ​ 链表也是一种常用的线形数据结构。特点：空间不是连续的，每个节点除本身数据外，一般都存储至少一个指针数据，指向它的前驱或者后继节点，因为空间不是连续的，所以随机访问效率不高，但是删除，添加效率很高，不需要批量移动元素，这里只简单练习下双向循环链表，单链表更加简单。采用接口的方式实现，练习下go的面向接口编程\n代码  DoublyLinkedList_主要接口及结构体定义 接口用结构体指针实现\n//LinkNoder 链表接口定义 支持相关操作函数定义 type LinkNoder interface { IsEmpty() bool //返回链表释放为空链表 GetSize() int //返回链表长度 Get(index int) *LinkNode //返回下标对应的元素指针 下标从0开始 GetFirst() *LinkNode //返回第一个元素指针 也就是Head GetLast() *LinkNode //返回最后一个元素指针 也就是Tail //在对应下标位置插入元素 成功返回true 失败返回false InsertByIndex(index int, PayLoad interface{}) bool //默认在最后一个节点后面添加 PushBack(PayLoad interface{}) bool //插入到表头位置 PushFront(PayLoad interface{}) bool //释放包含某个元素 包含(true,下标) 不包含 (false,-1) IsContains(PayLoad interface{}) (bool, int, *LinkNode) //按照下标删除元素 返回元素值 DelByIndex(index int) interface{} DelHead() interface{} //删除头节点 DelTail() interface{} //删除尾节点 //按照元素值删除 成功返回true 失败返回false DelByValue(PayLoad interface{}) bool } //LinkNode 链表节点定义 type LinkNode struct { PayLoad interface{} //节点元素 Prev *LinkNode //前一个节点元素指针 Next *LinkNode //后一个节点元素指针 } //DoublyLinkList 双向循环链表定义 type DoublyLinkList struct { Head *LinkNode //双向循环链表头节点指针(这里指向第一个真正的节点 如果为nil 代表双向循环链表为空) Tail *LinkNode //双向循环链表尾部节点指针 Size int //双向循环链表长度 }  \n DoublyLinkedList详细接口方法实现\n//CreateDblist 创建一个空的dblist func CreateDblist() *DoublyLinkList { return \u0026amp;DoublyLinkList{nil, nil, 0} } //DestroyDblist 销毁双向循环链表 func DestroyDblist(dblist *DoublyLinkList) { if dblist.Size == 0 { //如果链表为空直接返回 return } pHead, p := dblist.Head, dblist.Head.Next //pHead指向第一个节点 p指向第一个节点的下一个节点 pHead.Prev, pHead.Next = nil, nil //第一个节点前驱后继都置空 for p != dblist.Head { //遍历将所有节点前驱后继都置空 pNext := p.Next //先记录当前节点的后继 p.Next, p.Prev = nil, nil //当前节点的前驱和后继指针复制为nil 等待gc回收 p = pNext //p指向下一个节点 } } func (dblist *DoublyLinkList) IsEmpty() bool { return dblist.Size == 0 } func (dblist *DoublyLinkList) GetSize() int { return dblist.Size } func (dblist *DoublyLinkList) GetFirst() *LinkNode { return dblist.Head } func (dblist *DoublyLinkList) GetLast() *LinkNode { return dblist.Tail } func (dblist *DoublyLinkList) Get(index int) *LinkNode { if index \u0026lt; 0 || index \u0026gt;= dblist.Size { fmt.Println(\u0026quot;index invalid\u0026quot;) return nil } p, i := dblist.Head, 0 for ; i \u0026lt; index; i++ { p = p.Next } return p } func (dblist *DoublyLinkList) InsertByIndex(index int, PayLoad interface{}) bool { if index \u0026lt; 0 || index \u0026gt;= dblist.Size { fmt.Println(\u0026quot;index invalid\u0026quot;) return false } //构造插入元素节点 cur := LinkNode{PayLoad, nil, nil} //当前链表为空 插入第一个元素 if dblist.Size == 0 \u0026amp;\u0026amp; index == 0 { dblist.Head = \u0026amp;cur dblist.Tail = \u0026amp;cur cur.Prev = \u0026amp;cur cur.Next = \u0026amp;cur dblist.Size++ return true } if index == 0 { //插入到表头 return dblist.PushFront(PayLoad) } if index == dblist.Size-1 { //插入到表尾 return dblist.PushBack(PayLoad) } //当前链表不为空 先得到index下标元素指针 然后插入 if p := dblist.Get(index); p != nil { cur.Prev, cur.Next = p.Prev, p p.Prev.Next = \u0026amp;cur p.Prev = \u0026amp;cur dblist.Size++ return true } fmt.Println(\u0026quot;Get(index) err\u0026quot;) return false } func (dblist *DoublyLinkList) PushBack(PayLoad interface{}) bool { //构造插入元素节点 cur := LinkNode{PayLoad, nil, nil} //当前链表为空 插入第一个元素 if dblist.Size == 0 { dblist.Head = \u0026amp;cur dblist.Tail = \u0026amp;cur cur.Prev = \u0026amp;cur cur.Next = \u0026amp;cur dblist.Size++ return true } cur.Prev, cur.Next = dblist.Tail, dblist.Head dblist.Tail.Next = \u0026amp;cur dblist.Head.Prev = \u0026amp;cur dblist.Tail = \u0026amp;cur dblist.Size++ return true } func (dblist *DoublyLinkList) PushFront(PayLoad interface{}) bool { //构造插入元素节点 cur := LinkNode{PayLoad, nil, nil} //当前链表为空 插入第一个元素 if dblist.Size == 0 { dblist.Head = \u0026amp;cur dblist.Tail = \u0026amp;cur cur.Prev = \u0026amp;cur cur.Next = \u0026amp;cur dblist.Size++ fmt.Println(\u0026quot;dblist.Size=\u0026quot;, dblist.Size) return true } cur.Prev, cur.Next = dblist.Tail, dblist.Head dblist.Head.Prev = \u0026amp;cur dblist.Tail.Next = \u0026amp;cur dblist.Head = \u0026amp;cur dblist.Size++ return true } func (dblist *DoublyLinkList) IsContains(PayLoad interface{}) (bool, int, *LinkNode) { if dblist.Size == 0 { //链表为空 直接返回不存在 return false, -1, nil } for p, i := dblist.Head, 0; i \u0026lt; dblist.Size; p, i = p.Next, i+1 { if p.PayLoad == PayLoad { return true, i, p } } return false, -1, nil } func (dblist *DoublyLinkList) DelHead() interface{} { if dblist.Size == 0 { //链表为空 直接返回不存在 return nil } if dblist.Size == 1 { //如果只有一个元素 删除完链表为空 PayLoad := dblist.Head.PayLoad dblist.Head, dblist.Tail = nil, nil dblist.Size-- return PayLoad } p := dblist.Head p.Next.Prev = dblist.Tail dblist.Tail.Next = p.Next dblist.Head = p.Next p.Prev, p.Next = nil, nil dblist.Size-- return p.PayLoad } func (dblist *DoublyLinkList) DelTail() interface{} { if dblist.Size == 0 { //链表为空 直接返回不存在 return nil } if dblist.Size == 1 { //如果只有一个元素 删除完链表为空 PayLoad := dblist.Tail.PayLoad dblist.Head, dblist.Tail = nil, nil dblist.Size-- return PayLoad } p := dblist.Tail dblist.Head.Prev = dblist.Tail.Prev dblist.Tail.Prev.Next = dblist.Head dblist.Tail = dblist.Tail.Prev p.Prev, p.Next = nil, nil dblist.Size-- return p.PayLoad } func (dblist *DoublyLinkList) DelByIndex(index int) interface{} { if index == 0 { return dblist.DelHead() } if index == (dblist.Size - 1) { return dblist.DelTail() } if p := dblist.Get(index); p != nil { p.Prev.Next = p.Next p.Next.Prev = p.Prev p.Prev, p.Next = nil, nil dblist.Size-- return p.PayLoad } return nil } func (dblist *DoublyLinkList) DelByValue(PayLoad interface{}) bool { _, index, p := dblist.IsContains(PayLoad) if index == 0 { _ = dblist.DelHead() return true } if index == (dblist.Size - 1) { _ = dblist.DelTail() return true } if p != nil { p.Prev.Next = p.Next p.Next.Prev = p.Prev p.Prev, p.Next = nil, nil return true } return false } func (dblist *DoublyLinkList) Print() { fmt.Print(\u0026quot;struct DoublyLinkList[\u0026quot;) for i, p := 0, dblist.Head; i \u0026lt; dblist.Size; i++ { fmt.Print(p.PayLoad) fmt.Print(\u0026quot;,\u0026quot;) p = p.Next } fmt.Print(\u0026quot;]\\n\u0026quot;) }  \n优化 ​ 待补充\n​ 按照下标查找元素可以用二分查找\n网搜图解 ​ 双向循环链表比较简单，很好理解 不再找图了\n栈 介绍 ​ 栈是一种后进先出的数据结构，可以用很多方式实现，因为我之前的双向循环链表已经实现了，所以直接用其实现了\n代码  Stack代码(双向循环链表实现)\n//HCStack 实现的简易栈 采用双向链表实现 type HCStack struct { Stack *doublylinkedlist.DoublyLinkList } //CreateEmptyStack 创建一个空的栈 func CreateEmptyStack() *HCStack { dblist := doublylinkedlist.CreateDblist() return \u0026amp;HCStack{dblist} } //GetSize 获取栈的真实长度 func (hcstack *HCStack) GetSize() int { return hcstack.Stack.GetSize() } //IsEmpty 返回栈是否为空 func (hcstack *HCStack) IsEmpty() bool { return hcstack.Stack.IsEmpty() } //Push 压栈操作 func (hcstack *HCStack) Push(payLoad interface{}) bool { return hcstack.Stack.PushFront(payLoad) } //Pop 出栈操作 func (hcstack *HCStack) Pop() interface{} { if hcstack.Stack.Size == 0 { fmt.Println(\u0026quot;栈为空\u0026quot;) return nil } return hcstack.Stack.DelHead() } //Peek 获取栈顶元素 不删除 func (hcstack *HCStack) Peek() interface{} { if hcstack.Stack.Size == 0 { fmt.Println(\u0026quot;栈为空\u0026quot;) return nil } return hcstack.Stack.GetFirst().PayLoad } //Clear 清空栈 func (hcstack *HCStack) Clear() { doublylinkedlist.DestroyDblist(hcstack.Stack) }  \n队列 介绍 ​ 队列是一种先进先出的数据结构，可以用很多方式实现，因为我之前的双向循环链表已经实现了，所以直接用其实现了\n代码  Queue代码(双向循环链表实现)\n//HCQueue 实现的简易队列 采用双向链表实现 type HCQueue struct { Queue *doublylinkedlist.DoublyLinkList } //CreateEmptyQueue 创建一个空的栈 func CreateEmptyQueue() *HCQueue { dblist := doublylinkedlist.CreateDblist() return \u0026amp;HCQueue{dblist} } //GetSize 获取队列的真实长度 func (hcqueue *HCQueue) GetSize() int { return hcqueue.Queue.Size } //IsEmpty 返回队列是否为空 func (hcqueue *HCQueue) IsEmpty() bool { return hcqueue.Queue.Size == 0 } //Push 入队列操作 func (hcqueue *HCQueue) Push(payLoad interface{}) bool { return hcqueue.Queue.PushBack(payLoad) } //Pop 出队列操作 func (hcqueue *HCQueue) Pop() interface{} { if hcqueue.Queue.Size == 0 { fmt.Println(\u0026quot;Pop 队列为空\u0026quot;) return nil } return hcqueue.Queue.DelHead() } //GetHead 获取队头元素 不删除 func (hcqueue *HCQueue) GetHead() interface{} { if hcqueue.Queue.Size == 0 { fmt.Println(\u0026quot;GetHead 队列为空\u0026quot;) return nil } return hcqueue.Queue.GetFirst().PayLoad } //GetTail 获取队头元素 不删除 func (hcqueue *HCQueue) GetTail() interface{} { if hcqueue.Queue.Size == 0 { fmt.Println(\u0026quot;GetTail 队列为空\u0026quot;) return nil } return hcqueue.Queue.GetLast().PayLoad } //Clear 清空栈 func (hcqueue *HCQueue) Clear() { doublylinkedlist.DestroyDblist(hcqueue.Queue) }  \n二叉树 介绍 ​ 二叉树是每个节点最多有2个子树的树结构，有5种基本形态。\n性质1：二叉树第i层上的结点数目最多为 2{i-1} (i≥1)。 性质2：深度为k的二叉树至多有2{k}-1个结点(k≥1)。 性质3：包含n个结点的二叉树的高度至少为log2 (n+1)。 性质4：在任意一棵二叉树中，若终端结点的个数为n0，度为2的结点数为n2，则n0=n2+1。\n性质1：二叉树第i层上的结点数目最多为 2{i-1} (i≥1) ​ 证明：下面用\u0026rdquo;数学归纳法\u0026rdquo;进行证明。 (01) 当i=1时，第i层的节点数目为2{i-1}=2{0}=1。因为第1层上只有一个根结点，所以命题成立。 (02) 假设当i\u0026gt;1，第i层的节点数目为2{i-1}。这个是根据(01)推断出来的！ ​ 下面根据这个假设，推断出\u0026rdquo;第(i+1)层的节点数目为2{i}\u0026ldquo;即可。 ​ 由于二叉树的每个结点至多有两个孩子，故\u0026rdquo;第(i+1)层上的结点数目\u0026rdquo; 最多是 \u0026ldquo;第i层的结点数目的2倍\u0026rdquo;。即，第(i+1)层上的结点数目最大值=2×2{i-1}=2{i}。 ​ 故假设成立，原命题得证！\n性质2：深度为k的二叉树至多有2{k}-1个结点(k≥1) ​ 证明：在具有相同深度的二叉树中，当每一层都含有最大结点数时，其树中结点数最多。利用\u0026rdquo;性质1\u0026rdquo;可知，深度为k的二叉树的结点数至多为： 20+21+…+2k-1=2k-1 故原命题得证！\n性质3：包含n个结点的二叉树的高度至少为log2 (n+1) ​ 证明：根据\u0026rdquo;性质2\u0026rdquo;可知，高度为h的二叉树最多有2{h}–1个结点。反之，对于包含n个节点的二叉树的高度至少为log2(n+1)。\n性质4：在任意一棵二叉树中，若终端结点的个数为n0，度为2的结点数为n2，则n0=n2+1 ​ 证明：因为二叉树中所有结点的度数均不大于2，所以结点总数(记为n)=\u0026ldquo;0度结点数(n0)\u0026rdquo; + \u0026ldquo;1度结点数(n1)\u0026rdquo; + \u0026ldquo;2度结点数(n2)\u0026ldquo;。由此，得到等式一。 (等式一) n=n0+n1+n2 另一方面，0度结点没有孩子，1度结点有一个孩子，2度结点有两个孩子，故二叉树中孩子结点总数是：n1+2n2。此外，只有根不是任何结点的孩子。\n​ 故二叉树中的结点总数又可表示为等式二。 (等式二) n=n1+2n2+1 由(等式一)和(等式二)计算得到：n0=n2+1。原命题得证！\n满二叉树 ​ 高度为h，并且由2{h} –1个结点的二叉树，被称为满二叉树\n完全二叉树 定义：一棵二叉树中，只有最下面两层结点的度可以小于2，并且最下一层的叶结点集中在靠左的若干位置上。这样的二叉树称为完全二叉树。 特点：叶子结点只能出现在最下层和次下层，且最下层的叶子结点集中在树的左部。显然，一棵满二叉树必定是一棵完全二叉树，而完全二叉树未必是满二叉树\n二叉查找树 ​ 又叫二叉排序树 ,英文一般是binary_search_tree。这里会重点复习下二叉查找树\n 若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意节点的左、右子树也分别为二叉查找树。 没有键值相等的节点（no duplicate nodes）  Binary_Search_Tree 二叉查找树 重要概念介绍  一个节点一般有数据域、左孩子指针，右孩子指针，父节点指针\n 前序遍历\n  先遍历根节点 再遍历左子树 再遍历右子树\n如果是递归实现代码如下:\n void preOrder(node* root){ print(root); preOrder(root-\u0026gt;left); preOrder(root-\u0026gt;right); }  如果是非递归实现 大值逻辑如下:\n void preOrderNotRecur(node* root){ stack\u0026lt;node*\u0026gt; myStack; myStack.push(root);//将跟压入栈 while(!myStack.empty()){//栈为空则终止 node* cur=myStack.pop(); print(cur);//出栈 并打印 if( cur-\u0026gt;right!=null){ myStack.push(cur-\u0026gt;right);//先压右孩子 } if (cur-\u0026gt;left!=null){ myStack.push(cur-\u0026gt;left);//再压左孩子 左孩子先出栈 先打印 } } }   中序遍历  先遍历左子树 再遍历根节点 再遍历右子树\n如果是递归实现代码很简单\n void inOrder(node* root){ inOrder(root-\u0026gt;left); print(root); inOrder(root-\u0026gt;right); }  如果是非递归实现 大值逻辑如下:\n void inOrderNotRecur(node* root){ stack\u0026lt;node*\u0026gt; myStack; while(root != null){ myStack.push(root); root=root-\u0026gt;left;//先将节点自身和节点的所有左孩子全部入栈 最左边的孩子已经入栈 而且是栈顶 } while(!myStack.empty()){//栈为空则终止 //弹出以某个节点为根的树的最左边的孩子 该孩子肯定没有左孩子了 node* cur=myStack.pop(); print(cur);//出栈 并打印 if( cur-\u0026gt;right!=null){//因为其没有左孩子了 就看看右孩子是否存在 //如果右孩子不为空 将其右孩子及右孩子的左孩子们全部依次入栈 跟根节点一样的操作 while(cur != null){ myStack.push(cur); cur=cur-\u0026gt;left;//先将节点自身和节点的所有左孩子全部入栈 最左边的孩子已经入栈 而且是栈顶 } } } }   后序遍历  先遍历左子树 再遍历右子树 再遍历根节点\n递归实现比较简单\nvoid postOrder(node* root){ inOrder(root-\u0026gt;left); inOrder(root-\u0026gt;right); print(root); }  非递归实现有点麻烦，这里用2个栈实现 ，前序是根左右，如果把前序改为 根右左，该打印的时候全部入到另外一个栈，那么出栈就变为左右根了，也就是实现了后续遍历。\nvoid postOrderNotRecur(node* root){ stack\u0026lt;node*\u0026gt; myStack,myStackPrint; myStack.push(root);//将根压入栈 while(!myStack.empty()){//栈为空则终止 node* cur=myStack.pop(); myStackPrint.push(cur);//print(cur); 前序对应打印的时候 先压栈到另外一个栈 if (cur-\u0026gt;left!=null){ myStack.push(cur-\u0026gt;left);//先压左孩子 } if( cur-\u0026gt;right!=null){ myStack.push(cur-\u0026gt;right);//再压右孩子 右孩子先出栈 这里跟前序遍历左右孩子压栈顺序变了下，所以就变为了 根右左 } } while( !myStackPrint.empty()){//前面已经按照根右左的顺序入栈 所以出栈就变为了 左右根 print(myStackPrint.top());myStackPrint.pop(); } }   前驱节点  小于该节点值中最大的一个节点\n 后继节点  大于该节点值中最小的一个节点\n 插入大概逻辑\n首先要为待插入节点(toIns)找到合适的节点位置，准确来说就是要找到toIns的父节点(parent),然后比较key，判断是左孩子还是右边孩子 if ( 树为空){直接插入，也就是此节点为根节点 }else{ //树不为空 cur=root //当前节点指向根节点 while(cur != null){ parent=cur // toIns的parent也指向当前节点 if (toIns.key\u0026lt;cur.key){ //小于当前节点的值,当前节点变为其左孩子 cur=cur.left } if (toIns.key\u0026gt;cur.key){ //小于当前节点的值，当前节点变为其右孩子 cur=cur.right } if ( key == cur.key ){ return //不允许插入相同节点 } } if toIns.key\u0026lt;parent.key{ parent-\u0026gt;left=toIns }else{ parent-\u0026gt;right=toIns } }  查找前驱节点大概逻辑\n//GetPredecessor 找到当前节点的前驱节点 func (tree *BSTTREE) GetPredecessor(cur *BSTNODE) *BSTNODE { var predecessor *BSTNODE = nil if cur.Left != nil { //如果左子树不为空 则找左子树上面的最大值 for predecessor = cur.Left; predecessor.Right != nil; predecessor = predecessor.Right { } } else { parent := cur.Parent for parent != nil \u0026amp;\u0026amp; parent.Right != cur { //如果没有父节点或者如果有父节点并且当前节点是父亲节点的右边孩子 循环终止 cur, parent = parent, parent.Parent //否则当节节点指向父亲节点 父亲节点指向自己的父亲节点继续判断 } return parent } return predecessor }  查找后继节点大值逻辑\n//GetSuccessor 找到当前节点的后继节点 func (tree *BSTTREE) GetSuccessor(cur *BSTNODE) *BSTNODE { var successor *BSTNODE = nil if cur.Right != nil { //如果右边子树不为空 则找右边子树上面的最小值 for successor = cur.Right; successor.Left != nil; successor = successor.Left { } } else { parent := cur.Parent for parent != nil \u0026amp;\u0026amp; parent.Left != cur { //如果没有父节点或者如果有父节点并且当前节点是父亲节点的左孩子 循环终止 cur, parent = parent, parent.Parent //否则当节节点指向父亲节点 父亲节点指向自己的父亲节点继续判断 } return parent } return successor }  删除节点逻辑\n核心逻辑 删除后不能改变二叉树的特点 if (cur为叶子节点){ cur.parent.(left|right)=null cur.parent=null }elseif ( cur有一个孩子) //将cur的父亲指向其孩子即可 cur.parent.(left|right)=cur.(left|right) cur.(left|right).parent=cur.parent cur.(left|right)=cur.parent=null }elseif (cur有2个孩子){ //找到其后继节点 successor cur.key=successor.key //删除后继节点 successor.parent.(left|right)=null successor.left=successor.right=successor.parent=null }   代码  BinarySearchTree代码实现\n//Less 比较两个元素大小 如果a\u0026lt;b 返回true 负责返回false type Less func(a interface{}, b interface{}) bool //BSTNODE 节点定义 type BSTNODE struct { Key interface{} Left *BSTNODE //左孩子 Right *BSTNODE //右孩子 Parent *BSTNODE //父节点 } //ChildVisitCount 记录某一个节点对应的孩子节点访问次数 用来判断孩子节点是否都访问过了 type ChildVisitCount struct { node *BSTNODE count int } //BSTTREE 二叉搜索树定义 type BSTTREE struct { Root *BSTNODE //根节点 Size int //当前节点数 less Less //比较是否小于函数 调用者可自行实现 } //BSTTreeInterface 二叉搜索树接口定义 type BSTTreeInterface interface { //IsEmpty 判断一个二叉搜索树是否为空 IsEmpty() bool //Insert 插入一个节点 返回是否插入成功 Insert(Key interface{}) bool //SearchKey 查找一个Key是否存在 在则返回其节点地址 不在则返回nil SearchKey(Key interface{}) *BSTNODE //DeleteByNode 删除一个节点 根据传入的节点地址删除 返回是否删除成功 DeleteByNode(cur *BSTNODE) bool //GetMax 得到树的最大值 GetMax() interface{} //GetMin 得到树的最小值 GetMin() interface{} //GetPredecessor 找到当前节点的前驱节点 GetPredecessor(cur *BSTNODE) *BSTNODE //GetSuccessor 找到当前节点的后继节点 GetSuccessor(cur *BSTNODE) *BSTNODE //前序遍历二叉树 打印到屏幕 PreOrder() //中序遍历二叉树 打印到屏幕 InOrder() //后序遍历二叉树 打印到屏幕 PostOrder() //前序遍历二叉树 返回一个slice PreOrderToSlice() []*BSTNODE //中序遍历二叉树 返回一个slice InOrderToSlice() []*BSTNODE //后序遍历二叉树 返回一个slice PostOrderToSlice() []*BSTNODE } //CreateEmptyTree 创建一个空的二叉搜索树 func CreateEmptyTree(less Less) *BSTTREE { return \u0026amp;BSTTREE{nil, 0, less} } //DestroyTree 销毁一个二叉树 前序遍历销毁BST func DestroyTree(tree *BSTTREE) { myStack := stack.CreateEmptyStack() if tree.Size \u0026gt; 0 { myStack.Push(tree.Root) //根节点先压栈 } for myStack.IsEmpty() == false { node := myStack.Pop().(*BSTNODE) //先遍历根节点 if node.Right != nil { myStack.Push(node.Right) //先压右子树 } if node.Left != nil { myStack.Push(node.Left) //再压左子树 } node.Left, node.Right, node.Parent = nil, nil, nil } myStack.Clear() } //CreateBSTree 把接口类型的切片转换为二叉查找树 返回树节点 func CreateBSTree(a []interface{}, less Less) *BSTTREE { tree := \u0026amp;BSTTREE{nil, 0, less} for i := 0; i \u0026lt; len(a); i++ { tree.Insert(a[i]) } return tree } //IsEmpty 判断一个二叉搜索树是否为空 func (tree *BSTTREE) IsEmpty() bool { return tree.Size == 0 } //Insert 插入一个节点 返回是否插入成功 func (tree *BSTTREE) Insert(Key interface{}) bool { toIns := BSTNODE{Key, nil, nil, nil} if tree.Root == nil { //当前树为空 tree.Root = \u0026amp;toIns tree.Size++ return true } //当前树不为空 cur, Parent := tree.Root, tree.Root //Parent指的是待插入节点的父节点 for cur != nil { Parent = cur // toIns的Parent也指向当前节点 if tree.less(toIns.Key, cur.Key) { //小于当前节点的值,当前节点变为其左孩子 cur = cur.Left } else if toIns.Key == cur.Key { return false //不允许插入相同节点 } else { //大于当前节点的值，当前节点变为其右孩子 cur = cur.Right } } tree.Size++ toIns.Parent = Parent if tree.less(toIns.Key, Parent.Key) { Parent.Left = \u0026amp;toIns } else { Parent.Right = \u0026amp;toIns } return true } //SearchKey 查找一个Key是否存在 在则返回其节点地址 不在则返回nil func (tree *BSTTREE) SearchKey(Key interface{}) *BSTNODE { cur := tree.Root for cur != nil \u0026amp;\u0026amp; cur.Key != Key { if tree.less(Key, cur.Key) { cur = cur.Left } else { cur = cur.Right } } return cur } //DeleteByKey 删除一个节点 根据传入的节点Key值删除 返回是否删除成功 func (tree *BSTTREE) DeleteByKey(Key interface{}) bool { node := tree.SearchKey(Key) if node != nil { return tree.DeleteByNode(node) } return false //如果node为空 代表Key不在树种 直接返回false } //DeleteByNode 删除一个节点 根据传入的节点地址删除 返回是否删除成功 func (tree *BSTTREE) DeleteByNode(delNode *BSTNODE) bool { if delNode != nil { if delNode.Left == nil { //如果其左子树为空 则用其右孩子替换被删除节点即可 当然如果右孩子是空 也就是纯叶子节点 直接删除即可 fmt.Println(\u0026quot;删除节点左子树为空\u0026quot;) tree.replaceNode(delNode, delNode.Right) } else if delNode.Right == nil { //如果其右子树为空 则用其左孩子替换被删除节点即可 fmt.Println(\u0026quot;删除节点右子树为空\u0026quot;) tree.replaceNode(delNode, delNode.Left) } else { fmt.Println(\u0026quot;删除节点左右子树都非空\u0026quot;) //左右子树都非空 这个时候就找到其后继节点 然后替换 succssor := tree.GetSuccessor(delNode) if succssor.Parent != delNode { //后继节点不是其右孩子(其右孩子还有左子树) fmt.Println(\u0026quot;后继节点的父亲节点不是删除节点\u0026quot;) //拿后继节点右孩子替换后继节点 也就是后继节点父节点的左孩子 变为后继节点的右孩子 tree.replaceNode(succssor, succssor.Right) succssor.Right = delNode.Right //更新后继节点的右孩子 指向被删除节点的右孩子 delNode.Right.Parent = succssor //同时更新被删除节点右孩子的的Parent属性 } tree.replaceNode(delNode, succssor) //拿后继节点替换被删除节点 succssor.Left = delNode.Left //后继节点的左孩子 指向被删除节点的左孩子 delNode.Left.Parent = succssor //同时更新被删除节点左孩子的Parent属性 } tree.Size-- delNode.Parent, delNode.Left, delNode.Right = nil, nil, nil //等待gc回收 return true } return false } //replaceNode 用newNode替换nodeToRepalce节点 func (tree *BSTTREE) replaceNode(nodeToReplace *BSTNODE, newNode *BSTNODE) *BSTNODE { if nodeToReplace.Parent == nil { //如果被替换的是根节点 则更新根节点指向新的节点 tree.Root = newNode } else if nodeToReplace == nodeToReplace.Parent.Left { //如果被替换节点是其父节点的左孩子 则将其父节点的左孩子指向新的节点 nodeToReplace.Parent.Left = newNode } else { //如果被替换节点是其父节点的右孩子 则将其父节点的右孩子指向新的节点 nodeToReplace.Parent.Right = newNode } if newNode != nil { //如果新的节点非空 则更改其父节点为被替换节点的父节点 newNode.Parent = nodeToReplace.Parent } return newNode } //GetMax 得到树的最大值 func (tree *BSTTREE) GetMax() interface{} { maxNode := tree.Root for ; maxNode.Right != nil; maxNode = maxNode.Right { } if maxNode != nil { return maxNode.Key } return nil } //GetMin 得到树的最小值 func (tree *BSTTREE) GetMin() interface{} { minNode := tree.Root for ; minNode.Left != nil; minNode = minNode.Left { } if minNode != nil { return minNode.Key } return nil } //GetPredecessor 找到当前节点的前驱节点 func (tree *BSTTREE) GetPredecessor(cur *BSTNODE) *BSTNODE { var predecessor *BSTNODE = nil if cur.Left != nil { //如果左子树不为空 则找左子树上面的最大值 for predecessor = cur.Left; predecessor.Right != nil; predecessor = predecessor.Right { } } else { if cur.Parent != nil \u0026amp;\u0026amp; cur == cur.Parent.Right { //cur是其父节点的右边孩子 前驱就是其父节点 predecessor = cur.Parent } else if cur.Parent != nil \u0026amp;\u0026amp; cur == cur.Parent.Left { // cur是其父节点的左孩子 找到爷爷 并且其父节点是其爷爷的右孩子 if cur.Parent.Parent != nil \u0026amp;\u0026amp; cur.Parent.Parent.Right == cur.Parent { predecessor = cur.Parent.Parent } } } return predecessor } //GetSuccessor 找到当前节点的后继节点 func (tree *BSTTREE) GetSuccessor(cur *BSTNODE) *BSTNODE { var successor *BSTNODE = nil if cur.Right != nil { //如果右边子树不为空 则找右边子树上面的最小值 for successor = cur.Right; successor.Left != nil; successor = successor.Left { } } else { if cur.Parent != nil \u0026amp;\u0026amp; cur.Parent.Left == cur { // cur是其父节点的左孩子 cur是其父节点的左孩子 successor = cur.Parent } else if cur.Parent != nil \u0026amp;\u0026amp; cur.Parent.Right == cur { //cur是其父节点的右孩子 找到爷爷 并且其父节点是其爷爷的左孩子 if cur.Parent.Parent != nil \u0026amp;\u0026amp; cur.Parent.Parent.Left == cur.Parent { successor = cur.Parent.Parent } } } return successor } //PreOrder 前序遍历二叉树 打印到屏幕 func (tree *BSTTREE) PreOrder() { a := tree.PreOrderToSlice() fmt.Print(\u0026quot;BSTTreePreOrder[\u0026quot;) for i := 0; i \u0026lt; len(a); i++ { fmt.Print(a[i].Key) if i == len(a)-1 { fmt.Print(\u0026quot;]\\n\u0026quot;) } else { fmt.Print(\u0026quot;,\u0026quot;) } } } //InOrder 中序遍历二叉树 打印到屏幕 func (tree *BSTTREE) InOrder() { a := tree.InOrderToSlice() fmt.Print(\u0026quot;BSTTreeInOrder[\u0026quot;) for i := 0; i \u0026lt; len(a); i++ { fmt.Print(a[i].Key) if i == len(a)-1 { fmt.Print(\u0026quot;]\\n\u0026quot;) } else { fmt.Print(\u0026quot;,\u0026quot;) } } } //PostOrder 后序遍历二叉树 打印到屏幕 func (tree *BSTTREE) PostOrder() { a := tree.PostOrderToSlice() fmt.Print(\u0026quot;BSTTreePostOrder[\u0026quot;) for i := 0; i \u0026lt; len(a); i++ { fmt.Print(a[i].Key) if i == len(a)-1 { fmt.Print(\u0026quot;]\\n\u0026quot;) } else { fmt.Print(\u0026quot;,\u0026quot;) } } } //PreOrderToSlice 前序遍历二叉树 根、左子树、右子树 返回一个slice func (tree *BSTTREE) PreOrderToSlice() []*BSTNODE { if tree.Size == 0 { return nil } a := make([]*BSTNODE, tree.Size) myStack := stack.CreateEmptyStack() myStack.Push(tree.Root) //根节点先压栈 for i := 0; myStack.IsEmpty() == false; { a[i] = myStack.Pop().(*BSTNODE) //先遍历根节点 if a[i].Right != nil { myStack.Push(a[i].Right) //先压右子树 } if a[i].Left != nil { myStack.Push(a[i].Left) //再压左子树 } i++ } myStack.Clear() return a } //InOrderToSlice 中序遍历二叉树 左子树、根、右子树 返回一个slice func (tree *BSTTREE) InOrderToSlice() []*BSTNODE { if tree.Size == 0 { return nil } a := make([]*BSTNODE, tree.Size, tree.Size) myStack := stack.CreateEmptyStack() //先将根节点及其左孩子一条线全部入栈 栈顶最后就是最左的节点 for p := tree.Root; p != nil; p = p.Left { myStack.Push(p) } for i := 0; myStack.IsEmpty() == false; { a[i] = myStack.Pop().(*BSTNODE) //最左边的节点直接出栈 而且其没有左孩子 if i \u0026gt; 0 \u0026amp;\u0026amp; tree.less(a[i], a[i-1]) { panic(\u0026quot;二叉查找树不正确\u0026quot;) } for p := a[i].Right; p != nil; p = p.Left { //将其右孩子及右孩子的左孩子一条线 全部入栈 myStack.Push(p) } i++ } myStack.Clear() return a } //isChildAllVisited 判断当前节点的孩子节点是否都已经访问过了 func isChildAllVisited(p *BSTNODE, visit map[*BSTNODE]int) bool { if p == nil { panic(\u0026quot;in isChildAllVisited input *BSTNODE is nil\u0026quot;) } childCount := 0 if p.Left != nil { childCount++ } if p.Right != nil { childCount++ } if childCount == 0 { //如果没有孩子 直接返回true return true } if childVisitCount, ok := visit[p]; ok { if childCount == childVisitCount { //所有孩子节点都已经访问过了 delete(visit, p) return true } return false } else { return false //孩子还没有被访问过 } } //PostOrderToSlice 后序遍历二叉树 左子树、右子树、根 返回一个slice func (tree *BSTTREE) PostOrderToSlice() []*BSTNODE { if tree.Size == 0 { return nil } visit := make(map[*BSTNODE]int) //记录某个节点的孩子节点访问次数 a := make([]*BSTNODE, tree.Size) myStack := stack.CreateEmptyStack() myStack.Push(tree.Root) for i := 0; myStack.IsEmpty() == false; { p := myStack.Peek().(*BSTNODE) //当前节点可以理解为根 if isChildAllVisited(p, visit) { //如果当前栈顶节点对应的孩子都已经访问过了 那就出栈 a[i] = myStack.Pop().(*BSTNODE) //fmt.Println(\u0026quot;节点:\u0026quot;, a[i].Key, \u0026quot; 左右孩子都已经访问过了 已经出栈 当前数组下标为:\u0026quot;, i) visit[a[i].Parent]++ i++ continue } if p.Right != nil { //将右孩子压栈 //fmt.Println(\u0026quot;当前栈顶是:\u0026quot;, p.Key, \u0026quot; 左右孩子尚未访问完成 不出栈，压入右孩子:\u0026quot;, p.Right.Key) myStack.Push(p.Right) } if p.Left != nil { //将左孩子压栈 //fmt.Println(\u0026quot;当前栈顶是:\u0026quot;, p.Key, \u0026quot; 左右孩子尚未访问完成 不出栈，压入左孩子:\u0026quot;, p.Left.Key) myStack.Push(p.Left) } } myStack.Clear() return a }  \n​ 其中中序遍历添加了判断是否递增，如果不是递增 则会报错\n 判断是否是一个BST二叉搜索树\n//ISBSTRET 判断是否是BST的返回值 type ISBSTRET struct { isBST bool //是否是BST minValNode *BSTNODE //当前树的最小值节点 maxValNode *BSTNODE //当前树的最大值节点 } //ISBST 判断当前树是否为BST树 外部使用 func ISBST(node *BSTNODE, less Less) bool { ret := isAnBinarySearchTree(node, less) return ret.isBST } //isAnBinarySearchTree 判断当前树是否为BST树 内部使用 func isAnBinarySearchTree(node *BSTNODE, less Less) ISBSTRET { if node == nil { return ISBSTRET{true, nil, nil} } retLeft, retRight := isAnBinarySearchTree(node.Left, less), isAnBinarySearchTree(node.Right, less) if retLeft.isBST \u0026amp;\u0026amp; retRight.isBST \u0026amp;\u0026amp; (retLeft.maxValNode == nil || less(retLeft.maxValNode.Key, node.Key)) \u0026amp;\u0026amp; (retRight.minValNode == nil || less(node.Key, retRight.minValNode.Key)) { ret := ISBSTRET{true, nil, nil} if retLeft.minValNode == nil { ret.minValNode = node } else { ret.minValNode = retLeft.minValNode //当前树的最小值节点赋值为左子树的最小值 } if retRight.maxValNode == nil { ret.maxValNode = node } else { ret.maxValNode = retRight.maxValNode //当前树的最大值节点赋值为右子树的最大值 } return ret } else { fmt.Println(\u0026quot;key=\u0026quot;, node.Key, \u0026quot; 不是BST\u0026quot;) if retLeft.isBST == false { fmt.Println(\u0026quot;原因:其左子树不是BST\u0026quot;) } if retRight.isBST == false { fmt.Println(\u0026quot;原因:其右子树不是BST\u0026quot;) } if retLeft.maxValNode != nil \u0026amp;\u0026amp; less(retLeft.maxValNode.Key, node.Key) == false { fmt.Println(\u0026quot;原因:其左子树存在比其大的节点:\u0026quot;, retLeft.maxValNode.Key) } if retRight.minValNode != nil \u0026amp;\u0026amp; less(node.Key, retRight.minValNode.Key) == false { fmt.Println(\u0026quot;原因:其右子树存在比其小的节点:\u0026quot;, retRight.minValNode.Key) } return ISBSTRET{false, nil, nil} } }  \nAVLTree 严格平衡二叉树 介绍 ​ AVL树是根据它的发明者G.M. Adelson-Velsky和E.M. Landis命名的。\n它是最先发明的自平衡二叉查找树，也被称为高度平衡树。相比于\u0026rdquo;二叉查找树\u0026rdquo;，它的特点是：AVL树中任何节点的两个子树的高度最大差别为1。\n为什么要有AVL树，因为普通的二叉查找树有可能出现长斜树的情况，最快的情况直接是一棵线形的树，比如依次插入54321，所以这个时候查找的性能大幅下降，不能达到logN,而下降为N，所以才有了AVL，AVL查找的性能达到logN，多付出的代价是插入或者删除的时候要维持平衡，所以需要旋转。\n各种旋转示意图 LL旋转实现逻辑 g为待插入节点(红色部分)的爷爷节点 这个节点的平衡性受到破坏 p待插入节点的父节点，同时是爷爷节点的左孩子\n//LLRotation LL旋转 旋转一次即可 func (tree *AvlTree) LLRotation(g *AvlTreeNode) { p := g.Left gOldParent := g.Parent pOldRight := p.Right g.Left = pOldRight p.Right = g //更新相关节点的Parent属性 如果不想要Parent属性 则下面Parent相关代码可以删除 if pOldRight != nil { pOldRight.Parent = g } if g == tree.Root { //g为根节点 tree.Root = p } else { //g非根节点 if g == gOldParent.Left { gOldParent.Left = p } else { gOldParent.Right = p } } p.Parent = gOldParent g.Parent = p //更新g和p的高度 updateHeight(g) updateHeight(p) return p }  RR旋转实现逻辑 g为待插入节点(红色部分)的爷爷节点 这个节点的平衡性受到破坏 p待插入节点的父节点，同时是爷爷节点的右边\n//RRRotation RR旋转 旋转一次即可 func (tree *AvlTree) RRRotation(g *AvlTreeNode) { p := g.Right //调整节点左右孩子指向 完成旋转 gOldParent := g.Parent pOldLeft := p.Left g.Right = pOldLeft p.Left = g //更新相关节点的Parent属性 如果不想要Parent属性 则下面Parent相关代码可以删除 if pOldLeft != nil { pOldLeft.Parent = g } if g == tree.Root { //g为根节点 tree.Root = p } else { //g非根节点 if g == gOldParent.Left { gOldParent.Left = p } else { gOldParent.Right = p } } p.Parent = gOldParent g.Parent = p //更新g和p的高度 updateHeight(g) updateHeight(p) return p }  LR旋转实现逻辑 g为待插入节点(红色部分)的爷爷节点 这个节点的平衡性受到破坏 p待插入节点的父节点，同时是爷爷节点的左孩子\n这种情况要经过2次旋转 先对p节点RR旋转 再对g节点LL旋转\n//LRRotation 2次旋转 先对p节点RR旋转 再对g节点LL旋转 func (tree *AvlTree) LRRotation(g *AvlTreeNode) { g.Left=tree.RRRotation(g.Left) return tree.LLRotation(g) }  RL旋转实现逻辑 g为待插入节点(红色部分)的爷爷节点 这个节点的平衡性受到破坏 p待插入节点的父节点，同时是爷爷节点的右孩子\n这种情况要经过2次旋转 先对p节点LL旋转 再对g节点RR旋转\n//RLRotation 2次旋转 先对p节点LL旋转 再对g节点RR旋转 func (tree *AvlTree) RLRotation(g *AvlTreeNode) { g.Right=tree.LLRotation(g.Right) return tree.RRRotation(g) }  插入代码 ​ 这里先像BST一样先插入，然后针对插入的节点就行平衡性检查和调整 关键就是rebalance函数\n AvlTree插入代码\n//Insert 插入一个节点 返回插入节点的地址 func (tree *AvlTree) Insert(Key interface{}) *AvlTreeNode { newNode := tree.insertAsBST(Key) //先像BST树一样插入 然后网上逐个判断是否打破平衡因子 做适当调整 if newNode != nil { tree.rebalance(newNode) //调整平衡性 } return newNode } //rebalance 针对一个节点以及所有父辈节点进行平衡性判断与调整 func (tree *AvlTree) rebalance(node *AvlTreeNode) { for node != nil { hLeft, hRight := Height(node.Left), Height(node.Right) if hLeft-hRight == 2 { //左子树比右子树高 可能是LL或者LR if node.Left.Left != nil { // fmt.Println(\u0026quot;节点\u0026quot;, node.Key, \u0026quot;LL旋转\u0026quot;) tree.LLRotation(node) //LL break } else { // fmt.Println(\u0026quot;节点\u0026quot;, node.Key, \u0026quot;LR旋转\u0026quot;) tree.LRRotation(node) //LR break } } else if hLeft-hRight == -2 { if node.Right.Right != nil { // fmt.Println(\u0026quot;节点\u0026quot;, node.Key, \u0026quot;RR旋转\u0026quot;) tree.RRRotation(node) //RR break } else { // fmt.Println(\u0026quot;节点\u0026quot;, node.Key, \u0026quot;RL旋转\u0026quot;) tree.RLRotation(node) //RL break } } else { // fmt.Println(node.Key, \u0026quot;没有打破平衡\u0026quot;) updateHeight(node) //没有打破平衡也要更新其高度 } node = node.Parent //逐层往上对每个父辈节点都做判断调整处理 } } func updateHeight(node *AvlTreeNode) { if node == nil { return } hleft, hright := Height(node.Left), Height(node.Right) node.Height = Max(hleft, hright) + 1 }  \n删除代码 这里也是先像BST一样删除，只不过要返回删除后需要重新调整的节点起始位置(其父辈节点 全部高度都要变更，同时做平衡性检查和旋转)\n用到的rebalance函数个插入用到的函数一样\n AvlTree删除代码\n//DeleteByKey 删除一个节点 根据传入的节点值删除 返回是否删除成功 func (tree *AvlTree) DeleteByKey(Key interface{}) bool { var delNode *AvlTreeNode = tree.SearchKey(Key) if delNode != nil { node := tree.deleteByNodeAsBST(delNode) //这里node为需要重新调整高度的起始节点 其父辈都要调整 tree.recomputeHeight(node) tree.rebalance(node) return true } return false } //deleteByNodeAsBST 删除一个节点 根据传入的节点地址删除 返回删除后需要调整高度的第一个节点 其父辈节点都要更新高度 func (tree *AvlTree) deleteByNodeAsBST(delNode *AvlTreeNode) *AvlTreeNode { if delNode != nil { var retNode *AvlTreeNode = nil if delNode.Left == nil { //如果其左子树为空 则用其右孩子替换被删除节点即可 当然如果右孩子是空 也就是纯叶子节点 直接删除即可 // fmt.Println(\u0026quot;删除节点左子树为空\u0026quot;) tree.replaceNode(delNode, delNode.Right) //这种情况 被删除节点父辈节点都要调整高度 retNode = delNode.Parent } else if delNode.Right == nil { //如果其右子树为空 则用其左孩子替换被删除节点即可 // fmt.Println(\u0026quot;删除节点右子树为空\u0026quot;) tree.replaceNode(delNode, delNode.Left) //这种情况 被删除节点父辈节点都要调整高度 retNode = delNode.Parent } else { // fmt.Println(\u0026quot;删除节点左右子树都非空\u0026quot;) //左右子树都非空 这个时候就找到其后继节点 然后替换 succssor := tree.GetSuccessor(delNode) retNode = succssor.Parent //因为后继节点发生变化 if succssor.Parent != delNode { //后继节点不是其右孩子(其右孩子还有左子树) // fmt.Println(\u0026quot;后继节点的父亲节点不是删除节点\u0026quot;) //拿后继节点右孩子替换后继节点 也就是后继节点父节点的左孩子 变为后继节点的右孩子 tree.replaceNode(succssor, succssor.Right) succssor.Right = delNode.Right //更新后继节点的右孩子 指向被删除节点的右孩子 delNode.Right.Parent = succssor //同时更新被删除节点右孩子的的Parent属性 } tree.replaceNode(delNode, succssor) //拿后继节点替换被删除节点 succssor.Left = delNode.Left //后继节点的左孩子 指向被删除节点的左孩子 delNode.Left.Parent = succssor //同时更新被删除节点左孩子的Parent属性 } tree.Size-- delNode.Parent, delNode.Left, delNode.Right = nil, nil, nil //等待gc回收 return retNode } return nil } //recomputeHeight 节点和其父辈节点全部重新计算高度 func (tree *AvlTree) recomputeHeight(node *AvlTreeNode) { for node != nil { node.Height = Max(Height(node.Left), Height(node.Right)) + 1 node = node.Parent } }  \n 判断一个树是否为AVL\n//ISAVL 判断当前树是否为AVL树 外部使用 func ISAVL(node *AvlTreeNode, less Less) bool { ret := isAnAvlTree(node, less) return ret.isAVL } //isAnAvlTree 判断当前树是否为BST树 内部使用 func isAnAvlTree(node *AvlTreeNode, less Less) ISAVLRET { if node == nil { return ISAVLRET{true, nil, nil, 0} } retLeft, retRight := isAnAvlTree(node.Left, less), isAnAvlTree(node.Right, less) if retLeft.isAVL \u0026amp;\u0026amp; retRight.isAVL \u0026amp;\u0026amp; (retLeft.maxValNode == nil || less(retLeft.maxValNode.Key, node.Key)) \u0026amp;\u0026amp; (retRight.minValNode == nil || less(node.Key, retRight.minValNode.Key)) \u0026amp;\u0026amp; ABS(retLeft.height-retRight.height) \u0026lt;= 1 { ret := ISAVLRET{true, nil, nil, Max(retLeft.height, retRight.height) + 1} if retLeft.minValNode == nil { ret.minValNode = node } else { ret.minValNode = retLeft.minValNode //当前树的最小值节点赋值为左子树的最小值 } if retRight.maxValNode == nil { ret.maxValNode = node } else { ret.maxValNode = retRight.maxValNode //当前树的最大值节点赋值为右子树的最大值 } return ret } else { fmt.Println(\u0026quot;key=\u0026quot;, node.Key, \u0026quot; 不是AVL\u0026quot;) if retLeft.isAVL == false { fmt.Println(\u0026quot;原因:其左子树不是AVL\u0026quot;) } if retRight.isAVL == false { fmt.Println(\u0026quot;原因:其右子树不是AVL\u0026quot;) } if retLeft.maxValNode != nil \u0026amp;\u0026amp; less(retLeft.maxValNode.Key, node.Key) == false { fmt.Println(\u0026quot;原因:不是BST 其左子树存在比其大的节点:\u0026quot;, retLeft.maxValNode.Key) } if retRight.minValNode != nil \u0026amp;\u0026amp; less(node.Key, retRight.minValNode.Key) == false { fmt.Println(\u0026quot;原因:不是BST 其右子树存在比其小的节点:\u0026quot;, retRight.minValNode.Key) } if ABS(retLeft.height-retRight.height) \u0026gt; 1 { fmt.Println(\u0026quot;原因左右子树高度差大于1,左子树高度:\u0026quot;, retLeft.height, \u0026quot; 右子树高度:\u0026quot;, retRight.height) } return ISAVLRET{false, nil, nil, Max(retLeft.height, retRight.height) + 1} } }  \nRedBalckTree红黑树 介绍 红黑树也是二叉搜索树，也是为了高速查找才发明的，也是为了避免出现二叉搜索树的线形情况，所以想点办法让树尽量平衡，但又不像AVL树那样严格平衡，因为如果要严格平衡，则意味着很有可能随时随地都要调整树，要不断的旋转，这样也会浪费性能，红黑树是一种相对平衡的二叉查找树，有以下特点：\n 所有节点都是红色或者黑色 根节点为黑色 所有的 NULL 叶子节点都是黑色 如果该节点是红色的，那么该节点的子节点一定都是黑色 所有的 NULL 节点到根节点的路径上的黑色节点数量一定是相同的  红黑树保证了最长路径长度不会是最短路径长度的2倍 是一种相对平衡的二叉搜索树\n插入 ​ 插入相对于删除还是比较简单的 ，还是首先像BST一样插入，然后从插入节点(下面代码记为x)开始做变色和旋转处理，大值的逻辑如下：\n1 x.Color=Red //新插入是红色会较大概率不破坏红黑树的特性 2 while( x.Parent.Color==Red){//如果其父亲节点是黑色节点 不会破坏红黑树的性质 之然什么都不用做 直接插入即可 p,g,u:=x.Parent,x.Parent.Parent,getUncle(x) if getColor(u)==Red{// UncleRed_case p.Color,u.Color,g.Color=Balck,Black,Red//父节点 叔叔节点变黑色 爷爷节点变红色 x=g//x变为其爷爷节点 继续判断 }else{//叔叔节点为空也是黑色 if p==g.Left \u0026amp;\u0026amp; x==p.Left{//UncleBlack_LeftLeft_case p.Color,g.Color=Black,Red LLRotation(g) }else if p==g.Left \u0026amp;\u0026amp; x==p.Right{//UncleBlack_LeftRight_case RRRotation(p)//旋转后 x,p亲子关系调换 将p看作新插入节点 x是其父亲 又蜕变成为 Uncle Black LeftLeft case 代码有些许重复但逻辑更清晰 x,p=p,x p.Color,g.Color=Black,Red LLRotation(g) }else if p==g.Right \u0026amp;\u0026amp; x=p.Right{ //UncleBlack_RightRight_case p.Color,g.Color=Black,Red RRRotation(g) }else if p==g.Right \u0026amp;\u0026amp; x==p.Left{UncleBlack_RightLeft_case LLRotation(p)//旋转后 x,p亲子关系调换 将p看作新插入节点 x是其父亲 又蜕变成为 Uncle Black RightRight case 代码有些许重复但逻辑更清晰 x,p=p,x p.Color,g.Color=Black,Red LLRotation(g) } } } 3 Root.Color=Black//将树的根节点染为黑色  插入代码  红黑树插入代码\n//Insert 插入一个节点 返回插入节点的地址 func (tree *RBTree) Insert(Key interface{}) *RBTreeNode { newNode := tree.insertAsBST(Key) //先像BST树一样插入 if newNode != nil { tree.insertFixUp(newNode) //插入节点后调整 } return newNode } //insertFixUp 插入节点后进行颜色调整及旋转相关处理 func (tree *RBTree) insertFixUp(node *RBTreeNode) { // fmt.Println(\u0026quot;insertFixUp 当前插入节点为:\u0026quot;, node.Key, \u0026quot;Color:\u0026quot;, node.Color) for node != tree.Root \u0026amp;\u0026amp; node.Parent.Color == Red { //如果其父亲节点是黑色节点 不会破坏红黑树的性质 之然什么都不用做 直接插入即可 p, g, u := node.Parent, node.Parent.Parent, getUncle(node) if getColor(u) == Red { // UncleRed_case p.Color, u.Color, g.Color = Black, Black, Red //父节点 叔叔节点变黑色 爷爷节点变红色 node = g //x变为其爷爷节点 继续判断 } else { //叔叔节点为空也是黑色 if p == g.Left \u0026amp;\u0026amp; node == p.Left { //UncleBlack_LeftLeft_case p.Color, g.Color = Black, Red tree.LLRotation(g) } else if p == g.Left \u0026amp;\u0026amp; node == p.Right { //UncleBlack_LeftRight_case tree.RRRotation(p) //旋转后 x,p亲子关系调换 将p看作新插入节点 x是其父亲 又蜕变成为 Uncle Black LeftLeft case 代码有些许重复但逻辑更清晰 node, p = p, node p.Color, g.Color = Black, Red tree.LLRotation(g) } else if p == g.Right \u0026amp;\u0026amp; node == p.Right { //UncleBlack_RightRight_case p.Color, g.Color = Black, Red tree.RRRotation(g) } else if p == g.Right \u0026amp;\u0026amp; node == p.Left { //UncleBlack_RightLeft_case tree.LLRotation(p) //旋转后 x,p亲子关系调换 将p看作新插入节点 x是其父亲 又蜕变成为 Uncle Black RightRight case 代码有些许重复但逻辑更清晰 node, p = p, node p.Color, g.Color = Black, Red tree.RRRotation(g) } } } if tree.Root == node { //如果插入或者调整后当前节点是根节点 则将其置为黑色 node.Color = Black } }  \n删除 ​ 删除根插入比较相对复杂，但无非也是穷举的过程\n删除的节点只能存在三种情况： caseA:被删除节点是叶子节点(如图中的1,3,5,7,9){ A1:如果叶子节点是红色的，直接删除即可，无需修复 不会破坏红黑树特性 A2:如果叶子节点是黑色，删除后会破坏特性5 需要修复 } caseB:被删除节点只有一个孩子(如图中的10){ p为被删除节点 parent,c为其孩子节点 child B1:p为黑色,c为红色 {//如图中的10和9 删除10节点 交换p和c的值，然后将删除节点改为c,因为是红色，变成了A1，直接删除即可，不论孩子是左孩子还是右孩子都是一样的 } B2:p为黑色,c为黑色{ 交换p和c的值，然后将删除节点改为c,也就变成了A2的情况 } } caseC:被删除节点有2个孩子{//如图中的2,4,6,8 找到被删除节点的后继节点，然后交换被删除节点和其后继节点的值 然后将删除节点改为其后继节点(要么是叶子节点 对应caseA,要么是只有右孩子 对应caseB) } 综合上面的情况 caseC可以转化为caseB,caseB又可以转为为caseA A1情况可以直接删除，所以只有A2需要重点关注，当然也是最复杂的。很多穷举情况，上网找了一张图应该是比较全面的，也比较好理解，多看几遍就记住了。  删除代码  红黑树删除核心代码\n//DeleteByKey 删除一个节点 根据传入的节点值删除 返回是否删除成功 func (tree *RBTree) DeleteByKey(Key interface{}) bool { var delNode *RBTreeNode = tree.SearchKey(Key) //先找到被删除的节点 if delNode != nil { if delNode.Left == nil \u0026amp;\u0026amp; delNode.Right == nil { //caseA:被删除节点是叶子节点 return tree.delLeafNode(delNode) } else if delNode.Right == nil || delNode.Left == nil { //caseB:被删除节点只有一个孩子 return tree.delNodeHasOneChild(delNode) } else { //caseC:被删除节点有2个孩子 return tree.delNodeTwoOneChild(delNode) } } return false } //delLeafNode 删除叶子节点 对应删除的caseA:被删除节点是叶子节点 func (tree *RBTree) delLeafNode(delNode *RBTreeNode) bool { if delNode.Color == Red { //A1:如果叶子节点是红色的，直接删除即可，无需修复 不会破坏红黑树特性 p := delNode.Parent //肯定有父节点 因为只有根节点没有父节点 但根节点是黑色 if delNode == p.Left { p.Left = nil } else { p.Right = nil } tree.Size-- } else { //A2:如果叶子节点是黑色，删除后会破坏特性5 需要修复 tree.delBlackLeafFixUp(delNode) } return true } //delNodeHasOneChild 删除只有一个孩子节点的情况 对应caseB:被删除节点只有一个孩子 func (tree *RBTree) delNodeHasOneChild(delNode *RBTreeNode) bool { c := delNode.Left //c指向其孩子节点 if c == nil { c = delNode.Right } if delNode.Color == Black \u0026amp;\u0026amp; c.Color == Red { //B1:p为黑色,c为红色 交换p和c的值，然后将删除节点改为c,因为是红色，变成了A1，直接删除即可 delNode.Key, c.Key = c.Key, delNode.Key delNode.Left, delNode.Right = nil, nil //删除其孩子节点 c.Left, c.Right, c.Parent = nil, nil, nil } else if c.Color == Black { //B2:p为黑色或者红色,c为黑色 交换p和c的值，然后将删除节点改为c,也就变成了A2的情况 delNode.Key, c.Key = c.Key, delNode.Key tree.delBlackLeafFixUp(c) } tree.Size-- return true } //delNodeTwoOneChild 删除节点有2个孩子的情况 对应caseC:被删除节点有2个孩子 func (tree *RBTree) delNodeTwoOneChild(delNode *RBTreeNode) bool { //找到被删除节点的后继节点，然后交换被删除节点和其后继节点的值 然后将删除节点改为其后继节点(要么是叶子节点 对应caseA,要么是只有右孩子 对应caseB) successor := tree.GetSuccessor(delNode) delNode.Key, successor.Key = successor.Key, delNode.Key if successor.Right != nil { //后继节点右孩子不为空 左孩子肯定为空 蜕变为caseB return tree.delNodeHasOneChild(successor) } //后继节点为叶子节点 蜕变为caseA return tree.delLeafNode(successor) } //删除黑色叶子节点并调整 返回删除节点的位置 func (tree *RBTree) delBlackLeafFixUp(delNode *RBTreeNode) { oldDeleteNode := delNode //记录传入的节点 因为case4会改变其值 等调整完毕 再将其父节点指向它的指针改为nil 交给gc回收 tree.Size-- if delNode == tree.Root { //如果被删除节点是root节点 而且是叶子节点 说明整个树只剩下1个root节点了 直接删除即可 tree.Root = nil } else { for delNode != tree.Root \u0026amp;\u0026amp; delNode.Color == Black { p, b := delNode.Parent, getBrother(delNode) if delNode == p.Left { //当前节点是左节点 if b.Color == Red { //case5 : 如果该兄弟节点是红色的，那么根据红黑树的特性可以得出它的一定有两个黑色的子节点 b.Color, p.Color = Black, Red tree.RRRotation(p) } else { if b.Right != nil \u0026amp;\u0026amp; b.Right.Color == Red { //case1和case3 //对应case1 : 兄弟节点是黑色的，且有一个右节点（可以断定 右节点是红色的 //也对应case3 : 兄弟节点是黑色的，且有两个节点（可以断定 左右节点都是红色的）这两种情况一样 b.Color, p.Color = p.Color, b.Color //交换兄弟节点和父节点的颜色 b.Right.Color = Black tree.RRRotation(p) break } else if b.Left != nil \u0026amp;\u0026amp; b.Left.Color == Red { //case2 //对应case2: 兄弟节点是黑色的，且有一个左节点（可以断定 左节点是红色的） b.Left.Color, b.Color = Black, Red tree.LLRotation(b) //经过LL旋转也就是右旋 就蜕变为了case1 } else { //case4:兄弟节点是黑色的，且没有红色子节点 b.Color = Red if p.Color == Red { //将父节点直接染黑就结束了 也就是相当于父子颜色交换 黑色节点个数不变 p.Color = Black break } else { delNode = p //将删除节点改为其父亲节点 递归,直到遇到根节点 或者其父亲节点是红色的 } } } } else { //当前节点是右孩子 if b.Color == Red { //case5: 如果该兄弟节点是红色的，那么根据红黑树的特性可以得出它的一定有两个黑色的子节点 b.Color, p.Color = Black, Red tree.LLRotation(p) } else { if b.Left != nil \u0026amp;\u0026amp; b.Left.Color == Red { //case1和case3 //对应case1 : 兄弟节点是黑色的，且有一个右节点（可以断定 右节点是红色的 //也对应case3 : 兄弟节点是黑色的，且有两个节点（可以断定 左右节点都是红色的）这两种情况一样 b.Color = p.Color p.Color, b.Left.Color = Black, Black tree.LLRotation(p) break } else if b.Right != nil \u0026amp;\u0026amp; b.Right.Color == Red { //case2 //对应case2: 兄弟节点是黑色的，且有一个左节点（可以断定 左节点是红色的） b.Right.Color, b.Color = Black, Red tree.RRRotation(b) //经过RR旋转也就是右旋 就蜕变为了case1 } else { //case4:兄弟节点是黑色的，且没有红色子节点 b.Color = Red if p.Color == Red { //将父节点直接染黑就结束了 也就是相当于父子颜色交换 黑色节点个数不变 p.Color = Black break } else { delNode = p //将删除节点改为其父亲节点 递归,直到遇到根节点 或者其父亲节点是红色的 } } } } } } //颜色调整和旋转完毕 将oldDeleteNode对应父节点指向它的指针改为nil 等待gc回收 if oldDeleteNode == oldDeleteNode.Parent.Left { oldDeleteNode.Parent.Left = nil } else { oldDeleteNode.Parent.Right = nil } }  \n判断是否是红黑树  检查一个树是否是红黑树\n//ISRBTRET 判断是否是RBT的返回值 type ISRBTRET struct { ISRBT bool //是否是RBT minValNode *RBTreeNode //当前树的最小值节点 maxValNode *RBTreeNode //当前树的最大值节点 BlackCount int //左右子树路径的黑色节点个数这里应该相同 否则就不是红黑树 } //ISRBT 判断当前树是否为AVL树 外部使用 func ISRBT(node *RBTreeNode, less Less) bool { if node == nil { return true } if node.Color == Red { return false } ret := isAnRBTree(node, less) return ret.ISRBT } //isAnRBTree 判断当前树是否为BST树 内部使用 func isAnRBTree(node *RBTreeNode, less Less) ISRBTRET { if node == nil { return ISRBTRET{true, nil, nil, 0} } if node.Color == Red \u0026amp;\u0026amp; (getColor(node.Left) == Red || getColor(node.Right) == Red) { fmt.Println(\u0026quot;不是RBT 原因是节点:\u0026quot;, node.Key, \u0026quot; 颜色为红,其子节点还有红色\u0026quot;) if getColor(node.Left) == Red { fmt.Println(\u0026quot;左孩子为红色:\u0026quot;, node.Left.Key) } if getColor(node.Right) == Red { fmt.Println(\u0026quot;右孩子为红色:\u0026quot;, node.Right.Key) } return ISRBTRET{false, nil, nil, 0} } retLeft, retRight := isAnRBTree(node.Left, less), isAnRBTree(node.Right, less) if retLeft.ISRBT \u0026amp;\u0026amp; retRight.ISRBT \u0026amp;\u0026amp; (retLeft.maxValNode == nil || less(retLeft.maxValNode.Key, node.Key)) \u0026amp;\u0026amp; (retRight.minValNode == nil || less(node.Key, retRight.minValNode.Key)) \u0026amp;\u0026amp; retLeft.BlackCount == retRight.BlackCount { blackCount := retLeft.BlackCount if node.Color == Black { //如果当前节点是黑色 黑色节点数量加一 blackCount++ } ret := ISRBTRET{true, nil, nil, blackCount} if retLeft.minValNode == nil { ret.minValNode = node } else { ret.minValNode = retLeft.minValNode //当前树的最小值节点赋值为左子树的最小值 } if retRight.maxValNode == nil { ret.maxValNode = node } else { ret.maxValNode = retRight.maxValNode //当前树的最大值节点赋值为右子树的最大值 } return ret } else { fmt.Println(\u0026quot;key=\u0026quot;, node.Key, \u0026quot; 不是RBT\u0026quot;) if retLeft.ISRBT == false { fmt.Println(\u0026quot;原因:其左子树不是RBT\u0026quot;) } if retRight.ISRBT == false { fmt.Println(\u0026quot;原因:其右子树不是RBT\u0026quot;) } if retLeft.maxValNode != nil \u0026amp;\u0026amp; less(retLeft.maxValNode.Key, node.Key) == false { fmt.Println(\u0026quot;原因:不是BST 其左子树存在比其大的节点:\u0026quot;, retLeft.maxValNode.Key) } if retRight.minValNode != nil \u0026amp;\u0026amp; less(node.Key, retRight.minValNode.Key) == false { fmt.Println(\u0026quot;原因:不是BST 其右子树存在比其小的节点:\u0026quot;, retRight.minValNode.Key) } if retLeft.BlackCount != retRight.BlackCount { fmt.Println(\u0026quot;原因左右子树黑色节点个数不相等,左子树黑节点个数:\u0026quot;, retLeft.BlackCount, \u0026quot; 右子树黑节点个数:\u0026quot;, retRight.BlackCount) } return ISRBTRET{false, nil, nil, -1} } }  \n从上到下按照层次 从左到右按照顺序打印红黑树 红色节点打印红色  逐层，每层从左到右形象化打印红黑树\n//PrintVisually 逐层打印 方向 从左往右形象化更直观的打印二叉树 func (tree *RBTree) PrintVisually() { if tree.Size == 0 { return } nilNode := \u0026amp;RBTreeNode{nil, nil, nil, nil, false} //定义一个空节点 depth := getMaxDepth(tree.Root) //最深层次 // fmt.Println(\u0026quot;depth=\u0026quot;, depth) //申请2个队列 从1个队列出队 同时将其左右子树依次入队到另外一个队列 myQueue1, myQueue2 := queue.CreateEmptyQueue(), queue.CreateEmptyQueue() myQueue1.Push(tree.Root) //根节点先入队列1 //终止条件 最大层次打印完毕 for i, cur, next := 1, myQueue1, myQueue2; i \u0026lt;= depth; i, cur, next = i+1, next, cur { count := 1 //标记打印当前层次的第几个元素 tabCount := (1\u0026lt;\u0026lt;(depth+1-i) - 1) / 2 //打印元素 计算打印前面\\t个数 for cur.IsEmpty() == false { //队列1不为空 if count \u0026gt; 1 { tabCount = (1\u0026lt;\u0026lt;(depth+1-i) - 1) } node := cur.Pop().(*RBTreeNode) if node != nilNode { //不是空节点 //将其左右孩子入到下一层队列 for j := 0; j \u0026lt; tabCount; j++ { fmt.Print(\u0026quot; \u0026quot;) } if node.Color == Red { fmt.Print(redBg, node.Key, reset) } else { fmt.Print(node.Key) } count++ if node.Left != nil { next.Push(node.Left) } else { next.Push(nilNode) //加入一个空节点 为了打印好看 } if node.Right != nil { next.Push(node.Right) } else { next.Push(nilNode) //加入一个空节点 为了打印好看 } } else { //空节点 for j := 0; j \u0026lt; tabCount; j++ { fmt.Print(\u0026quot; \u0026quot;) } fmt.Print(\u0026quot;*\u0026quot;) count++ next.Push(nilNode) //加入一个空节点 为了打印好看 next.Push(nilNode) //加入一个空节点 为了打印好看 } } fmt.Print(\u0026quot;\\n\u0026quot;) } myQueue1.Clear() myQueue2.Clear() }  \nB树 定义及特点 ​ B树也叫B-树 这里的-是连接符，不是减号，是一个多路平衡查找树，描述一个B树必须要说明是几阶的，也就是树中一个节点最多能有多少个孩子，一般用m来表示，如果m=2，那就是AVL树（当然也是BST树）\n一颗m阶的B树定义及特点如下：\n 每个结点最多有m-1个关键字。\n 根结点至少要有1个关键字(也就是2个孩子)。\n 非根结点至少有 取上限(m/2)-1个关键字。如果是4阶，则至少有1个关键字，如果是5阶，则至少有2个关键字\n 每个结点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。\n 所有叶子结点都位于同一层，或者说根结点到每个叶子结点的长度都相同。\n  下面有个5阶B树示意图\nB树主要是为了解决磁盘存储高效查找的，如果是AVL树，对于在内存或者少量在磁盘存放还是可以接受的，但是如果大量文件存放在磁盘上面，因为是2路的，所以势必avl的高度值就很大，这个高度简单来说就是代表磁盘查找的次数，磁盘的速度远远低于内存速度，所以如果是大量数据存放在磁盘，AVL的效率就肯定是不行的了。所以实际应用中B树阶树一般都比较大，通常都是100往上，因为这样可以降低树的高度，当然也就减少了磁盘搜索次数，提高查找性能。\nMangoDb是B树索引，Mysql是B+树索引。上图中的data实际中往往是磁盘的地址，这里为了简单期间，数据也全部放到内存。后续有时间实现个B+树存放在磁盘的key-value简易数据库\n本章节大部分图片来自：https://www.cnblogs.com/nullzx/p/8729425.html\n插入操作简易介绍 ​ 这里的插入指的是插入一对key-value,如果key已经存在，那就更新value。B树的插入有一个特点就是首先肯定是在叶子节点完成插入操作的(最底层的节点)\n 先根据key找到对应的要插入的叶子节点并按照大小顺序插入(小值在前面)\n 判断插入后的叶子节点key值个数是否\u0026lt;=m-1,如果是 则直接结束插入操作，否则继续下一步分裂调整\n 如果插入后叶子节点key值个数\u0026gt;m-1 则不符合特点1,需要调整 3.1. 找到该节点中间的key记为midKey，可以用二分的mid方法，begin+(end-begin)/2 3.2. 以midkey为中心，其左其右各分裂一个节点出来 记为midLeft,midRight\n  3.3. 将midKey插入到该叶子节点的父节点中(小值在前面) 同时其左分支指向midLeft 右分支指向midRight\n3.4. 将指针指向其父节点(调整后midKey在的节点) 继续循环第2、3步判断\u0026mdash;因为父节点新插入一个midKey后也可能破坏特点1\n网搜简易插入图解m=5  空树插入39  网上的图是先直接申请好节点空间，也就是5阶最多4个key，当然也可以用链表存放，用的时候再生成。 这个时候只有一个节点也是根节点\n 继续插入22、97、41  因为key个数没有超过m-1，所以直接按序插入即可。无序分裂调整\n 继续插入53  这时候key个数超过m-1，就需要找到中间key,然后分裂调整，midKey为41，\n分裂为midLeft(22,39),midRight(53,97),将midKey 41,插入到其父节点，这里因为父节点为空，所以41成为新的根节点 左边指向midLeft,右边指向midRight。\n将指针指向父节点，也就是41在的新的root节点，继续判断，发现key值数量\u0026lt;=m-1 循环中断，插入分裂调整结束，调整后图如下:\n 更多例子 请直接看https://www.cnblogs.com/nullzx/p/8729425.html  插入代码  BTree插入代码go版本\n//Less 比较两个元素大小 如果a\u0026lt;b 返回true 负责返回false type Less func(a interface{}, b interface{}) bool //Node 定义key-data数据对 type Node struct { Key interface{} Data interface{} } //BTNode 定义每一个btree节点 type BTNode struct { KeyNum int //本节点保存的关键字数量 Parent *BTNode //父节点指针 Nodes []*Node //保存的key-data数据对数组 Childs []*BTNode //孩子节点指针数组 } //BTree b树结构体定义 type BTree struct { M int //b树阶数 Root *BTNode //根节点 Size int //保存key-data数据对数量 less Less //比较Key大小函数 minKeyNum int } //Insert 向Btree插入一个数据对 返回是否插入成功 func (tree *BTree) Insert(node *Node) bool { if node == nil { //如果传入指针为空 则返回插入失败 return false } //查找是否存在 存在则更新 不存在下面函数会返回插入的节点指针和数据对数组下标 flag, index, btNode := tree.Search(node.Key) if flag == false { if btNode == nil { //当前树为空 fmt.Println(\u0026quot;当前树为空,插入:\u0026quot;, node.Key) btNode = tree.CreateNewBTNode(nil, nil, nil) btNode.Nodes[0] = node btNode.KeyNum++ tree.Root = btNode return true } fmt.Println(\u0026quot;将插入到\u0026quot;, index, \u0026quot;位置\u0026quot;) if index == -1 { panic(\u0026quot;Search函数返回下标为-1 函数处理异常,请检查\u0026quot;) } //如果btNode不为空 则Search函数返回的就是插入的节点指针 index就是该节点数据对数组对应的下标 return tree.insert(btNode, index, node) } //如果flag为真 则说明已经存在相同的key值 更新信息即可 if btNode == nil || index == -1 { panic(\u0026quot;Search函数当元素存在是返回节点指针为nil,或者返回下标为-1,处理异常 请检查\u0026quot;) } btNode.Nodes[index] = node return true } //Search 在一颗B树中查找一个元素 返回(是否存在,存在返回对应下标｜不存在返回插入位置,存在返回对应节点指针|不存在返回插入节点位置) func (tree *BTree) Search(Key interface{}) (bool, int, *BTNode) { index, retNode := -1, tree.Root for btNode := tree.Root; btNode != nil; { i := 0 if btNode != nil { fmt.Printf(\u0026quot;正在节点地址为%p中找寻\\n\u0026quot;, btNode) } for { if tree.less(Key, btNode.Nodes[i].Key) { fmt.Println(Key, \u0026quot;小于\u0026quot;, btNode.Nodes[i].Key) index, retNode = i, btNode btNode = btNode.Childs[i] //如果传入Key小于当前节点正在遍历的Key值 则指向正在遍历Key的左子树遍历 if btNode != nil { fmt.Printf(\u0026quot;准备去其左孩子地址为%p中找寻\\n\u0026quot;, btNode) } break } else if Key == btNode.Nodes[i].Key { //如果相等 则找到 直接return fmt.Printf(\u0026quot;找到key，地址为%p 下标为%d\\n\u0026quot;, btNode, i) return true, i, btNode } else { //传入Key大于当前节点正在遍历的Key值 则i++遍历当前节点下一个Key if i == btNode.KeyNum-1 { index, retNode = i+1, btNode btNode = btNode.Childs[i+1] //如果已经是最后一个节点 则指向正在遍历Key的右子树遍历 break } fmt.Println(Key, \u0026quot;大于\u0026quot;, btNode.Nodes[i].Key) // fmt.Printf(\u0026quot;准备去其右孩子地址为%p中找寻\\n\u0026quot;, btNode.Childs[i]) i++ } } } //代码走到这里肯定是没有找到 返回要插入的节点及对应key数据对数组下标 如果retNode为nil 则说明当前树为空 return false, index, retNode } //insert 在btNode节点中插入一个数据对node 其中index为数据对数组的下标 func (tree *BTree) insert(btNode *BTNode, index int, node *Node) bool { for i := len(btNode.Nodes) - 1; i \u0026gt; index; i-- { //从index位置开始的所有元素指针后移一位 btNode.Nodes[i] = btNode.Nodes[i-1] } btNode.Nodes[index] = node //插入节点 btNode.KeyNum++ if btNode.KeyNum \u0026lt; tree.M { //如果插入元素后关键词数量没有超过最大值 直接返回 fmt.Println(\u0026quot;key:\u0026quot;, node.Key, \u0026quot;插入后当前节点关键词数量为\u0026quot;, btNode.KeyNum, \u0026quot;没有超过最大关键词数量:\u0026quot;, tree.M-1) return true } //如果插入元素后关键词数量刚好超过最大值 则对本节点做分裂操作 for btNode.KeyNum \u0026gt;= tree.M { fmt.Println(\u0026quot;key:\u0026quot;, node.Key, \u0026quot;插入后当前节点关键词数量为\u0026quot;, btNode.KeyNum, \u0026quot;超过最大关键词数量:\u0026quot;, tree.M-1) fmt.Println(\u0026quot;开始分裂调整\u0026quot;) btNode = tree.split(btNode) } return true } //split 对btNode做分裂调整 返回调整后的父节点 func (tree *BTree) split(btNode *BTNode) *BTNode { midIndex := 0 + (btNode.KeyNum-1)/2 midNode := btNode.Nodes[midIndex] //0--minIndex-1 是分裂后的左节点(还在原来的节点中) midIndex+1到btNode.KeyNum-1是分裂后的右节点(生成一个新的节点) //先生成右节点 rightBtNode := tree.CreateNewBTNode(nil, btNode.Nodes[midIndex+1:], btNode.Childs[midIndex+1:]) //如果新生成的右节点本身有孩子节点 则将其孩子节点的父亲节点改为新生成的节点 if rightBtNode.Childs[0] != nil { for i := 0; i \u0026lt;= rightBtNode.KeyNum; i++ { rightBtNode.Childs[i].Parent = rightBtNode } } //再将原节点中所有右节点的数据清除 for i := midIndex; i \u0026lt; len(btNode.Nodes); i++ { btNode.Nodes[i] = nil btNode.KeyNum-- } for i := midIndex + 1; i \u0026lt; len(btNode.Childs); i++ { btNode.Childs[i] = nil } //将midIndex插入到父节点 parentBtNode := tree.insertIntoParent(btNode.Parent, midNode, btNode, rightBtNode) return parentBtNode } //insertIntoParent 将node插入到父亲节点 func (tree *BTree) insertIntoParent(parentBtNode *BTNode, node *Node, leftBtNode *BTNode, rightBtNode *BTNode) *BTNode { if parentBtNode == nil { //是根节点分裂的 因为其父节点为nil 生成一个新的节点 将node插入 并指向传入的左右子树 并将根节点指向新生成的节点 fmt.Println(\u0026quot;根节点分裂\u0026quot;) btNode := tree.CreateNewBTNode(nil, nil, nil) btNode.Nodes[0] = node btNode.Childs[0], btNode.Childs[1] = leftBtNode, rightBtNode btNode.KeyNum++ leftBtNode.Parent, rightBtNode.Parent = btNode, btNode tree.Root = btNode return btNode } //如果传入父亲节点不为空 则先找到应该插入的位置 index := -1 for i := 0; i \u0026lt; parentBtNode.KeyNum; i++ { fmt.Println(node.Key, \u0026quot;父节点 \u0026quot;, i, \u0026quot;位置\u0026quot;, parentBtNode.Nodes[i].Key) if tree.less(node.Key, parentBtNode.Nodes[i].Key) { index = i break } if i == parentBtNode.KeyNum-1 { index = i + 1 //如果已经是最后一个节点 则插入到最后的位置 break } } fmt.Println(node.Key, \u0026quot;将插入到父节点的\u0026quot;, index, \u0026quot;位置\u0026quot;) for i := len(parentBtNode.Nodes) - 1; i \u0026gt; index; i-- { parentBtNode.Nodes[i] = parentBtNode.Nodes[i-1] //index后面元素后移一位 } parentBtNode.Nodes[index] = node //完成节点插入 for i := len(parentBtNode.Childs) - 1; i \u0026gt; (index + 1); i-- { parentBtNode.Childs[i] = parentBtNode.Childs[i-1] } parentBtNode.Childs[index] = leftBtNode parentBtNode.Childs[index+1] = rightBtNode rightBtNode.Parent = parentBtNode parentBtNode.KeyNum++ return parentBtNode } //CreateNewBTNode 初始化一个BTNode func (tree *BTree) CreateNewBTNode(Parent *BTNode, Nodes []*Node, Childs []*BTNode) *BTNode { btNode := \u0026amp;BTNode{0, nil, nil, nil} btNode.Parent = Parent btNode.Nodes = make([]*Node, tree.M) //这里没有用链表实现 直接按照最大容量生成了 会有一定空间浪费 btNode.Childs = make([]*BTNode, tree.M+1) //这里没有用链表实现 直接按照最大容量生成了 会有一定空间浪费 if Nodes != nil { copy(btNode.Nodes, Nodes) btNode.KeyNum = len(Nodes) } if Childs != nil { copy(btNode.Childs, Childs) } return btNode }  \n删除操作简易介绍 删除操作相对麻烦一些，大概如下几个步骤：\n 首先找到key在树中的位置，包括树节点位置和树节点中key关键字数组中对应的下标，如果找不到自然返回删除失败\n 如果当前key在的节点不是叶子节点，则找到其后继key，用后继key覆盖要删除的key 然后删除后继key(肯定在叶子节点) 然后继续执行下面步骤\n 如果删除key所在节点是叶子节点 并且关键字数量删除后依然符合最小要求，则直接删除返回，结束。\n 如果删除key所在节点是叶子节点 但是关键字数量删除后不符合最小要求 做以下处理:\n  4.1. 如果删除key所在节点的左右兄弟节点关键字数量个数都\u0026gt;最小要求个数，也就是可以从兄弟节点中借一个key过来，这样删除后关键字数量就都符合要求了，这里也牵扯到父节点中key的变化调整，相当于一次简单的旋转操作，下面有例子，至于左右兄弟节点如果都符合要求，从哪里借的问题，我个人选择的是关键字数量最大的兄弟节点\n4.2. 如果删除key所在节点的左右兄弟关键词数量都不符合要求(\u0026lt;=最小要求个数)，这时候需要将父节点中一个key下移，与其兄弟节点中的key合并成为一个新的节点。原父结点中的key的两个孩子指针就变成了一个孩子指针，指向这个新结点。然后当前结点的指针指向父结点，然后从第3步开始重复判断操作，因为父节点下移一个节点，有可能关键字数量也不符合要求了，也要调整。\n网搜简易删除图解m=5  删除前原始状态   删除21  是叶子节点，并且删除后关键字数量符合最小要求(最小为2) 所以直接删除即可，注意修改该节点关键字数量，删除后为：\n 继续删除27  非叶子节点，找到其后继key，也就是28，用后继key的值覆盖原先的key27，然后删除key变为key28（要删除图中28 29节点中的key28）删除后的样子如下：\n这时候变成了情况4.1 有兄弟节点可以借关键字，所以父节点中的key28下移，兄弟节点中的key26节点顶替父亲节点中的key28位置，有点像对key28做一次右旋操作，但不完全相同。最后变为：\n 继续删除32  删除32后，关键字不符合要求，而且兄弟节点也不能借，所以为情况4.2.\n这个时候合并兄弟节点 key31 跑到兄弟节点中(key28,key29所在节点)，同时让父节点中key30下移，跟其合并后新的孩子节点(key28,29,31)再次合并 同时注意修改父节点中的孩子指针。\n然后将当前节点指针改为父亲节点(key 22 26) 发现关键词数量符合要求，结束调整，最后为：\n 继续删除40  属于情况4.2,删除后关键词不够了，兄弟节点也都不够借，key39\u0026ndash;\u0026gt;(key34,35)\u0026mdash;\u0026gt;(key 34,35,39)\n然后父节点的key36下移 变为(key 34,35,36,39) 指针指向其父节点\n然后发现还是情况4.2. Key41\u0026ndash;\u0026gt;(key22,26)\u0026mdash;\u0026gt;(key 22 26 41)\n然后父节点下移 变为(key22 26 33 41) 这个时候也不要忘记修改root指针\n删除代码  BTree删除代码go版本\n//Delete 删除树中的key对应的数据对 返回删除成功或者失败 func (tree *BTree) Delete(Key interface{}) bool { flag, KeyDelIndex, delBtNode := tree.Search(Key) if flag == false || KeyDelIndex == -1 || delBtNode == nil { //找不到节点 return false } if tree.isLeafBtNode(delBtNode) == false { //非叶子节点 一定有左右孩子,找到删除Key的后继Key 也就是右孩子的最左孩子的第一个key successorBtNode := tree.getSuccessor(delBtNode, KeyDelIndex) fmt.Println(Key, \u0026quot;不是叶子节点，其后继key为:\u0026quot;, successorBtNode.Nodes[0].Key) successorKeyNode := successorBtNode.Nodes[0] delBtNode.Nodes[KeyDelIndex] = successorKeyNode //用后继key覆盖原先要删除的key delBtNode, KeyDelIndex = successorBtNode, 0 //删除节点改为其后继bt节点 对应的KeyIndex就是其后继Key也就是0 此时后继节点肯定是叶子节点 } fmt.Println(\u0026quot;删除节点Key:\u0026quot;, delBtNode.Nodes[KeyDelIndex].Key, \u0026quot; 为叶子节点\u0026quot;) //下面都是叶子节点的逻辑 先删除对应的Key 然后判断关键字数量 // key1--key2...KeyDelIndex.... KeyDelIndex后面的元素全部前移 然后该节点的关键字数量减1 for i := KeyDelIndex; i \u0026lt; delBtNode.KeyNum; i++ { delBtNode.Nodes[i] = delBtNode.Nodes[i+1] } delBtNode.KeyNum-- for delBtNode.KeyNum \u0026lt; tree.minKeyNum { //如果被删除叶子节点的关键字数量不符合要求 则需要调整 //先找到该节点的左右兄弟 尝试充兄弟中借key leftBroBtNode, rightBroBtNode, lBroIndexInPChilds, rBroIndexInPChilds := tree.getBrothers(delBtNode) if tree.borrowKeyFormBrothers(leftBroBtNode, rightBroBtNode, delBtNode, lBroIndexInPChilds, rBroIndexInPChilds) { //成功则返回 fmt.Println(\u0026quot;兄弟节点够借\u0026quot;) return true } fmt.Println(\u0026quot;兄弟节点不够借 准备合并\u0026quot;) //如果兄弟节点借不到 则需要合并节点了 delBtNode = tree.merge(delBtNode, leftBroBtNode, rightBroBtNode, lBroIndexInPChilds, rBroIndexInPChilds) if delBtNode.Nodes[0] != nil { fmt.Println(\u0026quot;合并后删除节点变为其父节点 \u0026quot;, delBtNode.Nodes[0].Key) tree.PrintVisually() } } fmt.Println(\u0026quot;删除完成\u0026quot;) return true } //isLeafBtNode 检查一个节点是否是叶子节点 也就是没有孩子 func (tree *BTree) isLeafBtNode(btNode *BTNode) bool { if btNode == nil || btNode.KeyNum == 0 { return true } return btNode.Childs[0] == nil //如果是叶子节点 那么就没有一个孩子 第一个key的左孩子肯定为nil 否则就是非叶子节点 } //getSuccessor 传入某一个Bt节点和对应key的小标 找到该Key的后继Key 返回后继Key的Bt节点(当然后继Key肯定是该节点的第一个key) func (tree *BTree) getSuccessor(btNode *BTNode, index int) *BTNode { rightBtNode := btNode.Childs[index+1] retBtNode := rightBtNode for ; rightBtNode.Childs[0] != nil; retBtNode, rightBtNode = rightBtNode, rightBtNode.Childs[0] { //如果最左的孩子不为空 则继续往下找到最左的孩子 } return retBtNode } //getBrothers 传入一个bt节点 找到其左右兄弟返回 第一个返回值为左兄弟 同时也返回左右兄弟在父节点孩子节点指针数组中的下标 func (tree *BTree) getBrothers(btNode *BTNode) (*BTNode, *BTNode, int, int) { if btNode.Parent == nil { return nil, nil, -1, -1 } //遍历父节点重的孩子节点指针数组 找到该节点指针的下标，左边就是其左兄弟 右边就是其又兄弟 index := -1 var leftBroBtNode, rightBroBtNode *BTNode = nil, nil for i := 0; i \u0026lt;= btNode.Parent.KeyNum; i++ { if btNode.Parent.Childs[i] == btNode { index = i break } } if index == -1 { panic(\u0026quot;在父亲节点中找不到该节点指针\u0026quot;) } if index == 0 { //如果该节点是父亲节点的第一个孩子 则没有左兄弟 leftBroBtNode = nil } else { leftBroBtNode = btNode.Parent.Childs[index-1] } if index == btNode.Parent.KeyNum { //如果该节点是父亲节点的最后一个孩子 则没有右兄弟 rightBroBtNode = nil fmt.Println(\u0026quot;没有右边兄弟 index=\u0026quot;, index, \u0026quot;keyNum=\u0026quot;, btNode.KeyNum) } else { rightBroBtNode = btNode.Parent.Childs[index+1] } return leftBroBtNode, rightBroBtNode, index - 1, index + 1 } //borrowKeyFormBrothers 从兄弟中借key 返回是否成功 //lBroIndexInPChilds, rBroIndexInPChilds 分别为左右兄弟在父节点孩子指针数组中的下标 func (tree *BTree) borrowKeyFormBrothers(leftBroBtNode *BTNode, rightBroBtNode *BTNode, delBtNode *BTNode, lBroIndexInPChilds int, rBroIndexInPChilds int) bool { //想从兄弟中借key首先本身兄弟key比较富足 否则返回失败，如果都比较富足，则取最富足的 //如果两者key数量相同 切都富足 则这里固定取左兄弟 if (leftBroBtNode == nil || leftBroBtNode.KeyNum \u0026lt;= tree.minKeyNum) \u0026amp;\u0026amp; (rightBroBtNode == nil || rightBroBtNode.KeyNum \u0026lt;= tree.minKeyNum) { return false } isBorrowLeftBro, isBorrowRightBro := false, false //如果左兄弟为空或者左兄弟关键词数量小于右兄弟 则从右兄弟借 否则从左兄弟借 2兄弟key数量相等 也从左兄弟借 if leftBroBtNode == nil || leftBroBtNode.KeyNum \u0026lt; rightBroBtNode.KeyNum { isBorrowRightBro = true } else { isBorrowLeftBro = true } if isBorrowLeftBro { //从左兄弟借 //将父节点中对应key插入delBtNode中 插入到最左边 因为从父节点找到的key是大于左兄弟中的最大值 小于删除节点中的最小值的 for i := delBtNode.KeyNum; i \u0026gt; 0; i-- { delBtNode.Nodes[i] = delBtNode.Nodes[i-1] //原先节点全部后移一位 把最左边位置腾出来 } delBtNode.Nodes[0] = leftBroBtNode.Parent.Nodes[lBroIndexInPChilds] //父节点下来一个节点 delBtNode.KeyNum++ //将左兄弟中最靠右的key，也就是最大的key 插入到父节点换到被删除节点的key位置 leftBroBtNode.Parent.Nodes[lBroIndexInPChilds] = leftBroBtNode.Nodes[leftBroBtNode.KeyNum-1] leftBroBtNode.Nodes[leftBroBtNode.KeyNum-1] = nil leftBroBtNode.KeyNum-- return true } if isBorrowRightBro { //从右兄弟借 //将父节点中对应key插入delBtNode中 插入到最右边 因为从父节点找到的key左孩子指向是被删除的节点 大于删除节点中的最大值的 delBtNode.Nodes[delBtNode.KeyNum] = rightBroBtNode.Parent.Nodes[rBroIndexInPChilds] delBtNode.KeyNum++ //将右兄弟中最靠左的key，也就是最小的key 插入到父节点换到被删除节点的key位置 rightBroBtNode.Parent.Nodes[rBroIndexInPChilds] = rightBroBtNode.Nodes[0] //右兄弟中所有key元素前移一个位置 并将原先最后一个key的指针置空 for i := 0; i \u0026lt; rightBroBtNode.KeyNum; i++ { rightBroBtNode.Nodes[i] = rightBroBtNode.Nodes[i+1] } rightBroBtNode.Nodes[rightBroBtNode.KeyNum] = nil rightBroBtNode.KeyNum-- return true } return false } //merge 合并节点 将要删除的节点合并到传入的左/右兄弟节点中 返回其父节点 func (tree *BTree) merge(delBtNode *BTNode, leftBroBtNode *BTNode, rightBroBtNode *BTNode, lBroIndexInPChilds int, rBroIndexInPChilds int) *BTNode { if leftBroBtNode != nil { fmt.Println(\u0026quot;传入左兄弟不为空\u0026quot;) } if leftBroBtNode != nil { //只要左边兄弟不为nil 就将delBtNode合并到左兄弟节点中 //先将父节点中指向左兄弟的key也移动到左边兄弟中 leftBroBtNode.Nodes[leftBroBtNode.KeyNum] = leftBroBtNode.Parent.Nodes[lBroIndexInPChilds] leftBroBtNode.KeyNum++ //将delBtNode中的key全部移动到leftBroBtNode中 for i := 0; i \u0026lt; delBtNode.KeyNum; i++ { leftBroBtNode.Nodes[leftBroBtNode.KeyNum] = delBtNode.Nodes[i] leftBroBtNode.Childs[leftBroBtNode.KeyNum] = delBtNode.Childs[i] leftBroBtNode.KeyNum++ } leftBroBtNode.Childs[leftBroBtNode.KeyNum] = delBtNode.Childs[delBtNode.KeyNum] //处理父节点的key数组和孩子指针数组 因为delBtNode合并到左兄弟中了 所以原先父节点指向delBtNode的指针就要删除了 //key数组因为有一个放到删除节点的左兄弟中 所以其右的所有key往前移动一个 for i := lBroIndexInPChilds; i \u0026lt; leftBroBtNode.Parent.KeyNum; i++ { leftBroBtNode.Parent.Nodes[i] = leftBroBtNode.Parent.Nodes[i+1] } //因为delBtNode合并到左兄弟节点中了 所以父节点中孩子指针数组 delBtNode后边的全部往前移动一位 for i := lBroIndexInPChilds + 1; i \u0026lt;= leftBroBtNode.Parent.KeyNum; i++ { leftBroBtNode.Parent.Childs[i] = leftBroBtNode.Parent.Childs[i+1] } leftBroBtNode.Parent.KeyNum-- if leftBroBtNode.Parent == tree.Root { tree.Root = leftBroBtNode return leftBroBtNode } return leftBroBtNode.Parent } //没有左兄弟节点 合并到右兄弟节点 其中父亲节点中指向左兄弟节点的key也转移到右兄弟节点 //新申请一个slice 先后将delBtNode、父节点、右兄弟的key复制进去 newNodes := make([]*Node, tree.M) i := 0 for ; i \u0026lt; delBtNode.KeyNum; i++ { newNodes[i] = delBtNode.Nodes[i] } //将父节点元素也复制到右兄弟节点 newNodes[i] = rightBroBtNode.Parent.Nodes[rBroIndexInPChilds-1] i++ //将原先兄兄弟中的节点也copy到新申请的slice for j := 0; j \u0026lt; rightBroBtNode.KeyNum; i, j = i+1, j+1 { newNodes[i] = rightBroBtNode.Nodes[j] } rightBroBtNode.Nodes, rightBroBtNode.KeyNum = newNodes, i //新申请一个slice 存放合并后的孩子指针 newChilds := make([]*BTNode, tree.M+1) //先后将delBtNode和rightBroBtNode的孩子指针cp进来 j := 0 for ; j \u0026lt;= delBtNode.KeyNum; j++ { newChilds[j] = delBtNode.Childs[j] } for k := 0; k \u0026lt;= rightBroBtNode.KeyNum; j, k = j+1, k+1 { newChilds[j] = rightBroBtNode.Childs[k] } rightBroBtNode.Childs = newChilds //处理父节点的key数组和孩子节点数组 //有一个key去了右兄弟节点 所以这个key后面的所有key都要前移 for i := rBroIndexInPChilds - 1; i \u0026lt; rightBroBtNode.Parent.KeyNum; i++ { rightBroBtNode.Parent.Nodes[i] = rightBroBtNode.Parent.Nodes[i+1] } //处理孩子指针数组 for i := rBroIndexInPChilds - 1; i \u0026lt;= rightBroBtNode.Parent.KeyNum; i++ { rightBroBtNode.Parent.Childs[i] = rightBroBtNode.Parent.Childs[i+1] } rightBroBtNode.KeyNum-- return rightBroBtNode.Parent }  \nB+树 待补充 Hash 一些哈希函数的性质  input一般无穷\n output有限范围\n 同样的input 同样的output\n 因为input无穷 output有限 必定出现不同的input 同样的output情况 hash碰撞或者hash冲突\n 大量不同的input 经过hash函数后 output上大致均匀分布 也就是hash函数的离散型\n  如果hashcode在output域均匀分布，那么每个hashcode%M,也就是对M取模后 则在0到M-1的范围也是均匀分布的\n制造hash函数 思路  假设手上有1个比较不错的hash函数，针对每一个hashcode 都将其内存一分为二，也就是对于一个Hashcode将其拆分为h1和h2 各占一半字节 然后h1+1*h2 就是一个新的hash算法 同理h1+2*h2也是一个新的hash算法 而且彼此独立。可以改变系数 得到大量的hash函数  当然也可以准备2个hash函数 结果对应分别为h1 h2 按照同样的思想来回组合即可\nhashcode的每一位根其它的位都是独立的 互不相关的，所以这么组合来的就也不相关。\nhash表相关 ​ hash表也就是存放hashcode和数据(数据地址)的地方，hash表通常可以是单链表实现(相同的hashcode用链表链接存放)，Java的是用红黑树，避免了重复扩容带来的代价。\n一些hash应用 1 统计大文件中的重复的行  如果文件太大，比如100T，单台机器是搞不定的(时间太长) 分布式多台机器解决，假设有1000台机器，分布式并发读取每一行，经过同样的hash函数得到hashcode然后对1000取模，分到不同的机器，这样以来就把100T文件大致均匀的分到了1000个机器上面，而且相同的行一定分到了同一台机器上。 然后1000台 每个机器也可以再经过一个hash 扔给不同的线程并发计算 最后综合下结果。  利用了相同输入 相同输出，大量不同输入，结果均匀分布的性质，将大任务搞成小任务，小任务可以继续再小任务。\n设计一个randomePool 题目描述 设计RandomPool结构 【题目】 设计一种结构，在该结构中有如下三个功能: insert(key):将某个key加入到该结构，做到不重复加入。 delete(key):将原本在结构中的某个key移除。 getRandom(): 等概率随机返回结构中的任何一个key。 【要求】 Insert、delete和getRandom方法的时间复杂度都是 O(1)\n思路：  准备2个hashmap。hash1key:value=\u0026lt;元素值:存放次序编号从0开始 \u0026gt;，hash2key:value=\u0026lt;存放次序编号:元素值\u0026gt;\n 添加的时候2个hashmap都加入，存放次序编号+1\n get的时候需要随机就比较简单了 因为从0到N顺序放入的元素及次序都在hash2中了 生成一个从0\u0026mdash;\u0026gt;N的随机数 然后作为key从hash2中拿到其元素值即可\n 删除的时候需要注意 不能直接删除，比如删除了编号为10的元素，在hash2中编号为10的的位置就空了出来，如果随机出来编号10，则会出现问题，所以需要将最后一个元素覆盖编号为10的元素，同时删除最后一个元素，这样元素都还是顺序存放的，编号不会出现空洞，也成功实现了删除， removeIndex为删除元素的编号，removeValue为要删除的元素，size为删除前总元素个数，这个时候删除的大值逻辑如下：\nlastValue=delete(hash2\u0026lt;size-1\u0026gt;);//从hash2删除最后一个元素 delete(hash1\u0026lt;lastValue\u0026gt;);//从hash1删除最后一个元素 hash2\u0026lt;removeIndex\u0026gt;=lastValue;//hash2中用最后一个元素覆盖removeIndex原先的值 实现删除 delete(hash1\u0026lt;removeValue\u0026gt;);//从hash1中删除要删除的元素 hash1\u0026lt;removeIndex\u0026gt;=lastValue;//hash1用最后元素的值覆盖原先要删除的元素 size--; 整体数量减1   代码  转载JAVA\npublic class Code_02_RandomPool { public static class Pool\u0026lt;K\u0026gt; { private HashMap\u0026lt;K, Integer\u0026gt; keyIndexMap; private HashMap\u0026lt;Integer, K\u0026gt; indexKeyMap; private int size; public Pool() { this.keyIndexMap = new HashMap\u0026lt;K, Integer\u0026gt;(); this.indexKeyMap = new HashMap\u0026lt;Integer, K\u0026gt;(); this.size = 0; } public void insert(K key) { if (!this.keyIndexMap.containsKey(key)) { this.keyIndexMap.put(key, this.size); this.indexKeyMap.put(this.size++, key); } } public void delete(K key) { if (this.keyIndexMap.containsKey(key)) { int deleteIndex = this.keyIndexMap.get(key); int lastIndex = --this.size; K lastKey = this.indexKeyMap.get(lastIndex); this.keyIndexMap.put(lastKey, deleteIndex); this.indexKeyMap.put(deleteIndex, lastKey); this.keyIndexMap.remove(key); this.indexKeyMap.remove(lastIndex); } } public K getRandom() { if (this.size == 0) { return null; } int randomIndex = (int) (Math.random() * this.size); // 0 ~ size -1 return this.indexKeyMap.get(randomIndex); } } public static void main(String[] args) { Pool\u0026lt;String\u0026gt; pool = new Pool\u0026lt;String\u0026gt;(); pool.insert(\u0026quot;zuo\u0026quot;); pool.insert(\u0026quot;cheng\u0026quot;); pool.insert(\u0026quot;yun\u0026quot;); System.out.println(pool.getRandom()); System.out.println(pool.getRandom()); System.out.println(pool.getRandom()); System.out.println(pool.getRandom()); System.out.println(pool.getRandom()); System.out.println(pool.getRandom()); } }  \n大数量黑名单查询 题目描述  假设有100亿条黑名单url，设计一个黑名单查询服务 每个url大概64字节，不算其它成本 但url字节存储到内存大概需要640G  思路  全部存储到单机器内存，用不同的set实现，缺点很明显 单台机器很难有这么多内存，而且成本太高 通过hash，将640G内存对应的100亿条黑名单url 大值均匀分布到1000台机器，然后通过rpc通信让1000台机器一起来抗，可以实现，不过成本较高，需要大量的机器 布隆过滤器 大大降低内存使用，同时单台机器即可提供服务，缺点有一定的失误率(非黑名单也会判定会黑名单)，如果可以接受一定的失误率 布隆过滤器应该是最优选择  布隆过滤器  既然要降低内存使用，最简单的思路就是准备比特bit类型的数组，让每一个bit都能代表相应的含义，这样就最大化的利用内存\n 如何让每一位bit都能代表相应的含义 ：\n  假设准备一个M长度的bit类型数组，我们让一个url经过一个hash算法，得到hashcode，然后让这个hashcode对M取模 得到下标index，将bit数组下标为index的位置置为1 ，查找url的时候也是同样的逻辑，经过hash算法得到hashcode，然后对M取模得到下标，然后查看下标为index的位置元素值是否为1。通过这样的hash转换我们就让这个bit数组有了实际含义\n 布隆过滤器 针对不同的失误率要求 往往会准备多个hash，相对更大的bit数组：  关于多个hash：多个hash主要是为了降低hash冲突的概率 只有多个hash对M取模后都是1 才说明是黑名单，只要有一个不是则说明没有进过。\n关于bit数组长度：如果数组长度太短，大量url经过hash和取模后 全部数组都变为了1 那么就全是黑名单了 显然不符合要求。\n M= - (N * lnP) / ( (ln2)^2 ) N为样本量 P为失误率 算出的M为bit类型的长度。100亿数据 失误率万分之一 大概M为16G\n hash函数个数选择 K= ln2 *(M/N) K为hash个数\n M K向上取整后 真实失误率P= (1- E(-N*K/M))\n  一定不存在、可能存在、不能删除 如果经过多个hash对应的bit位如果有一个不是1 则说明一定不在这个集合中(因为如果进过集合 则对应的位置应该全都是1)，否则说明可能存在这个集合，关于可能存在举个例子。\n假设X进行三次hash后对应的bit位是(0,3,6)\nY被三次hash后对应的bit位是(0,3,7)，则Y在bit的0和3的值会覆盖掉X的值，\n假设还有一个新元素Z的hash结果是(1,3,6)，则意味着X的hash结果被全部覆盖，也就是说即使没有X，(0,3,6)位置的值也是1，所以只能是有可能存在。\n也正是因为这种情况 删除的X的时候 不能将对应bit为全部只为0 这样的Y，Z也被剔除集合了。\n几种优化 CBF Counting Bloom Filter，为了支持删除，把原先的每个bit位改为对应的每个counter，每次hash对应的值+1 空间有所增加，有所浪费\nSBF（Spectral Bloom Filter）在 CBF 的基础上提出了元素出现频率查询的概念，将CBF的应用扩展到了 multi-set 的领域；\ndlCBF（d-Left Counting Bloom Filter）利用 d-left hashing 的方法存储 fingerprint，解决哈希表的负载平衡问题；\nACBF（Accurate Counting Bloom Filter）通过 offset indexing 的方式将 Counter 数组划分成多个层级，来降低误判率\n布隆过滤器的其它一些应用： ​ 假设：redis当前放的热点数据，黑客高频非法id数据来查询，就可能出现问题(redis查不到 直接查数据库，那么数据库压力山大；如果查询不到直接将结果全部缓存的redis，那么redis内存压力大，而且这些是非法数据，redis内存淘汰策略可能吧正常的热点数据淘汰掉)。\n如果在redis热点和数据库中间加一个布隆过滤器可能会比较快\n redis热点找不到 再看布隆过滤器在不在，如果不在直接返回client（非法请求） 如果布隆过滤器存在 则去数据库查询(虽然可能存在其实不存在的问题，因为布隆过滤器有一定的失误率，但这个一般比较小) 这样就很大可能地方黑客的攻击  一致性哈希算法基本原理 题目: 服务器集群来设计和实现数据缓存\u0026ndash;常见的策略：\n 无论是添加、查询还是删除数据，都先将数据的id通过哈希函数换成一个哈希值，记为key 如果目前机器有N台，则计算key%N的值，这个值就是该数据所属的机器编号，无论是添加、删除还是查询操作，都只在这台机器上进行。  这样来实现集群的负载均衡 这个跟经典负载均衡算法中的源IP算法有点类似\n上述经典hash负载均衡算法 存在什么问题  如果增加或者删除机器 代表会变得很高，因为原先都是对N取模的，现在要变为对N+1台机器编号取模，之前的所有hash计算都要重新计算 这个代码是比较高的，其实跟hash扩容有点类似  一致性算法原理大值描述 我们假设hashcode的范围为0\u0026mdash;\u0026gt;2^32 ，将其范围想象为一个环\n接下来我们对应不同的机器，根据其特质(假设三台机器 根据其id)，针对其id用hash函数 计算出其hashcode，对应在环上，大致如下:\n​ 现在对于所有input，经过同样的hash函数计算出的hashcode，打到环上，顺时针往前找到的第一个机器idhash就是其要存放的机器，实现上可以将所有机器id的hash值放到排好序的数组，然后使用的时候二分查找第一个\u0026gt;=其hashcode的机器id hashcode即可\n这个时候如果删除节点m2 则将m2机器上的所有数据转移到m3即可，不用把所有数据都全部再hash一次。\n但这样又回引入一个问题，因为这种算法跟经典的少了取模运算，所以分到各个机器上的数量很有可能是不均衡的。\n增加删除机器也可能导致不均衡。\n为了解决这个问题，就引入了虚拟节点技术。即对每一台机器通过不同的哈希函数计算出多个哈希值，对多个位置都放置一个服务节点，称为虚拟节点。具体做法：比如对于machine1的IP192.168.25.132（或机器名），计算出192.168.25.132-1、192.168.25.132-2、192.168.25.132-3\u0026hellip;..192.168.25.132-1000的哈希值，然后对应到环上，其他的机器也是如此，这样的话节点数就变多了，根据哈希函数的性质，平衡性自然会变好：\n引入虚拟节点需要实现一张路由表，要知道机器对应的所有虚拟节点值，根据虚拟节点值也要很快找到对应的机器，而且要注意增加删除节点的时候要根据虚拟节点值先来计算 再对应到所属的机器上进行迁移。\n基于一致性哈希的原理有很多种具体的实现，包括Chord算法、KAD算法等，后续再进一步学习\n并查集 定义 并查集是一种树型的数据结构，用于处理一些不交集（Disjoint Sets）的合并及查询问题。有一个联合-查找算法（union-find algorithm）定义了两个用于此数据结构的操作：\n Find：确定元素属于哪一个子集。它可以被用来确定两个元素是否属于同一子集。 Union：将两个子集合并成同一个集合。  实现 初始化 并查集不适用流结构，也就是不能动态变化，只能在一开始直接初始化好，刚开始的时候一个元素构成一个节点 并且父节点指向自身\n合并 可以对任意两个元素进行合并操作。值得注意的是，union(nodeA,nodeB)并不是将结点nodeA和nodeB合并成一个集合，而是将nodeA所在的集合和nodeB所在的集合合并成一个新的子集，大值图解如下:\n代表节点：就是一个集合中谁的父节点指向自己，强行规定，刚开始ab节点独立，2个集合，代表节点都是自身，然后合并ab节点\n现在ab节点在一个集合，代表节点就是a，因为其父节点指向自身，一般合并的时候将集合节点数小的集合直接合并到节点数大的集合中，合并操作其实也就是将size小的集合的代表节点的父节点指针改为节点数大的集合的代表节点，相同size大小 随意\n查找 查询2个节点是否在同一个集合，也就是网上找到它的代表节点 看是否同一个，同时在查找的过程中，该元素到代表节点上的所有节点的父节点都直接改为代表节点，这样以来下次再查找的时候效率就更好了，只需查找1次就搞定了。\n代码实现 ​ 可以用2个hashmap实现：\n fartherMap\u0026lt;节点,对应父节点\u0026gt; sizeMap\u0026lt;代表节点,集合节点个数\u0026gt; 刚开始加入farther每个节点都入hash，父节点都指向自己，sizemap代表节点就是自己，元素个数为1 合并的时候 注意修改被合并集合代表节点的父节点指针 同时修改合并后集合代表集合对应的集合个数即可 查找的时候注意将被被查找元素网上的所有非代表节点的父节点都直接指向代表节点，提高下次查找效率   转载java 自己实现也很简单\npublic static class Node { // whatever you like } public static class UnionFindSet { public HashMap\u0026lt;Node, Node\u0026gt; fatherMap; public HashMap\u0026lt;Node, Integer\u0026gt; sizeMap; public UnionFindSet() { fatherMap = new HashMap\u0026lt;Node, Node\u0026gt;(); sizeMap = new HashMap\u0026lt;Node, Integer\u0026gt;(); } public void makeSets(List\u0026lt;Node\u0026gt; nodes) { fatherMap.clear(); sizeMap.clear(); for (Node node : nodes) { fatherMap.put(node, node); sizeMap.put(node, 1); } } private Node findHead(Node node) { Node father = fatherMap.get(node); if (father != node) { father = findHead(father); } fatherMap.put(node, father); return father; } public boolean isSameSet(Node a, Node b) { return findHead(a) == findHead(b); } public void union(Node a, Node b) { if (a == null || b == null) { return; } Node aHead = findHead(a); Node bHead = findHead(b); if (aHead != bHead) { int aSetSize= sizeMap.get(aHead); int bSetSize = sizeMap.get(bHead); if (aSetSize \u0026lt;= bSetSize) { fatherMap.put(aHead, bHead); sizeMap.put(bHead, aSetSize + bSetSize); } else { fatherMap.put(bHead, aHead); sizeMap.put(aHead, aSetSize + bSetSize); } } } }  \n前缀树 相关介绍 前缀树是一种存储字符串的高效容器，基于此结构的操作有：\n insert插入一个字符串到容器中 search容器中是否存在某字符串，返回该字符串进入到容器的次数，没有则返回0 delete将某个字符串进入到容器的次数减1 prefixNumber返回所有插入操作中，以某个串为前缀的字符串出现的次数  设计思路：该结构的重点实现在于存储。前缀树以字符为存储单位，将其存储在结点之间的树枝上而非结点上，如插入字符串abc之后前缀树如下：\ninsert操作逻辑： ​ 每次插入字符串，将字符串改为字符数组，逐个遍历，看看树头是否有岛该字符的路径，如果有树的指针往下走，然后对下一个字符执行相同的操作，比如插入\u0026rdquo;abc\u0026rdquo;，发现存在abc的路径，不新增节点，只是将到达该节点的次数+1,同时以c结尾的次数+1.\n如果插入\u0026rdquo;abde\u0026rdquo; 则ab2个字符不用新增节点 因为不存爱b\u0026ndash;\u0026gt;d的路 所以需要新增节点\n节点保存的时候需要额外保存2个信息(到达该字符的次数 path，以该字符结尾的字符串个数 endNum)\n查找“abc”字符串出现的次数 1. 前缀树是否有a的路径 有则继续 没有返回0 2. a有没有指向b的路径 有则继续 没有返回0 3. b有没有指向c的路径 没有返回0，有则返回以c为结束字符的个数 endNUm  查找以\u0026rdquo;ab\u0026rdquo;打头的字符串的个数  前缀树是否有到a的路径，有则继续 没有返回0 是否有a到b的路径 没有返回0，有则返回到b的路径次数 path  删除逻辑 比如删除字符串abc\n 首先字符串\u0026rdquo;abc\u0026rdquo;出现的次数是否\u0026gt;0 如果没有出现过 则直接返回，否则继续 找到指向a的路径，对应path\u0026ndash; 如果path减后变为0 则说明以a打头的只有一个abc 直接将指向a的路径置空返回 c++注意释放内存 找到指向b的路径 对应path\u0026ndash; 如果path减后变为0 则说明以ab打头的只有一个abc 直接将指向b的路径置空返回 c++注意释放内存 找到指向c的路径 对应path\u0026ndash; endNum\u0026ndash; 如果path减后变为0 则说明以ab打头的只有一个abc 直接将指向c的路径置空返回 c++注意释放内存  代码实现  转载JAVA\npackage class_07; public class Code_01_TrieTree { public static class TrieNode { public int path; public int end; public TrieNode[] nexts; public TrieNode() { path = 0; end = 0; nexts = new TrieNode[26]; } } public static class Trie { private TrieNode root; public Trie() { root = new TrieNode(); } public void insert(String word) { if (word == null) { return; } char[] chs = word.toCharArray(); TrieNode node = root; int index = 0; for (int i = 0; i \u0026lt; chs.length; i++) { index = chs[i] - 'a'; if (node.nexts[index] == null) { node.nexts[index] = new TrieNode(); } node = node.nexts[index]; node.path++; } node.end++; } public void delete(String word) { if (search(word) != 0) { char[] chs = word.toCharArray(); TrieNode node = root; int index = 0; for (int i = 0; i \u0026lt; chs.length; i++) { index = chs[i] - 'a'; if (--node.nexts[index].path == 0) { node.nexts[index] = null; return; } node = node.nexts[index]; } node.end--; } } public int search(String word) { if (word == null) { return 0; } char[] chs = word.toCharArray(); TrieNode node = root; int index = 0; for (int i = 0; i \u0026lt; chs.length; i++) { index = chs[i] - 'a'; if (node.nexts[index] == null) { return 0; } node = node.nexts[index]; } return node.end; } public int prefixNumber(String pre) { if (pre == null) { return 0; } char[] chs = pre.toCharArray(); TrieNode node = root; int index = 0; for (int i = 0; i \u0026lt; chs.length; i++) { index = chs[i] - 'a'; if (node.nexts[index] == null) { return 0; } node = node.nexts[index]; } return node.path; } } public static void main(String[] args) { Trie trie = new Trie(); System.out.println(trie.search(\u0026quot;zuo\u0026quot;)); trie.insert(\u0026quot;zuo\u0026quot;); System.out.println(trie.search(\u0026quot;zuo\u0026quot;)); trie.delete(\u0026quot;zuo\u0026quot;); System.out.println(trie.search(\u0026quot;zuo\u0026quot;)); trie.insert(\u0026quot;zuo\u0026quot;); trie.insert(\u0026quot;zuo\u0026quot;); trie.delete(\u0026quot;zuo\u0026quot;); System.out.println(trie.search(\u0026quot;zuo\u0026quot;)); trie.delete(\u0026quot;zuo\u0026quot;); System.out.println(trie.search(\u0026quot;zuo\u0026quot;)); trie.insert(\u0026quot;zuoa\u0026quot;); trie.insert(\u0026quot;zuoac\u0026quot;); trie.insert(\u0026quot;zuoab\u0026quot;); trie.insert(\u0026quot;zuoad\u0026quot;); trie.delete(\u0026quot;zuoa\u0026quot;); System.out.println(trie.search(\u0026quot;zuoa\u0026quot;)); System.out.println(trie.prefixNumber(\u0026quot;zuo\u0026quot;)); } }  \n经典题目 一个字符串类型的数组arr1，另一个字符串类型的数组arr2：\n arr2中有哪些字符，是arr1中出现的？请打印 arr2中有哪些字符，是作为arr1中某个字符串前缀出现的？请打印 arr2中有哪些字符，是作为arr1中某个字符串前缀出现的？请打印arr2中出现次数最大的前缀  将2个数组遍历构建一个前缀树，后面的判断利用前缀树实现。\n动态规划 暴力递归与动态规划的关系 ​ 暴力递归：\n 把问题转化为规模缩小了的同类问题的子问题 有明确的不需要继续进行递归的条件(base case) 有当得到了子问题的结果之后的决策过程 不记录每一个子问题的解  动态规划：\n 从暴力递归中来\n 将每一个子问题的解记录下来，避免重复计算\n 把暴力递归的过程，抽象成了状态表达\n 并且存在化简状态表达，使其更加简洁的可能\n  动态规划由暴力递归而来，是对暴力递归中的重复计算的一个优化，策略是空间换时间\n暴力递归存在重复计算的状态，而且这些状态跟从什么位置到来这个地方没有关系(无后效性问题)，都可以改为动态规划。\n求N！N的阶乘问题 暴力递归  如果知道N-1的阶乘 那么就知道了N!=N*f(N-1) basecase为 当N为1时候 f(1)=1 不需要再次递归 当知道f(N-1)就知道了f(N)  递归代码 int getFactorial(int N){ if( N==1){//base case 不用再递归了 return 1; } return N*getFactorial(N-1); }  优化暴力递归  知道了f(1)=1 就知道了f(2)=2 * f(1)=1 * 2 就知道了f(3)=3 * f(2)=1 * 2 * 3 也就可以直接计算了\nint getFactorial_1(int N){ int res=1; for(int i=1;i\u0026lt;=N;++i){ res*=i; } return res; }   汉诺塔问题 题目描述 汉诺塔（又称河内塔）问题是源于印度一个古老传说的益智玩具。大梵天创造世界的时候做了三根金刚石柱子，在一根柱子上从下往上按照大小顺序摞着64片黄金圆盘。大梵天命令婆罗门把圆盘从下面开始按大小顺序重新摆放在另一根柱子上。并且规定，在小圆盘上不能放大圆盘，在三根柱子之间一次只能移动一个圆盘。\n如下图所示，从左到右有A、B、C三根柱子，其中A柱子上面有从小叠到大的n个圆盘，现要求将A柱子上的圆盘移到C柱子上去，期间只有一个原则：一次只能移到一个盘子且大盘子不能在小盘子上面，求移动的步骤和移动的次数\n递归思路  假设有N都在A上 递归步骤如下:  1.1 首先肯定是将上面的N-1 移动到B(辅助)，\n1.2 然后将A只剩下的一个 直接移动到C\n1.3 然后将B上面的N-1移动到C 解决问题\n base case如果只剩下一个 直接移动到目标即可\n//A就是from B就是help C就是to 返回移动次数 int hanoi(int N,string from,string help,string to){ int count=0;//移动次数 count+=hanoi(N-1,from,to,help);//首先肯定是将上面的N-1 移动到B 这个时候可以用C辅助 cout\u0026lt;\u0026lt;N\u0026lt;\u0026lt;\u0026quot;从\u0026quot;\u0026lt;\u0026lt;from\u0026lt;\u0026lt;\u0026quot;移动到\u0026quot;\u0026lt;\u0026lt;to\u0026lt;\u0026lt;endl;//然后将A只剩下的一个 直接移动到C count++;//累计移动次数 count+=haoni(N-1,help,from,to);//然后将B上面的N-1移动到C 解决问题 return count; }   最小路径和 给你一个二维数组，二维数组中的每个数都是正数，要求从左上角走到右下角，每一步只能向右或者向下。沿途经过的数字要累加起来。返回最小的路径和。\n遇到类似题目，往往先写出一个最基础版本的递归，然后再考虑优化\n暴力递归思路 只能往右或者往下，所以对于一个点P1(iBegin,jBegin)到另外一个点P2(iEnd,jEnd)的最小路径和就等于 min( F(P1.right),F(P1.Down) )+value(iBegin,jBegin),当然对于i,j有一些边界要处理，比如i到达了最下面的行，只能往右，j到达了最右边的列只能往下。\nbasecase也就是递归终止条件为 当 i == iEnd \u0026amp;\u0026amp; j == jEnd,也就是到达了终点，返回终点坐标的value即可。\n//转载Java public static int minPathSum(int matrix[][], int i, int j) { // 如果(i,j)就是右下角的元素 if (i == matrix.length - 1 \u0026amp;\u0026amp; j == matrix[0].length - 1) { return matrix[i][j]; } // 如果(i,j)在右边界上，只能向下走 if (j == matrix[0].length - 1) { return matrix[i][j] + minPathSum(matrix, i + 1, j); } // 如果(i,j)在下边界上，只能向右走 if (i == matrix.length - 1) { return matrix[i][j] + minPathSum(matrix, i, j + 1); } // 不是上述三种情况，那么(i,j)就有向下和向右两种决策，取决策结果最小的那个 int left = minPathSum(matrix, i, j + 1); int down = minPathSum(matrix, i + 1, j); return matrix[i][j] + Math.min(left,down ); } public static void main(String[] args) { int matrix[][] = { { 9, 1, 0, 1 }, { 4, 8, 1, 0 }, { 1, 4, 2, 3 } }; System.out.println(minPathSum(matrix, 0, 0)); //14 }  这里假设为3*4的矩阵 从(0,0)走到(2,3) f(0,0)需要计算f(0,1)和f(1,0), f(1,0)需要计算f(1,1)和f(2,0) f(0,1) 需要计算f(1,1)和f(2,1),\n暴力递归 f(1,1)会存在重复计算 所以就浪费时间，最简单的优化可以把f(1,1)计算前，先判断是否已经计算过了，计算过了就直接使用，\n如果没有计算过，计算完后就记下来(比如 map map[\u0026ldquo;1_1\u0026rdquo;]=xxx).\n优化 ​ 由暴力递归改为动态规划的核心就是将子步骤的计算结果保存下来，从而达到空间换时间的目的，那么minPath(int matrix[][],int i,int j)中变量i和j的不同取值将导致i*j种结果，我们将这些结果保存在一个i*j的表中，假设叫做DP，DP(i,j)就是坐标i,j到终点的最小路径和。\nbasecase为右下角的3，最后一行和最后一列其实可以直接从右往左，从下往上直接推出结果，接下来对于倒数第二行和倒数第二列也是同样的从右往左，从下往上直接推出结果。\n​ 整个过程没有重复计算，所以动态规划问题就是优化暴力递归，所以首先要写出暴力递归版本，然后分析可变参数，看看那些返回值能够代表返回值的状态，可变参数是几纬的，状态结果表就是几纬的。 然后检查basecase，看看那些可以直接得到结果，对于一个普遍的状态看看它的依赖状态，然后按照相反的顺序推结果。\n代码  动态规划求最小路径和 转载Java\npackage class_08; public class Code_07_MinPath { public static int minPath1(int[][] matrix) { return process1(matrix, matrix.length - 1, matrix[0].length - 1); } //递归版本 public static int process1(int[][] matrix, int i, int j) { int res = matrix[i][j]; if (i == 0 \u0026amp;\u0026amp; j == 0) { return res; } if (i == 0 \u0026amp;\u0026amp; j != 0) { return res + process1(matrix, i, j - 1); } if (i != 0 \u0026amp;\u0026amp; j == 0) { return res + process1(matrix, i - 1, j); } return res + Math.min(process1(matrix, i, j - 1), process1(matrix, i - 1, j)); } public static int minPath2(int[][] m) { if (m == null || m.length == 0 || m[0] == null || m[0].length == 0) { return 0; } int row = m.length; int col = m[0].length; int[][] dp = new int[row][col]; dp[0][0] = m[0][0]; for (int i = 1; i \u0026lt; row; i++) { dp[i][0] = dp[i - 1][0] + m[i][0]; } for (int j = 1; j \u0026lt; col; j++) { dp[0][j] = dp[0][j - 1] + m[0][j]; } for (int i = 1; i \u0026lt; row; i++) { for (int j = 1; j \u0026lt; col; j++) { dp[i][j] = Math.min(dp[i - 1][j], dp[i][j - 1]) + m[i][j]; } } return dp[row - 1][col - 1]; } // for test public static int[][] generateRandomMatrix(int rowSize, int colSize) { if (rowSize \u0026lt; 0 || colSize \u0026lt; 0) { return null; } int[][] result = new int[rowSize][colSize]; for (int i = 0; i != result.length; i++) { for (int j = 0; j != result[0].length; j++) { result[i][j] = (int) (Math.random() * 10); } } return result; } public static void main(String[] args) { int[][] m = { { 1, 3, 5, 9 }, { 8, 1, 3, 4 }, { 5, 0, 6, 1 }, { 8, 8, 4, 0 } }; System.out.println(minPath1(m)); System.out.println(minPath2(m)); m = generateRandomMatrix(6, 7); System.out.println(minPath1(m)); System.out.println(minPath2(m)); } }  \n数组中任意数的和是否为Aim值 给你一个数组arr，和一个整数aim。如果可以任意选择arr中的数字，能不能累加得到aim，返回true或者false。\n思路 ​ 跟字符串的子序列类似，针对数组中的数只有2中状态，要或者不要，所以直接暴力递归\n//转载java //arr为原数组 aim为目标和 i，sum代表来到了下标为i的位置已经得到的sum值 public static boolean isSum(int arr[], int aim, int sum,int i) { //决策完毕 if (i == arr.length) {//最后一个元素也已经判断完毕 就看sum是否有累计为aim的 return sum == aim; } //决策来到了arr[i]：加上arr[i]或不加上。将结果扔给下一级 return isSum(arr, aim, sum + arr[i], i + 1) || isSum(arr, aim, sum, i + 1); }  优化 ​ 我们假设数组都是整数，分析函数的可变参数，只有sum和i可以变化，数组长度为N，i的变化范围就是N，\nsum的变化范围是0\u0026mdash;\u0026gt;所有数组元素之和。建立一个二维表，就拿数组[1,3,6] aim为9举例\n代码  动态规划求数组任意数和是否为aim 转载Java\npackage class_08; public class Code_08_Money_Problem { public static boolean money1(int[] arr, int aim) { return process1(arr, 0, 0, aim); } public static boolean process1(int[] arr, int i, int sum, int aim) { if (sum == aim) { return true; } // sum != aim if (i == arr.length) { return false; } return process1(arr, i + 1, sum, aim) || process1(arr, i + 1, sum + arr[i], aim); } public static boolean money2(int[] arr, int aim) { boolean[][] dp = new boolean[arr.length + 1][aim + 1]; for (int i = 0; i \u0026lt; dp.length; i++) { dp[i][aim] = true; } for (int i = arr.length - 1; i \u0026gt;= 0; i--) { for (int j = aim - 1; j \u0026gt;= 0; j--) { dp[i][j] = dp[i + 1][j]; if (j + arr[i] \u0026lt;= aim) { dp[i][j] = dp[i][j] || dp[i + 1][j + arr[i]]; } } } return dp[0][0]; } public static void main(String[] args) { int[] arr = { 1, 4, 8 }; int aim = 12; System.out.println(money1(arr, aim)); System.out.println(money2(arr, aim)); } }  \n背包问题 题目描述 一些算法题目 反转链表 题目描述 反转一个单链表。示例:\n输入: 1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;5-\u0026gt;NULL 输出: 5-\u0026gt;4-\u0026gt;3-\u0026gt;2-\u0026gt;1-\u0026gt;NULL 进阶: 你可以迭代或递归地反转链表。你能否用两种方法解决这道题？\n来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/reverse-linked-list 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。\n解答1 双指针逐个反转2个节点  声明2个指针p1 p2,p1先指向NULL,p2指向head. p2永远在p1前面 p2的next指向p1,然后p1,p2都向前走一步(当然要先记下来p2的next),直到p2为NULL 循环结束 p1将指向链表原来的最后一个节点，也就是新链表的头节点  代码 While (p2 !=null){ *tmp=p2-\u0026gt;next; p2-\u0026gt;next=p1; p1=p2;p2=tmp; } return p1;  解答2 递归实现 假设链表为 1\u0026ndash;\u0026gt;2\u0026ndash;\u0026gt;3\u0026ndash;\u0026gt;NULL\n 思路就是从头到尾将每个元素开始依次入函数栈，同时如果是最后一个节点 则记录这个节点最后此节点作为新链表的头节点返回  然后函数栈返回的时候，将当前节点的next节点的next指向当前节点 逐个完成反转 下面的网上找到的动图\n代码实现 Node* reverseList(Node* cur){ if ( cur==NULL || cur-\u0026gt;next==NULL){ return cur;//如果当前节点为空 或者当前节点没有后继节点 那么直接返回当前节点即可 } Node* ret=reverseList(cur-\u0026gt;next);//将节点的next节点入函数栈 ret最后指向就是原链表最后一个节点 cur-\u0026gt;next-\u0026gt;next=cur;//将当前节点的next节点的next节点 指向自己 完成局部反转 cur-\u0026gt;next=NULL;//将当前节点的next指针先指向NULL }  求数组小和 题目描述 ​ 在一个数组中，每一个数左边比当前数小的数累加起来，叫做这个数组的小和。求一个数组 的小和。例子: [1,3,4,2,5]\n1左边比1小的数，没有;\n3左边比3小的数，1;\n4左边比4小的数，1、3;\n2左边比2小的数，1;\n5左边比5小的数，1、3、4、2;\n所以小和为1+1+3+1+1+3+4+2=16\n最简单的解法 int smallNum(int a[],int len){ int num=0; for(int i=1;i\u0026lt;len;++i){ for(int j=0;j\u0026lt;i;++j){ if(a[j]\u0026lt;a[i]) num+=a[j]; } } return num; }  暴力搜索，针对每个元素 都遍历左边比它小的 然后累计，2层循环 时间复杂度O($N^2$)\n归并排序优化到O(N*logN)  左边比它小的数字相加 其实就是找一个数右边有多少个数比它大(假设为a) 那么这个数就会产生a*当前数的小和，所以归并排序的过程刚好可以加速，因为右边区间某个数如果比左边区间当前数大，那么右边区间这个数后面的所有元素都比左边区间这个数大  代码  归并排序求数组小和\nint merge2Slice(int a[],int l,int mid,int r){ int num=0; int *help= new int[r-l+1];//声明1个辅助数组 合并后先放入help数组 然后在copy回原数组 int l1=l,r1=mid,l2=mid+1,r2=r;//便于理解 分割成为2个区间 l1--r1 l2--r2 int cur1=l1,cur2=l2,hIndex=0;//刚开始下标分别指向2个区间的开始位置 辅助数组的下标刚开始赋值为0 while (cur1\u0026lt;=r1 \u0026amp;\u0026amp; cur2\u0026lt;=r2 ){//任意1个区间遍历完成退出循环 if (a[cur1]\u0026lt;a[cur2]){ num+=( a[cur1] * (r2-cur2+1) );//因为当前数小于另外一个 则炸出一个小和 help[hIndex++]=a[cur1++];//谁小谁进辅助数组 同时下标++ }else{ help[hIndex++]=a[cur2++]; } } while (cur1\u0026lt;=r1){//区间1 还有数据没有复制到help数组 把剩下的全部复制到辅助数组 help[hIndex++]=a[cur1++]; } while ( cur2\u0026lt;=r2){//区间1 还有数据没有复制到help数组 把剩下的全部复制到辅助数组 help[hIndex++]=a[cur2++]; } //将help数组复制回原数组 for (int i=0;i\u0026lt;=(r-l);++i){ a[l+i]=help[i]; } delete[] help; return num; } //归并排序递归实现 没做边界检查版本 同时返回对应的小和 int mergeSortRecur(int A[],int l,int r){ //base case 如果l==r 则直接返回 只有一个元素小和返回0 if (l==r){ return 0; } int mid=l + ( (r-l)\u0026gt;\u0026gt;1 ); int smallNumL=mergeSortRecur(A,l,mid);//左半边归并排序 int smallNumR=mergeSortRecur(A,mid+1,r);//右半边归并排序 return smallNumL+smallNumR+merge2Slice(A,l,mid,r);//将2个分片合并 }  \n数组逆序对问题 题目描述 在一个数组中，左边的数如果比右边的数大，则折两个数构成一个逆序对，请打印所有逆序对\n暴力算法时间复杂度为O($N^2$)\n也可以才有归并排序优化时间复杂度为O(NlogN)\n 代码\n//在一个数组中，左边的数如果比右边的数大，则折两个数构成一个逆序对，请打印所有逆序 对 int getReversePairs(vector\u0026lt;int\u0026gt;\u0026amp; nums){ int count=0; for (int i=0;i\u0026lt;nums.size()-1;++i){ for (int j=i+1;j\u0026lt;nums.size();++j){ if (nums[i]\u0026gt;nums[j]) count++; } } return count; } //采用归并排序优化 int merge2Slice1(vector\u0026lt;int\u0026gt;\u0026amp; a,int l,int mid,int r){ int count=0; int *help= new int[r-l+1];//声明1个辅助数组 合并后先放入help数组 然后在copy回原数组 int l1=l,r1=mid,l2=mid+1,r2=r;//便于理解 分割成为2个区间 l1--r1 l2--r2 int cur1=l1,cur2=l2,hIndex=0;//刚开始下标分别指向2个区间的开始位置 辅助数组的下标刚开始赋值为0 while (cur1\u0026lt;=r1 \u0026amp;\u0026amp; cur2\u0026lt;=r2 ){//任意1个区间遍历完成退出循环 if(a[cur2]\u0026lt;a[cur1]){//如果右边小于左边区间 右边数组先进help 同时右边区间下标++ count+=(r1-cur1+1); help[hIndex++]=a[cur2++]; }else if (a[cur2]==a[cur1]){//如果相等 则先cp左边 左边区间++ 右边区间不动因为要计算逆序对 help[hIndex++]=a[cur1++]; }else{//如果左边区间大于左边区间 则左边区间进辅助数组 左边区间下标++ help[hIndex++]=a[cur1++]; } } while (cur1\u0026lt;=r1){//区间1 还有数据没有复制到help数组 把剩下的全部复制到辅助数组 help[hIndex++]=a[cur1++]; } while ( cur2\u0026lt;=r2){//区间1 还有数据没有复制到help数组 把剩下的全部复制到辅助数组 help[hIndex++]=a[cur2++]; } //将help数组复制回原数组 for (int i=0;i\u0026lt;=(r-l);++i){ a[l+i]=help[i]; } delete[] help; return count; } //归并排序递归实现 没做边界检查版本 同时返回对应的逆序对数量 int mergeSortRecur1(vector\u0026lt;int\u0026gt;\u0026amp; nums,int l,int r){ //base case 如果l==r 则直接返回 只有一个元素小和返回0 if (l==r){ return 0; } int mid=l + ( (r-l)\u0026gt;\u0026gt;1 ); int reParisNumL=mergeSortRecur1(nums,l,mid);//左半边归并排序 并返回逆序对数量 int reParisNumR=mergeSortRecur1(nums,mid+1,r);//右半边归并排序 return reParisNumL+reParisNumR+merge2Slice1(nums,l,mid,r);//将2个分片合并 } //在一个数组中，左边的数如果比右边的数大，则折两个数构成一个逆序对，请打印所有逆序 归并排序优化版本 int getReversePairs1(vector\u0026lt;int\u0026gt;\u0026amp; nums){ return mergeSortRecur1(nums,0,nums.size()-1); }  \n数组分区\u0026lt;=左边 \u0026gt;右边 //问题1 //给定一个数组arr，和一个数num，请把小于等于num的数放在数 组的左边，大于num的数放在数组的右边。 // 要求额外空间复杂度O(1)，时间复杂度O(N) 返回\u0026lt;=num的第后一个下标 int partition1(int a[], int l, int r, int num) { int less = l - 1,cur=l;//指针先指向最左边元素的前一个位置 less为小于等于区域的边界 下标\u0026lt;=less的 都是\u0026lt;=num的 while (cur\u0026lt;=r) { if (a[cur]\u0026lt;=num){//如果当前元素\u0026lt;=num 则将less下一个位置的元素 跟当前元素交换 同时less++ 扩大\u0026lt;=区域 swap(a,++less,cur++); }else{ cur++; } } return less; }  荷兰国旗问题 //问题2 荷兰国旗 // 给定一个数组arr，和一个数num，请把小于num的数放在数组的 左边，等于num的数放在数组的中间，大于num的数放在数组的 右边。 // 要求额外空间复杂度O(1)，时间复杂度O(N) void partition2(int arr[], int l, int r, int num,int\u0026amp; lastLess,int\u0026amp; firstMore) { int less = l - 1,cur=l;//less先指向最左边元素的前面一个位置 下标\u0026lt;=less的元素都为\u0026lt;num的区域 int more = r + 1;//more先指向最右边边元素的后面一个位置 下标\u0026gt;=more的元素都为\u0026gt;num的区域 //同理 less+1--\u0026gt;more-1的区域为=num的区域 while (cur \u0026lt; more) {//cur指针刚开始指向最左边的元素 如果碰到了more就说明遍历完成了 if (arr[cur] \u0026lt; num) {//如果当前元素\u0026lt;num 则将less下一个位置的元素 跟当前元素交换 同时less++ 扩大\u0026lt;区域 cur++遍历下一个元素 swap(arr, ++less, cur++); } else if (arr[cur] \u0026gt; num) {//如果当前元素\u0026gt;num 则将more下一个位置的元素 跟当前元素交换 同时more-- 扩大\u0026gt;区域 cur不能++因为 more前面的元素还没有遍历比较 swap(arr, --more, cur); } else { cur++;//如果相等 cur直接++遍历下一个元素 } } lastLess=less+1,firstMore=more-1; return; }  荷兰国旗可以优化快速排序\n数组中位数 题目描述 如何得到一个数据流中的中位数？如果从数据流中读出奇数个数值，那么中位数就是所有数值排序之后位于中间的数值。如果从数据流中读出偶数个数值，那么中位数就是所有数值排序之后中间两个数的平均值。\n例如，\n[2,3,4] 的中位数是 3\n[2,3] 的中位数是 (2 + 3) / 2 = 2.5\n设计一个支持以下两种操作的数据结构：\nvoid addNum(int num) - 从数据流中添加一个整数到数据结构中。 double findMedian() - 返回目前所有元素的中位数。\n来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/shu-ju-liu-zhong-de-zhong-wei-shu-lcof 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。\n思路 准备2个堆 一个大堆 一个小堆 一个个加入堆\n 如果大堆size为0 直接进大堆\n 如果\u0026lt;=大堆堆顶 进大堆\n加入后 判断大堆size-小堆size如果\u0026gt;=2 也就是大堆数据太多了 则弹出大堆的堆顶 放入小堆\n 如果\u0026gt;大堆堆顶 进小堆\n  加入后 判断小堆size-大堆size如果\u0026gt;=2 也就是小堆数据太多了 则弹出小堆的堆顶 放入大堆\n这样的操作下来 大堆小堆数据量平均 同时较小的部分都在大堆 较大的部分都在小堆 堆结构的堆顶又比较特殊，\n所以大堆的堆顶 存放的是较小部分的最大值，小堆的堆顶存放的是较大部分的最小值 所以如果是偶数，直接2个堆顶相加除以2即可\n如果是奇数，哪个堆size大就返回其堆顶\n代码  求数组中位数\nclass MedianFinder { public: /** initialize your data structure here. */ priority_queue\u0026lt;int\u0026gt; maxq; priority_queue \u0026lt; int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt; \u0026gt; minq; MedianFinder() { } void addNum(int num) { if (maxq.size()==0 ){//如果大顶堆为空 先插入大顶堆 maxq.push(num); }else if (num\u0026lt;=maxq.top()){//如果小于等于大顶堆的堆顶 则放入大顶堆 maxq.push(num); if ( maxq.size()-minq.size()\u0026gt;=2){//大顶堆放多了 将其堆顶弹出 放入小顶堆 minq.push(maxq.top()); maxq.pop(); } }else{//如果大于大顶堆的堆顶 则放入小顶堆 minq.push(num); if ( minq.size()-maxq.size()\u0026gt;=2){//小顶堆放多了 将其堆顶弹出 放入大顶堆 maxq.push(minq.top()); minq.pop(); } } } double findMedian() { if (minq.size()==0 \u0026amp;\u0026amp; maxq.size()\u0026gt;0){ return double(maxq.top()); }else if( minq.size()\u0026gt;0 \u0026amp;\u0026amp; maxq.size()\u0026gt;0){ if ( (minq.size()+maxq.size())%2==0){ return double(minq.top()+maxq.top())/2; }else{ return maxq.size()\u0026gt;minq.size()?maxq.top():minq.top(); } } return 0; } }; /** * Your MedianFinder object will be instantiated and called as such: * MedianFinder* obj = new MedianFinder(); * obj-\u0026gt;addNum(num); * double param_2 = obj-\u0026gt;findMedian(); */  \n数组排序后相邻2位数的最大差值 题目描述 给定一个数组，求如果排序之后，相邻两数的最大差值，要求时 间复杂度O(N)，且要求不能用非基于比较的排序\n思路 首先常见的基于比较的排序时间复杂度做不到O(N)，然后又不能用桶排序，所以其实就是想说能不能不排序，也能解决问题，这里用到桶排序的思想，但是不真正排序。\n 假设数组有N个数，先找到最小值min，最大值max，准备N+1个桶\n min放到0号桶 max放N+1号桶，其它数据按照一定规律分配到桶中 (int) ((num - min) * len / (max - min))，其中len为数组长度，num为某一个具体的数\n  比如最小值0 最大值99，数组长度60 每个桶可以承载的数量是平均的，因为有N+1个桶，所以一定有桶是空的，因为每个桶容量平均，所以最大差值一定不在桶内产生，所以每个桶只需要记录入桶的最大最小值以及是否有数据入桶即可，比较所有相邻的非空桶，后面桶的最小减去前面桶的最大就是差值，遍历找到最大差值即可\n代码  不排序求数组中相邻2个数的最大差值O(N)\n// 给定一个数组，求如果排序之后，相邻两数的最大差值，要求时 间复杂度O(N)，且要求不能用非基于比较的排序。 #include \u0026lt;climits\u0026gt; #include\u0026lt;iostream\u0026gt; #include\u0026lt;vector\u0026gt; using namespace std; struct Node{ Node():isIn(false),min(INT_MAX),max(INT_MIN){} bool isIn;//是否入桶了 int min; int max; }; //传入数组元素num 数组长度len 数组中最小值min，最大值max 返回元素num应该放到第几号桶 int bucket(long num, long len, long min, long max) { return (int) ((num - min) * len / (max - min));//min在0桶 max在最后一个桶 } int maxGap(int nums[],int len) { if (len \u0026lt; 2) { return 0; } int min = INT_MAX; int max = INT_MIN; for (int i = 0; i \u0026lt; len; i++) {//遍历找到最大最小值 min = std::min(min, nums[i]); max = std::max(max, nums[i]); } if (min == max) {//如果最大最小值相等 则直接返回0 即可 return 0; } vector\u0026lt;Node\u0026gt; help(len+1);//辅助数组 int bid = 0;//计算得到放到第几号桶 for (int i = 0; i \u0026lt; len; i++) { bid = bucket(nums[i], len, min, max); if (!help[i].isIn){ help[i].min=help[i].max=nums[i]; help[i].isIn=true; }else{ help[i].min=std::min(help[i].min,nums[i]); help[i].max=std::max(help[i].max,nums[i]); } } int res = 0; int lastMax = help[0].max;//保存前一个非空桶中的最大值 刚开始为0号桶的最大值 int i = 1; for (; i \u0026lt;= len; i++) {//从1号桶开始遍历 0号桶一定不空因为放了min if (help[i].isIn) { res = std::max(res, help[i].min - lastMax);// 相邻2个非空桶 后一个的min-前一个max就是可能的最大差值 res保存最大差值 lastMax = help[i].max; } } return res; }  \n数组实现大小固定的队列和栈 栈  实现栈比较简单，定义一个指针或者说int类型的下标，刚开始指向0号下标位置，insertIndex刚开始赋值为0，顾名思义，insertIndex就是新插入元素的位置  每次插入元素insertIndex++ 每次弹出元素，对应下标为 insertIndex-1,弹出后insertIndex\u0026ndash; 边界值控制 insertIndex为0 不能弹出，insertIndex为数组长度，也就是最后一个元素后面，不能再插入。   栈代码  数组实现固定大小的栈 \ntemplate\u0026lt;typename T\u0026gt; struct ArrayStack { private: T* data;//数组指针 int insIndex;//保存下一个push元素时对应的插入位置指针 也可以由其计算出当前栈真正的元素个数 int capacity;//最大容量 public: ArrayStack(int intiCapacity) { data=new T[intiCapacity]; capacity=intiCapacity; insIndex=0;//插入位置刚赋值为0 } T peek() ;//返回栈顶元素值 不弹出 void push(T t);//压栈操作 T pop();//出栈操作 int getSize(){//返回当前栈有多少个元素 return insIndex; } ~ArrayStack(){ delete[] data; } }; template\u0026lt;typename T\u0026gt; void ArrayStack\u0026lt;T\u0026gt;::push(T t){ if(insIndex==capacity){//可插入下标==最大容量 说栈已经满了 throw std::runtime_error(\u0026quot;stack is full,no left space to push\u0026quot;); } data[insIndex++]=t;//在insIndex位置插入元素，同时insIndex++ } template\u0026lt;typename T\u0026gt; T ArrayStack\u0026lt;T\u0026gt;::peek(){ if( insIndex\u0026gt;0){//如果栈内有数据 返回栈顶元素 也就是insIndex-1的位置的元素 return data[insIndex-1]; }else{ throw std::runtime_error(\u0026quot;stack is empty\u0026quot;); } } template\u0026lt;typename T\u0026gt; T ArrayStack\u0026lt;T\u0026gt;::pop(){ if( insIndex\u0026gt;0){//如果栈内有数据 弹出栈顶元素 也就是insIndex-1的位置的元素 同时insIndex-- return data[--insIndex]; }else{ throw std::runtime_error(\u0026quot;stack is empty\u0026quot;); } }  \n队列  实现队列比实现栈多了一些内容，但也比较好理解 刻印设计2个指针 一个size变量  head指向队列头，insertIndex指向下一个可以插入的位置，2个指针的循环顺序都是0\u0026mdash;\u0026gt;size-1\u0026mdash;\u0026gt;0循环使用 刚开始都指向0下标\n 插入元素insertIndex++ ，head不动 size++ (size如果为最大容量 不给插入 报错) 弹出元素 head++，insertIndex不变(size如果为0 不给弹出 报错)  代码实现  数组实现的固定长度的队列\n//数组实现的固定大小长度的队列 template\u0026lt;typename T\u0026gt; struct ArrayQueue { private: T* data;//数组指针 int head;//队列头的下标 int insIndex;//保存下一个push元素时对应的插入位置指针 也可以由其计算出当前队列真正的元素个数 int capacity;//最大容量 int size;//当前队列的真实数据个数 public: ArrayQueue(int intiCapacity) { data=new T[intiCapacity]; capacity=intiCapacity; head=insIndex=size=0;//插入位置赋值为0 头指针为0 队列size为0 } T top() ;//返回队列头 元素值 不弹出 void push(T t);//入队操作 T pop();//出队操作 int getSize(){//返回当前队列有多少个元素 return size; } ~ArrayQueue(){ delete[] data; } }; template\u0026lt;typename T\u0026gt; void ArrayQueue\u0026lt;T\u0026gt;::push(T t){ if(size==capacity){//当前队列已经到达最大容量 说队列已经满了 throw std::runtime_error(\u0026quot;queue is full,no left space to push\u0026quot;); } data[insIndex++]=t;//在insIndex位置插入元素，同时insIndex++ if ( insIndex==capacity){//循环从0开始 insIndex=0; } size++; //push操作 head不变 } template\u0026lt;typename T\u0026gt; T ArrayQueue\u0026lt;T\u0026gt;::top(){ if( size\u0026gt;0){//如果队列内有数据 返回队列头元素 也就是head位置的元素 return data[head]; }else{ throw std::runtime_error(\u0026quot;queue is empty\u0026quot;); } } template\u0026lt;typename T\u0026gt; T ArrayQueue\u0026lt;T\u0026gt;::pop(){ if( size\u0026gt;0){//如果队列内有数据 弹出队列头元素 也就是head位置的元素 size--; //insIndex不变 int oldHead=head; head++; if ( head==capacity){//循环从0开始 head=0; } return data[oldHead]; }else{ throw std::runtime_error(\u0026quot;queue is empty\u0026quot;); } }  \n队列实现栈  准备2个队列，一个insQ 一个helpQ 刚开始都为空 插入都是插入到insQ helpQ不动 弹出操作逻辑如下:  将insQ依次出对(insQ队尾不出) 依次入对到helpQ 此时insQ只剩下队尾 然后弹出 返回(如果是peek操作 insQ队尾弹出后 需要也入对到helpQ) 将insQ和helpQ的指向互换即可   栈实现队列  准备2个栈 一个是push栈一个是pop栈 插入都是插入push栈 弹出操作如下：  如果pop栈为空 将push栈元素全部出栈 然后依次入栈道pop栈，最后弹出pop栈的栈顶(当时push栈最先插入的元素) 如果pop栈不为空 直接将pop栈的栈顶弹出   动物收容所 题目描述 动物收容所。有家动物收容所只收容狗与猫，且严格遵守“先进先出”的原则。在收养该收容所的动物时，收养人只能收养所有动物中“最老”（由其进入收容所的时间长短而定）的动物，或者可以挑选猫或狗（同时必须收养此类动物中“最老”的）。换言之，收养人不能自由挑选想收养的对象。请创建适用于这个系统的数据结构，实现各种操作方法，比如enqueue、dequeueAny、dequeueDog和dequeueCat。允许使用Java内置的LinkedList数据结构。enqueue方法有一个animal参数，animal[0]代表动物编号，animal[1]代表动物种类，其中 0 代表猫，1 代表狗。dequeue*方法返回一个列表[动物编号, 动物种类]，若没有可以收养的动物，则返回[-1,-1]。\n示例1: 输入： [\u0026ldquo;AnimalShelf\u0026rdquo;, \u0026ldquo;enqueue\u0026rdquo;, \u0026ldquo;enqueue\u0026rdquo;, \u0026ldquo;dequeueCat\u0026rdquo;, \u0026ldquo;dequeueDog\u0026rdquo;, \u0026ldquo;dequeueAny\u0026rdquo;] [[], [[0, 0]], [[1, 0]], [], [], []] 输出： [null,null,null,[0,0],[-1,-1],[1,0]] 示例2: 输入： [\u0026ldquo;AnimalShelf\u0026rdquo;, \u0026ldquo;enqueue\u0026rdquo;, \u0026ldquo;enqueue\u0026rdquo;, \u0026ldquo;enqueue\u0026rdquo;, \u0026ldquo;dequeueDog\u0026rdquo;, \u0026ldquo;dequeueCat\u0026rdquo;, \u0026ldquo;dequeueAny\u0026rdquo;] [[], [[0, 0]], [[1, 0]], [[2, 1]], [], [], []] 输出： [null,null,null,null,[2,1],[0,0],[1,0]]来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/animal-shelter-lcci 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。\n思路  肯定是2个队列 一个猫 一个狗。指定要狗或者猫，非常简单，直接从相应队列出队1个即可 如果不指定猫狗，就需要比较猫队头和狗队头谁进来的早(可以设计一个计数器，进来早的小，进来晚的大，返回计数器小的就行)，力扣上直接给动物编号了 直接用就行  代码  猫狗收容所c++\nclass AnimalShelf { public: AnimalShelf() { } void enqueue(vector\u0026lt;int\u0026gt; animal) { if (animal.at(1) == 0) //动物种类：猫 { m_queue_cat.push(animal); } else { m_queue_dog.push(animal); } } vector\u0026lt;int\u0026gt; dequeueAny() { vector\u0026lt;int\u0026gt; animal; if (m_queue_cat.empty() \u0026amp;\u0026amp; m_queue_dog.empty()) { return vector\u0026lt;int\u0026gt;{-1, -1}; } else if (!m_queue_cat.empty() \u0026amp;\u0026amp; m_queue_dog.empty()) { animal = m_queue_cat.front(); m_queue_cat.pop(); } else if (m_queue_cat.empty() \u0026amp;\u0026amp; !m_queue_dog.empty()) { animal = m_queue_dog.front(); m_queue_dog.pop(); } else { //用2个队列分别保存猫狗，而且要有个数据保存进来的编号，或者说是第几个进来的，这里动物编号就是这个意思了 所以直接使用就行 猫狗都有的时候 要看猫狗队头的编号 谁小给谁 if (m_queue_cat.front().at(0) \u0026lt; m_queue_dog.front().at(0)) //动物编号：猫 \u0026lt; 狗 猫先出 { animal = m_queue_cat.front(); m_queue_cat.pop(); } else { animal = m_queue_dog.front(); m_queue_dog.pop(); } } return animal; } vector\u0026lt;int\u0026gt; dequeueDog() { if (m_queue_dog.empty()) { return vector\u0026lt;int\u0026gt;{-1, -1}; } vector\u0026lt;int\u0026gt; dog = m_queue_dog.front(); m_queue_dog.pop(); return dog; } vector\u0026lt;int\u0026gt; dequeueCat() { if (m_queue_cat.empty()) { return vector\u0026lt;int\u0026gt;{-1, -1}; } vector\u0026lt;int\u0026gt; cat = m_queue_cat.front(); m_queue_cat.pop(); return cat; } private: queue\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; m_queue_cat; queue\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; m_queue_dog; }; // 作者：eric-345 // 链接：https://leetcode-cn.com/problems/animal-shelter-lcci/solution/c-mao-gou-liang-ge-dui-lie-by-eric-345/ // 来源：力扣（LeetCode） // 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 /** * Your AnimalShelf object will be instantiated and called as such: * AnimalShelf* obj = new AnimalShelf(); * obj-\u0026gt;enqueue(animal); * vector\u0026lt;int\u0026gt; param_2 = obj-\u0026gt;dequeueAny(); * vector\u0026lt;int\u0026gt; param_3 = obj-\u0026gt;dequeueDog(); * vector\u0026lt;int\u0026gt; param_4 = obj-\u0026gt;dequeueCat(); */  \n顺时针转圈打印矩阵 题目描述 输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字。\n示例 1：\n输入：matrix = [[1,2,3],[4,5,6],[7,8,9]] 输出：[1,2,3,6,9,8,7,4,5] 示例 2：\n输入：matrix = [[1,2,3,4],[5,6,7,8],[9,10,11,12]] 输出：[1,2,3,4,8,12,11,10,9,5,6,7]\n来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/shun-shi-zhen-da-yin-ju-zhen-lcof 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。\n思路：  实现一个函数 画一个矩形，左上方一个点到右下方一个点 然后循环画矩形 比如下图 下画(0,0)\u0026ndash;\u0026gt;(3,3)    然后xy坐标都+1 画(1,1)\u0026ndash;(2,2)  代码  顺时针转圈打印矩阵 代码非本人\n//给出左上方坐标 右下方坐标 顺时针画圈 void printSquare(int leftUp[], int rigthDown[],int matrix[][FACTORIAL]){ int i = leftUp[0], j = leftUp[1]; while (j \u0026lt; rigthDown[1]) { printf(\u0026quot;%d \u0026quot;, matrix[i][j++]); } while (i \u0026lt; rigthDown[0]) { printf(\u0026quot;%d \u0026quot;, matrix[i++][j]); } while (j \u0026gt; leftUp[1]) { printf(\u0026quot;%d \u0026quot;, matrix[i][j--]); } while (i \u0026gt; leftUp[0]) { printf(\u0026quot;%d \u0026quot;, matrix[i--][j]); } } //循环打印圈圈 也就是从外到内 void printMatrixCircled(int matrix[][FACTORIAL]){ int leftUp[] = {0, 0}, rightDown[] = {FACTORIAL-1,FACTORIAL-1}; while (leftUp[0] \u0026lt; rightDown[0] \u0026amp;\u0026amp; leftUp[1] \u0026lt; rightDown[1]) { printSquare(leftUp, rightDown, matrix); ++leftUp[0]; ++leftUp[1]; --rightDown[0]; --rightDown[1]; } } int main(){ int matrix[4][4] = { {1, 2, 3, 4}, {5, 6, 7, 8}, {9, 10, 11, 12}, {13, 14, 15, 16} }; printMatrixCircled(matrix);//1 2 3 4 8 12 16 15 14 13 9 5 6 7 11 10 }  \n旋转方块矩阵(正方形) 题目描述 旋转正方形矩阵 【题目】 给定一个整型正方形矩阵matrix，请把该矩阵调整成 顺时针旋转90度的样子。 【要求】 额外空间复杂度为O(1)。\n思路  设计一个函数 每次只旋转4个坐标点 刚开始为正方形的四个顶边坐标 然后依次顺时针推进再找4个点 外圈没了搞内圈  代码  旋转方块矩阵 代码非本人\n//每次选取4个坐标 旋转 void circleSquare(int leftUp[],int rightDown[],int matrix[][FACTORIAL]){ int p1[] = {leftUp[0], leftUp[1]}; int p2[] = {leftUp[0], rightDown[1]}; int p3[] = {rightDown[0], rightDown[1]}; int p4[] = {rightDown[0],leftUp[1]}; while (p1[1] \u0026lt; rightDown[1]) { //swap int tmp = matrix[p4[0]][p4[1]]; matrix[p4[0]][p4[1]] = matrix[p3[0]][p3[1]]; matrix[p3[0]][p3[1]] = matrix[p2[0]][p2[1]]; matrix[p2[0]][p2[1]] = matrix[p1[0]][p1[1]]; matrix[p1[0]][p1[1]] = tmp; p1[1]++; p2[0]++; p3[1]--; p4[0]--; } } //循环调用4坐标旋转函数，将所有坐标旋转完毕 void circleMatrix(int matrix[][FACTORIAL]){ int leftUp[] = {0, 0}, rightDown[] = {FACTORIAL - 1, FACTORIAL - 1}; while (leftUp[0] \u0026lt; rightDown[0] \u0026amp;\u0026amp; leftUp[1] \u0026lt; rightDown[1]) { circleSquare(leftUp, rightDown, matrix); leftUp[0]++; leftUp[1]++; --rightDown[0]; --rightDown[1]; } } void printMatrix(int matrix[][FACTORIAL]){ for (int i = 0; i \u0026lt; FACTORIAL; ++i) { for (int j = 0; j \u0026lt; FACTORIAL; ++j) { printf(\u0026quot;%2d \u0026quot;, matrix[i][j]); } printf(\u0026quot;\\n\u0026quot;); } } int main(){ int matrix[FACTORIAL][FACTORIAL] = { {1, 2, 3, 4}, {5, 6, 7, 8}, {9, 10, 11, 12}, {13, 14, 15, 16} }; printMatrix(matrix); circleMatrix(matrix); printMatrix(matrix); }  \n ## 特殊的栈(O(1)返回最小值) 实现一个特殊的栈，在实现栈的基本功能的基础上，再实现返 回栈中最小元素的操作 ### 思路： 再准备一个辅助栈(保存的是当前栈的最小值)， 1. 正常压栈的时候，如果辅助栈为空，也就是压入第一个元素，也将首元素压入辅助栈 2. 再次压栈的时候跟辅助栈栈顶比较取最小值 压入辅助栈，栈顶还是最小也压入 3. 出栈的时候 2个栈同时出栈 ## 之字形打印矩阵 ### 题目描述 之”字形打印矩阵 【题目】 给定一个矩阵matrix，按照“之”字形的方式打印这 个矩阵，例如:1 2 3 45 6 7 89 10 11 12 “之”字形打印的结果为:1，2，5，9，6，3，4，7，10，11， 8，12 【要求】 额外空间复杂度为O(1)。 ![](http://heketong.github.io/donate/之字形打印矩阵.jpg) ### 思路 1. 设计一个函数，能够在2个坐标之间画斜线 比如(0,2)---\u0026gt;(2.0) 就要经过3、8、13三个点 2. 然后搞2个指针 刚开始都指向(0,0),然后一个只能往下走(走到底就只能往右)，一个只能往右走(走到底就只能往下)，每次都同时走一步，然后画出这2个点之间的线，同时注意方向即可 ### 代码 \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;之字形打印矩阵 代码分本人\u0026lt;/summary\u0026gt;  c++ // const int rows = 3; const int cols = 6; //在2点之间画线，方向会依次相反 void printLine(int leftDown[],int rightUp[], bool turnUp,int matrix[rows][cols]){ int i,j; if (turnUp) { i = leftDown[0], j = leftDown[1]; while (j \u0026lt;= rightUp[1]) { printf(\u0026ldquo;%d \u0026ldquo;, matrix[i\u0026ndash;][j++]); } } else { i = rightUp[0], j = rightUp[1]; while (i \u0026lt;= leftDown[0]) { printf(\u0026ldquo;%d \u0026ldquo;, matrix[i++][j\u0026ndash;]); } } } //整2个指针 刚开始都指向(0,0) 刚开始都指向(0,0),然后一个只能往下走(走到底就只能往右)，一个只能往右走(走到底就只能往下)，每次都同时走一步，然后画出这2个点之间的线 void zigZagPrintMatrix(int matrix[rows][cols]){ if (matrix==NULL) return; int leftDown[] = {0, 0}, rightUp[] = {0, 0}; bool turnUp = true; while (leftDown[1] \u0026lt;= cols - 1) { printLine(leftDown, rightUp, turnUp, matrix); turnUp = !turnUp; if (leftDown[0] \u0026lt; rows - 1) { leftDown[0]++; } else { leftDown[1]++; } if (rightUp[1] \u0026lt; cols - 1) { ++rightUp[1]; } else { ++rightUp[0]; } } } int main(){ int matrix[rows][cols] = { {1, 2, 3, 4, 5, 6}, {7, 8, 9, 10, 11, 12}, {13, 14, 15, 16, 17, 18} }; zigZagPrintMatrix(matrix);//1 2 7 13 8 3 4 9 14 15 10 5 6 11 16 17 12 18 return 0; }\n\u0026lt;/details\u0026gt; ## 在行列都排好序的矩阵中找数 ### 题目描述 在行列都排好序的矩阵中找数 【题目】 给定一个有N*M的整型矩阵matrix和一个整数K， matrix的每一行和每一 列都是排好序的。实现一个函数，判断K 是否在matrix中。 例如: 0 1 2 5 2 3 4 7 4 4 4 8 5 7 7 9 如果K为7，返回true;如果K为6，返 回false。 【要求】 时间复杂度为O(N+M)，额外空间复杂度为O(1)。 ![](http://heketong.github.io/donate/在行列都排好序的矩阵中找数.jpg) ### 思路 因为行列都已经排好序了，所以就不需要完全遍历了 可以几个极点出发，慢慢扩散 下面假设从右上角的极点出发 1. 大于该极点的值 就往下走 4---\u0026gt;8 (不能往左走，因为4左边的数都比它小) 2. 如果小于该极点的值,(假设来到了8，我们要找6)，就往左走(因为8列下面的都比8大) 3. 列不能超出最大列 行不能超过最大行 所以找6的过程如下： 1. 6\u0026gt;4 往下走 2. 6\u0026lt;8 往左走 3. 6\u0026gt;5 往下走 4. 6\u0026lt;7 往左走 5. 6==6 找到 ### 代码 \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;在行列都排好序的数组中找数 代码分本人\u0026lt;/summary\u0026gt;  c++ #include  const int rows = 4; const int cols = 4; //大于该极点的值 就往下走 //如果小于该极点的值 就往左走 bool findNumInSortedMatrix(int num,int matrix[rows][cols]){ int i = 0, j = cols - 1; while (i \u0026lt;= rows - 1 \u0026amp;\u0026amp; j \u0026lt;= cols - 1) { if (matrix[i][j] \u0026gt; num) { \u0026ndash;j; } else if (matrix[i][j] \u0026lt; num) { ++i; } else { return true; } } return false; } int main(){ int matrix[rows][cols] = { {1, 2, 3, 4}, {2, 4, 5, 8}, {3, 6, 7, 9}, {4, 8, 9, 10} }; if (findNumInSortedMatrix(7, matrix)) { printf(\u0026ldquo;find!\u0026rdquo;); } else { printf(\u0026ldquo;not exist!\u0026rdquo;); } return 0; }\n\u0026lt;/details\u0026gt; ## 判断链表是否为回文结构(正反一样) ### 思路 #### 用栈 1. 遍历链表 依次压栈 2. 再次遍历链表 依次入栈 逐一比较是否相等，不能就是false，都相等就是true #### 反转后半段链表 ​\t快慢指针，反转后半段链表，然后左右往中间夹逼，判断逐一相等 ### 代码 \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;是否回文链表\u0026lt;/summary\u0026gt;  java // need n extra space public static boolean isPalindrome1(Node head) { Stack stack = new Stack(); Node cur = head; while (cur != null) { stack.push(cur); cur = cur.next; } while (head != null) { if (head.value != stack.pop().value) { return false; } head = head.next; } return true; } // need n/2 extra space public static boolean isPalindrome2(Node head) { if (head == null || head.next == null) { return true; } Node right = head.next; Node cur = head; while (cur.next != null \u0026amp;\u0026amp; cur.next.next != null) { right = right.next; cur = cur.next.next; } Stack stack = new Stack(); while (right != null) { stack.push(right); right = right.next; } while (!stack.isEmpty()) { if (head.value != stack.pop().value) { return false; } head = head.next; } return true; } // need O(1) extra space public static boolean isPalindrome3(Node head) { if (head == null || head.next == null) { return true; } Node n1 = head; Node n2 = head; while (n2.next != null \u0026amp;\u0026amp; n2.next.next != null) { // find mid node n1 = n1.next; // n1 -\u0026gt; mid n2 = n2.next.next; // n2 -\u0026gt; end } n2 = n1.next; // n2 -\u0026gt; right part first node n1.next = null; // mid.next -\u0026gt; null Node n3 = null; while (n2 != null) { // right part convert n3 = n2.next; // n3 -\u0026gt; save next node n2.next = n1; // next of right node convert n1 = n2; // n1 move n2 = n3; // n2 move } n3 = n1; // n3 -\u0026gt; save last node n2 = head;// n2 -\u0026gt; left first node boolean res = true; while (n1 != null \u0026amp;\u0026amp; n2 != null) { // check palindrome if (n1.value != n2.value) { res = false; break; } n1 = n1.next; // left to mid n2 = n2.next; // right to mid } n1 = n3.next; n3.next = null; while (n1 != null) { // recover list n2 = n1.next; n1.next = n3; n3 = n1; n1 = n2; } return res; }\n\u0026lt;/details\u0026gt; ## 链表按某元素值分区间(\u0026lt; = \u0026gt;) ### 题目描述 将单向链表按某值划分成左边小、中间相等、右边大的形式 【题目】 给定一个单向链表的头节点head，节点的值类型是整型，再给定一个 整 数pivot。实现一个调整链表的函数，将链表调整为左部分都是值小于 pivot 的节点，中间部分都是值等于pivot的节点，右部分都是值大于 pivot的节点。 除这个要求外，对调整后的节点顺序没有更多的要求。 例如:链表9-\u0026gt;0-\u0026gt;4-\u0026gt;5- \u0026gt;1，pivot=3。 调整后链表可以是1-\u0026gt;0-\u0026gt;4-\u0026gt;9-\u0026gt;5，也可以是0-\u0026gt;1-\u0026gt;9-\u0026gt;5-\u0026gt;4。总 之，满 足左部分都是小于3的节点，中间部分都是等于3的节点(本例中这个部 分为空)，右部分都是大于3的节点即可。对某部分内部的节点顺序不做 要求。 进阶: 在原问题的要求之上再增加如下两个要求。 在左、中、右三个部分的内部也做顺序要求，要求每部分里的节点从左 到右的 顺序与原链表中节点的先后次序一致。 例如:链表9-\u0026gt;0-\u0026gt;4-\u0026gt;5-\u0026gt;1，pivot=3。 调整后的链表是0-\u0026gt;1-\u0026gt;9-\u0026gt;4-\u0026gt;5。 在满足原问题要求的同时，左部分节点从左到 右为0、1。在原链表中也 是先出现0，后出现1;中间部分在本例中为空，不再 讨论;右部分节点 从左到右为9、4、5。在原链表中也是先出现9，然后出现4， 最后出现5。 如果链表长度为N，时间复杂度请达到O(N)，额外空间复杂度请达到O(1)。 ### 思路 1. 链表cp到数组 荷兰国旗问题搞定 不稳定 需要O(N)辅助空间 2. 遍历2遍数组 2.1. 第一遍遍历 得到第一个小于元素值的节点 第一个等于元素值的节点 第一个大于元素值的节点 2.2. 第二遍遍历 \u0026lt;num不是第一个小于的节点 挂到FirstLess后面 稳定 等于大于情况一样 把一个链表拆成了3个链表 2.3. 拼接3个链表 ### 代码 \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;javacode\u0026lt;/summary\u0026gt;  java package class_03; public class Code_12_SmallerEqualBigger { public static class Node { public int value; public Node next; public Node(int data) { this.value = data; } } public static Node listPartition1(Node head, int pivot) { if (head == null) { return head; } Node cur = head; int i = 0; while (cur != null) { i++; cur = cur.next; } Node[] nodeArr = new Node[i]; i = 0; cur = head; for (i = 0; i != nodeArr.length; i++) { nodeArr[i] = cur; cur = cur.next; } arrPartition(nodeArr, pivot); for (i = 1; i != nodeArr.length; i++) { nodeArr[i - 1].next = nodeArr[i]; } nodeArr[i - 1].next = null; return nodeArr[0]; } public static void arrPartition(Node[] nodeArr, int pivot) { int small = -1; int big = nodeArr.length; int index = 0; while (index != big) { if (nodeArr[index].value \u0026lt; pivot) { swap(nodeArr, ++small, index++); } else if (nodeArr[index].value == pivot) { index++; } else { swap(nodeArr, \u0026ndash;big, index); } } } public static void swap(Node[] nodeArr, int a, int b) { Node tmp = nodeArr[a]; nodeArr[a] = nodeArr[b]; nodeArr[b] = tmp; } public static Node listPartition2(Node head, int pivot) { Node sH = null; // small head Node sT = null; // small tail Node eH = null; // equal head Node eT = null; // equal tail Node bH = null; // big head Node bT = null; // big tail Node next = null; // save next node // every node distributed to three lists while (head != null) { next = head.next; head.next = null; if (head.value \u0026lt; pivot) { if (sH == null) { sH = head; sT = head; } else { sT.next = head; sT = head; } } else if (head.value == pivot) { if (eH == null) { eH = head; eT = head; } else { eT.next = head; eT = head; } } else { if (bH == null) { bH = head; bT = head; } else { bT.next = head; bT = head; } } head = next; } // small and equal reconnect if (sT != null) { sT.next = eH; eT = eT == null ? sT : eT; } // all reconnect if (eT != null) { eT.next = bH; } return sH != null ? sH : eH != null ? eH : bH; } public static void printLinkedList(Node node) { System.out.print(\u0026ldquo;Linked List: \u0026ldquo;); while (node != null) { System.out.print(node.value + \u0026ldquo; \u0026ldquo;); node = node.next; } System.out.println(); } public static void main(String[] args) { Node head1 = new Node(7); head1.next = new Node(9); head1.next.next = new Node(1); head1.next.next.next = new Node(8); head1.next.next.next.next = new Node(5); head1.next.next.next.next.next = new Node(2); head1.next.next.next.next.next.next = new Node(5); printLinkedList(head1); // head1 = listPartition1(head1, 4); head1 = listPartition2(head1, 5); printLinkedList(head1); } }\n\u0026lt;/details\u0026gt; ## 打印链表公共部分 打印两个有序链表的公共部分 【题目】 给定两个有序链表的头指针head1和head2，打印两个 链表的公共部分。 ## 思路 链表有序，从头遍历，谁小谁往后移动，相等就打印 ## 复制含有随机指针节点的链表 ### 题目描述 【题目】 一种特殊的链表节点类描述如下: public class Node { public int value; public Node next; public Node rand; public Node(int data) { this.value = data; } } Node类中的value是节点值，next指针和正常单链表中next指针的意义 一 样，都指向下一个节点，rand指针是Node类中新增的指针，这个指 针可 能指向链表中的任意一个节点，也可能指向null。 给定一个由 Node节点类型组成的无环单链表的头节点head，请实现一个 函数完成 这个链表中所有结构的复制，并返回复制的新链表的头节点。 进阶: 不使用额外的数据结构，只用有限几个变量，且在时间复杂度为 O(N) 内完成原问题要实现的函数。 ### 思路 - 遍历复制节点本身没有问题 但是不能复制随机指针节点 - 第一种方案就是使用hashmap，第一次遍历复制节点，同时加入map[oldNode]=newNode;这个map就保存了新旧节点的对应关系 第二次遍历，找到oldNode的随机节点oldRandom，通过map找到对应的新节点newNode,和newRandDom,设置即可。这种空间复杂度为O(N) - 第二种方案不用hashmap但是借鉴其思想，主要就是保存新旧节点的对应关系，第一次遍历搞成下面的链表结构: oldNode1---\u0026gt;newNode1---\u0026gt;oldNode2----\u0026gt;newNode2---,这样以来新旧node的对应关系就保存下来了，旧节点的next就是其新节点 ​ 第二次遍历就 newNode1.RandomNode=oldNode1.Random即可 同时next指向newNode2 ### 代码 \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;复制含有随机指针节点的链表 java\u0026lt;/summary\u0026gt;  Java package class_03; import java.util.HashMap; public class Code_13_CopyListWithRandom { public static class Node { public int value; public Node next; public Node rand; public Node(int data) { this.value = data; } } public static Node copyListWithRand1(Node head) { HashMapmap = new HashMap(); Node cur = head; while (cur != null) { map.put(cur, new Node(cur.value)); cur = cur.next; } cur = head; while (cur != null) { map.get(cur).next = map.get(cur.next); map.get(cur).rand = map.get(cur.rand); cur = cur.next; } return map.get(head); } public static Node copyListWithRand2(Node head) { if (head == null) { return null; } Node cur = head; Node next = null; // copy node and link to every node while (cur != null) { next = cur.next; cur.next = new Node(cur.value); cur.next.next = next; cur = next; } cur = head; Node curCopy = null; // set copy node rand while (cur != null) { next = cur.next.next; curCopy = cur.next; curCopy.rand = cur.rand != null ? cur.rand.next : null; cur = next; } Node res = head.next; cur = head; // split while (cur != null) { next = cur.next.next; curCopy = cur.next; cur.next = next; curCopy.next = next != null ? next.next : null; cur = next; } return res; } public static void printRandLinkedList(Node head) { Node cur = head; System.out.print(\u0026ldquo;order: \u0026ldquo;); while (cur != null) { System.out.print(cur.value + \u0026ldquo; \u0026ldquo;); cur = cur.next; } System.out.println(); cur = head; System.out.print(\u0026ldquo;rand: \u0026ldquo;); while (cur != null) { System.out.print(cur.rand == null ? \u0026ldquo;- \u0026rdquo; : cur.rand.value + \u0026ldquo; \u0026ldquo;); cur = cur.next; } System.out.println(); } public static void main(String[] args) { Node head = null; Node res1 = null; Node res2 = null; printRandLinkedList(head); res1 = copyListWithRand1(head); printRandLinkedList(res1); res2 = copyListWithRand2(head); printRandLinkedList(res2); printRandLinkedList(head); System.out.println(\u0026ldquo;=========================\u0026rdquo;); head = new Node(1); head.next = new Node(2); head.next.next = new Node(3); head.next.next.next = new Node(4); head.next.next.next.next = new Node(5); head.next.next.next.next.next = new Node(6); head.rand = head.next.next.next.next.next; // 1 -\u0026gt; 6 head.next.rand = head.next.next.next.next.next; // 2 -\u0026gt; 6 head.next.next.rand = head.next.next.next.next; // 3 -\u0026gt; 5 head.next.next.next.rand = head.next.next; // 4 -\u0026gt; 3 head.next.next.next.next.rand = null; // 5 -\u0026gt; null head.next.next.next.next.next.rand = head.next.next.next; // 6 -\u0026gt; 4 printRandLinkedList(head); res1 = copyListWithRand1(head); printRandLinkedList(res1); res2 = copyListWithRand2(head); printRandLinkedList(res2); printRandLinkedList(head); System.out.println(\u0026ldquo;=========================\u0026rdquo;); } }\n\u0026lt;/details\u0026gt; ## 两个链表是否相交 这个问题要区分链表是否有环，所以先看是否有环。 ### 判断链表是否有环 - 第一种 准备一个hash表，然后遍历链表，如果节点不在hash中，则加入，如果在hash中则说明存在环，而且第一个在hash中的节点就是第一个入环的节点 - 第二种 准备2个指针，快(f)慢(s)指针(刚开始都指向第一个节点)，然后快指针一次走2步,慢指针一次走1步，如果快慢指针撞上了就是有环，这个时候将快指针指向第一个节点，然后快慢指针每次都走一步，再次撞上的节点就是第一个入环的节点(数学可以证明这个方法是正确的，不用纠结) ### 两个无环链表可能相交，最后一个节点必定为同一个节点 这种可以有hash，也可以不用hash。 1. 用hash，就将链表1 依次入到hash，然后遍历链表2 第一个在hash中存在的节点就是2个链表相交的节点 2. 不用hash，遍历2个链表，分别得到len1,endNode1,len2,endnode2,如果endNode1==endNode2，则2个链表相交，找到最长的链表，先走(abs(len1-len2))步，然后2个链表都依次走1步 第一个撞上的节点就是相交的节点 ### 两个无环链表和一个有环链表不可能相交 因为是单链表 ### 两个有环链表可能相交 ![](http://heketong.github.io/donate/两个有环链表相交问题.png) ### 代码 \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;链表相交问题\u0026lt;/summary\u0026gt;  Java package class_03; public class Code_14_FindFirstIntersectNode { public static class Node { public int value; public Node next; public Node(int data) { this.value = data; } } public static Node getIntersectNode(Node head1, Node head2) { if (head1 == null || head2 == null) { return null; } Node loop1 = getLoopNode(head1); Node loop2 = getLoopNode(head2); if (loop1 == null \u0026amp;\u0026amp; loop2 == null) { return noLoop(head1, head2); } if (loop1 != null \u0026amp;\u0026amp; loop2 != null) { return bothLoop(head1, loop1, head2, loop2); } return null; } public static Node getLoopNode(Node head) { if (head == null || head.next == null || head.next.next == null) { return null; } Node n1 = head.next; // n1 -\u0026gt; slow Node n2 = head.next.next; // n2 -\u0026gt; fast while (n1 != n2) { if (n2.next == null || n2.next.next == null) { return null; } n2 = n2.next.next; n1 = n1.next; } n2 = head; // n2 -\u0026gt; walk again from head while (n1 != n2) { n1 = n1.next; n2 = n2.next; } return n1; } public static Node noLoop(Node head1, Node head2) { if (head1 == null || head2 == null) { return null; } Node cur1 = head1; Node cur2 = head2; int n = 0; while (cur1.next != null) { n++; cur1 = cur1.next; } while (cur2.next != null) { n\u0026ndash;; cur2 = cur2.next; } if (cur1 != cur2) { return null; } cur1 = n \u0026gt; 0 ? head1 : head2; cur2 = cur1 == head1 ? head2 : head1; n = Math.abs(n); while (n != 0) { n\u0026ndash;; cur1 = cur1.next; } while (cur1 != cur2) { cur1 = cur1.next; cur2 = cur2.next; } return cur1; } public static Node bothLoop(Node head1, Node loop1, Node head2, Node loop2) { Node cur1 = null; Node cur2 = null; if (loop1 == loop2) { cur1 = head1; cur2 = head2; int n = 0; while (cur1 != loop1) { n++; cur1 = cur1.next; } while (cur2 != loop2) { n\u0026ndash;; cur2 = cur2.next; } cur1 = n \u0026gt; 0 ? head1 : head2; cur2 = cur1 == head1 ? head2 : head1; n = Math.abs(n); while (n != 0) { n\u0026ndash;; cur1 = cur1.next; } while (cur1 != cur2) { cur1 = cur1.next; cur2 = cur2.next; } return cur1; } else { cur1 = loop1.next; while (cur1 != loop1) { if (cur1 == loop2) { return loop1; } cur1 = cur1.next; } return null; } } public static void main(String[] args) { // 1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;5-\u0026gt;6-\u0026gt;7-\u0026gt;null Node head1 = new Node(1); head1.next = new Node(2); head1.next.next = new Node(3); head1.next.next.next = new Node(4); head1.next.next.next.next = new Node(5); head1.next.next.next.next.next = new Node(6); head1.next.next.next.next.next.next = new Node(7); // 0-\u0026gt;9-\u0026gt;8-\u0026gt;6-\u0026gt;7-\u0026gt;null Node head2 = new Node(0); head2.next = new Node(9); head2.next.next = new Node(8); head2.next.next.next = head1.next.next.next.next.next; // 8-\u0026gt;6 System.out.println(getIntersectNode(head1, head2).value); // 1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;5-\u0026gt;6-\u0026gt;7-\u0026gt;4\u0026hellip; head1 = new Node(1); head1.next = new Node(2); head1.next.next = new Node(3); head1.next.next.next = new Node(4); head1.next.next.next.next = new Node(5); head1.next.next.next.next.next = new Node(6); head1.next.next.next.next.next.next = new Node(7); head1.next.next.next.next.next.next = head1.next.next.next; // 7-\u0026gt;4 // 0-\u0026gt;9-\u0026gt;8-\u0026gt;2\u0026hellip; head2 = new Node(0); head2.next = new Node(9); head2.next.next = new Node(8); head2.next.next.next = head1.next; // 8-\u0026gt;2 System.out.println(getIntersectNode(head1, head2).value); // 0-\u0026gt;9-\u0026gt;8-\u0026gt;6-\u0026gt;4-\u0026gt;5-\u0026gt;6.. head2 = new Node(0); head2.next = new Node(9); head2.next.next = new Node(8); head2.next.next.next = head1.next.next.next.next.next; // 8-\u0026gt;6 System.out.println(getIntersectNode(head1, head2).value); } }\n\u0026lt;/details\u0026gt; ## 分层打印二叉树 ### 思路 - 主体思路用2个队列，根先入一个Q1，然后出对，按照顺序将左右孩子依次入到另外一个队列Q2 - 遍历Q2的逻辑也是一样 出队之后，将其左右孩子依次入Q1 - 一个Q一层，然后将另外一层入到另外一个队列即可 - 注意空节点的打印 也要先获取树的最大层次 - 大值打印效果如下  1 2 3 * * 4 5\n ### 代码 \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;自己写的一个c++版本\u0026lt;/summary\u0026gt;  c++ //定义二叉树节点 template struct Node{ T key;//数据元素 Node* left;//左孩子 Node* right;//右孩子 Node(T tIn){ key=tIn; left=right=nullptr; } }; //获取树的最大层次 //getMaxDepth 获取一个树的最大高度或者层次 根为第1层 template int getMaxDepth(Node* node) { if (node == nullptr) { return 0; } int depth = 1; depth += std::max(getMaxDepth(node-\u0026gt;left), getMaxDepth(node-\u0026gt;right)); return depth; } //分层打印二叉树 template void printByLevel(Node* root){ if (root ==nullptr){ return; } int depth = getMaxDepth(root) ; //获取树的最深层次 //申请2个队列 从1个队列出队 同时将其左右子树依次入队到另外一个队列 queue\u0026lt; Node* \u0026gt; q1,q2; queue\u0026lt; Node* \u0026gt; *cur=\u0026amp;q1,next=\u0026q2; q1.push(root); //终止条件 最大层次打印完毕 for (int i=1; i \u0026lt;= depth; ++i) { int count = 1 ; //标记打印当前层次的第几个元素 int tabCount = ( (1\u0026lt;\u0026lt;(depth+1-i)) - 1) / 2 ;//打印元素 计算打印前面\\t个数 while( cur-\u0026gt;empty()==false) { //队列1不为空 if (count \u0026gt; 1) { tabCount = ( (1\u0026lt;\u0026lt;(depth+1-i)) - 1); } Node node=cur-\u0026gt;front();cur-\u0026gt;pop(); if (node != nullptr) { //不是空节点 //将其左右孩子入到下一层队列 for (int j = 0; j \u0026lt; tabCount; j++) { cout\u0026lt;\u0026lt;\u0026rdquo; \u0026ldquo;; } cout\u0026lt;key; count++; if (node-\u0026gt;left != nullptr) { next-\u0026gt;push(node-\u0026gt;left); } else { next-\u0026gt;push(nullptr); //加入一个空节点 为了打印好看 } if (node-\u0026gt;right != nullptr) { next-\u0026gt;push(node-\u0026gt;right); } else { next-\u0026gt;push(nullptr); //加入一个空节点 为了打印好看 } } else { //空节点 for (int j = 0; j \u0026lt; tabCount; j++) { cout\u0026lt;\u0026lt;\u0026rdquo; \u0026ldquo;; } cout\u0026lt;\u0026lt;\u0026rdquo;\u0026rdquo;; count++; next-\u0026gt;push(nullptr); //加入一个空节点 为了打印好看 next-\u0026gt;push(nullptr); //加入一个空节点 为了打印好看 } } cout\u0026lt; \u0026gt; *tmp=next;next=cur;cur=tmp;//交换队列指针指向 } }\n\u0026lt;/details\u0026gt; ## 如何判断一个树为完全二叉树 ### 思路 准备一个队列,分层遍历，如果一个节点只有右孩子，没有左孩子 直接返回false，否则再判断这个节点是否左右孩子双全，如果不是，这个节点之后的所有节点都必须是叶子节点，否则为false，第一个遇到不是左右孩子双全的时候，将isCheckAllLeaf开关打开 1. 根为空或者只有根返回true 否则根入队 isCheckAllLeaf初始化为false 2. 队列为空则终止 3. 从队列弹出一个节点，如果该节点只有右孩子，没有左孩子，直接返回false(不符合完全二叉树定义)，否则继续往下走 4. 如果该节点不是左右孩子双全  if ( isCheckAllLeaf){//如果开关已经打开 说明之前已经出现了孩子不全的情况了 之后出现的必须是叶子节点 所以直接返回false即可 return false; }else{ isCheckAllLeaf=true; }\n 5. 循环完毕都没有返回false 那就return true ### 代码 \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;转载java\u0026lt;/summary\u0026gt;  Java public static boolean isCBT(Node head) { if (head == null) { return true; } Queue queue = new LinkedList(); boolean leaf = false; Node l = null; Node r = null; queue.offer(head); while (!queue.isEmpty()) { head = queue.poll(); l = head.left; r = head.right; if ((leaf \u0026amp;\u0026amp; (l != null || r != null)) || (l == null \u0026amp;\u0026amp; r != null)) { return false; } if (l != null) { queue.offer(l); } if (r != null) { queue.offer\u0026reg;; } else { leaf = true; } } return true; }\n\u0026lt;/details\u0026gt; ## 如何判断一个树为二叉搜索树 BST ### 思路 1. 中序遍历 后面的树比前面的数要大即可 2. 递归判断左右子树是否都是BST，同时得到左右子树的最大最小值，然后判断本节点是否BST(\u0026gt;左孩子最大值\u0026amp;\u0026amp;\u0026lt;右孩子最小值) 上面BST章节有go版本的代码 ## 求完全二叉树个数 ### 题目描述 已知一棵完全二叉树，求其节点的个数 要求:时间复杂度低于O(N)，N为这棵树的节点个数 ### 思路 - 肯定不能遍历 因为时间复杂度要低于O(N) - 利用完全二叉树的特点和满二叉树最大个数特点计算 大值逻辑如下： ​\t针对每一个节点都递归求解 1. 先求树的最大高度(一路找左孩子 累计) 2. 判断右子树最大高度跟其最大高度相等 如果相等则 其左孩子为满二叉树 个数为($2^(L-1)$ -1) L为最大高度 加上节点本身就是$2^L-1$，然后类似逻辑递归求接右子树的个数 3. 如果右子树最大高度跟其最大高度不等 则其右孩子为满二叉树 假设右子树最大高度为LR 则右子树个数位$2^(LR-1)$ -1 加上节点本身就是$2^(LR-1)$ ,然后递归求解左孩子的个数 ### 代码  //递归伪代码 int getNodeNum(Node* root){ int L=getMaxLevel(root);//该树最大高度 int LR=getMaxLevel(root-\u0026gt;right);//右子树最大高度 int numLeft=0,numRight=0;//左子树个数 右子树个数 if ( L==(LR+1)){ //右子树最大高度跟其最大高度相等 如果相等则 其左孩子为满二叉树 个数为(2^(L-1) -1) 加上节点本身就是2^(L-1) numLeft= ( 1\u0026lt;\u0026lt;(L-1) ) -1; return numLeft + 1 + getNodeNum(root-\u0026gt;right); }else{ //右子树最大高度跟其最大高度不等 则其右孩子为满二叉树 个数为 (2^(LR-1) -1) numRight= ( 1\u0026lt;\u0026lt;(LR-1) -1 ); return numRight + 1 + getNodeNum(root-\u0026gt;left); } }\n \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;转载Java实现\u0026lt;/summary\u0026gt;  Java package class_04; public class Code_08_CompleteTreeNodeNumber { public static class Node { public int value; public Node left; public Node right; public Node(int data) { this.value = data; } } public static int nodeNum(Node head) { if (head == null) { return 0; } return bs(head, 1, mostLeftLevel(head, 1)); } public static int bs(Node node, int l, int h) { if (l == h) { return 1; } if (mostLeftLevel(node.right, l + 1) == h) { return (1 \u0026lt;\u0026lt; (h - l)) + bs(node.right, l + 1, h); } else { return (1 \u0026lt;\u0026lt; (h - l - 1)) + bs(node.left, l + 1, h); } } public static int mostLeftLevel(Node node, int level) { while (node != null) { level++; node = node.left; } return level - 1; } public static void main(String[] args) { Node head = new Node(1); head.left = new Node(2); head.right = new Node(3); head.left.left = new Node(4); head.left.right = new Node(5); head.right.left = new Node(6); System.out.println(nodeNum(head)); } }\n\u0026lt;/details\u0026gt; ## 折纸问题 ### 题目描述 折纸问题 【题目】 请把一段纸条竖着放在桌子上，然后从纸条的下边向 上方对折1次，压出折痕后展开。此时 折痕是凹下去的，即折痕 突起的方向指向纸条的背面。如果从纸条的下边向上方连续对折 2 次，压出折痕后展开，此时有三条折痕，从上到下依次是下折 痕、下折痕和上折痕。 给定一 个输入参数N，代表纸条都从下边向上方连续对折N次， 请从上到下打印所有折痕的方向。 例如:N=1时，打印: down N=2时，打印: down down up ### 思路 - 要自己玩一下 转换为中序遍历 ### 代码 \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;转载 java\u0026lt;/summary\u0026gt;  Java public class Code_05_PaperFolding { public static void printAllFolds(int N) { printProcess(1, N, true); } public static void printProcess(int i, int N, boolean down) { if (i \u0026gt; N) { return; } printProcess(i + 1, N, true); System.out.println(down ? \u0026ldquo;down \u0026rdquo; : \u0026ldquo;up \u0026ldquo;); printProcess(i + 1, N, false); } public static void main(String[] args) { int N = 4; printAllFolds(N); } }\n\u0026lt;/details\u0026gt; ## 岛问题 ### 题目描述 一个矩阵中只有0和1两种值，每个位置都可以和自己的上、下、左、右 四个位置相连，如果有一片1连在一起，这个部分叫做一个岛，求一个 矩阵中有多少个岛? 举例: ![001010](http://heketong.github.io/donate/岛问题示意图.jpg) 这个矩阵中有1个岛。 ### 思路 1. 遍历求解 两层for循环遍历每一个点 1 如果1个点是1 则将其改为2，同时将其上下左右是1的点也全都改为2(对于上下左右是1的点也要递归找到其上下左右是1的点改为2)，都改为2之后将岛的数量+1 2 如果该点是2或者0 直接pass 3 遍历结束返回岛累计计数结果 2. 利用并查集结构。 如果矩阵非常大，单机器单cpu则会比较慢，可以将矩阵分割为多个矩阵，利用多cpu或者多个机器并行计算，最后根据矩阵的边界，利用并查集结构求解，会提高效率。 ![](http://heketong.github.io/donate/并查集解决岛问题.jpg) **分析边界逻辑：** ​\t1 如果2个点都是1，且对应的的代表节点不一样，则合并2个集合，岛数量减去1，否则跳过这对边界点 继续处理下一对边界点 ​\t2 如果 一个是0 一个是1（说明2个岛无法连接 pass） ​\t3 如果 2个都是1，但是对应的代表节点一样(之前合并过了 本次直接跳过，岛数量不减)。 ### 遍历求解代码 \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;岛问题遍历递归求解 转载JAVA\u0026lt;/summary\u0026gt;  JAVA public class Code_03_Islands { public static int countIslands(int[][] m) { if (m == null || m[0] == null) { return 0; } int N = m.length; int M = m[0].length; int res = 0; for (int i = 0; i \u0026lt; N; i++) { for (int j = 0; j \u0026lt; M; j++) { if (m[i][j] == 1) { res++; infect(m, i, j, N, M); } } } return res; } public static void infect(int[][] m, int i, int j, int N, int M) { if (i \u0026lt; 0 || i \u0026gt;= N || j \u0026lt; 0 || j \u0026gt;= M || m[i][j] != 1) { return; } m[i][j] = 2; infect(m, i + 1, j, N, M); infect(m, i - 1, j, N, M); infect(m, i, j + 1, N, M); infect(m, i, j - 1, N, M); } public static void main(String[] args) { int[][] m1 = { { 0, 0, 0, 0, 0, 0, 0, 0, 0 }, { 0, 1, 1, 1, 0, 1, 1, 1, 0 }, { 0, 1, 1, 1, 0, 0, 0, 1, 0 }, { 0, 1, 1, 0, 0, 0, 0, 0, 0 }, { 0, 0, 0, 0, 0, 1, 1, 0, 0 }, { 0, 0, 0, 0, 1, 1, 1, 0, 0 }, { 0, 0, 0, 0, 0, 0, 0, 0, 0 }, }; System.out.println(countIslands(m1)); int[][] m2 = { { 0, 0, 0, 0, 0, 0, 0, 0, 0 }, { 0, 1, 1, 1, 1, 1, 1, 1, 0 }, { 0, 1, 1, 1, 0, 0, 0, 1, 0 }, { 0, 1, 1, 0, 0, 0, 1, 1, 0 }, { 0, 0, 0, 0, 0, 1, 1, 0, 0 }, { 0, 0, 0, 0, 1, 1, 1, 0, 0 }, { 0, 0, 0, 0, 0, 0, 0, 0, 0 }, }; System.out.println(countIslands(m2)); } }\n\u0026lt;/details\u0026gt; ## 拼接最小字典序 ### 题目描述 给定一个字符串类型的数组strs，找到一种拼接方式，使得把所有字符串拼起来之后形成的字符串具有最低的字典序 不能直接按照字典序排序数组，然后拼接因为假设有 \u0026quot;b\u0026quot; \u0026quot;ba\u0026quot; 这就是字典序排序后的东西 拼接出来的bba 不如bab 也就是比较器需要自己实现 str1+str2\u0026lt;=str2+str1 返回str1 否则返回str2  java //转载 JAVA public static class MyComparator implements Comparator { @Override public int compare(String a, String b) { return (a + b).compareTo(b + a); } } public static String lowestString(String[] strs) { if (strs == null || strs.length == 0) { return \u0026ldquo;\u0026rdquo;; } // 用自己定义的比较器搞 c/c++就是重载比较运算符 Arrays.sort(strs, new MyComparator()); String res = \u0026ldquo;\u0026rdquo;; for (int i = 0; i \u0026lt; strs.length; i++) { res += strs[i]; } return res; }\n ## 分金条代价最小 ### 题目描述 一块金条切成两半，是需要花费和长度数值一样的铜板的。比如 长度为20的 金条，不管切成长度多大的两半，都要花费20个铜 板。 一群人想整分整块金条，怎么分最省铜板? 例如,给定数组{10,20,30}，代表一共三个人，整块金条长度为 10+20+30=60. 金条要分成10,20,30三个部分。 如果， 先把长 度60的金条分成10和50，花费60 再把长度50的金条分成20和30， 花费50 一共花费110铜板。 如果， 先把长度60的金条分成30和30，花费60 再把长度30 金条分成10和20，花费30 一共花费90铜板。 输入一个数组，返回分割的最小代价。 ### 思路 ​\t这个其实就是哈夫曼编码问题，也是典型的贪心问题，策略就是找2个最小元素相加，这个和就是分割的花费，然后再将这个最小和作为新的元素 放进集合，再从中挑选2个最小的数相加累计花费，最后只剩下一个元素结束。 可以用最小堆实现，先将数组元素全部入堆，先后弹出2个元素(当前数组中最小的)，花费+=弹出的2元素之和，同时再将元素和入堆 知道最后堆只剩下一个元素。 ### 代码  java //转载 JAVA //PriorityQueue是Java语言对堆结构的一个实现，默认将按自然顺序的最小元素放在堆顶 PriorityQueue minHeap = new PriorityQueue(); for (int i : arr) { minHeap.add(i); } int res = 0; int curCost = 0; while (minHeap.size() \u0026gt; 1) { curCost = minHeap.poll() + minHeap.poll(); res += curCost; minHeap.add(curCost); } return res\n ## IPO问题 ### 题目描述: 定若干个项目。对于每个项目 i，它都有一个纯利润 Pi，并且需要最小的资本 Ci 来启动相应的项目。最初，你有 W 资本。当你完成一个项目时，你将获得纯利润，且利润将被添加到你的总资本中。 总而言之，从给定项目中选择最多 k 个不同项目的列表，以最大化最终资本，并输出最终可获得的最多资本。 示例 1: 输入: k=2, W=0, Profits=[1,2,3], Capital=[0,1,1]. 输出: 4 解释: 由于你的初始资本为 0，你尽可以从 0 号项目开始。 在完成后，你将获得 1 的利润，你的总资本将变为 1。 此时你可以选择开始 1 号或 2 号项目。 由于你最多可以选择两个项目，所以你需要完成 2 号项目以获得最大的资本。 因此，输出最后最大化的资本，为 0 + 1 + 3 = 4。 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/ipo ### 思路： ​\t也是贪心 贪心一般都有堆实现，准备2个堆1个大根堆(按照项目利润排序)，一个小根堆(按照项目成本排序) 1. 首先对应Captial成本数组 一个入小根堆(成本最低的在堆顶) 2. 循环将堆顶的项目成本Ci\u0026lt;=W的所有项目 对应的利润扔到大根堆 ，所以目前大根堆里面的项目都是解锁的项目，也就是手里有钱可以做的，如果大根堆size为0，代表没有可以做的项目 直接返回即可，已完成项目次数到达了K 也直接返回即可 否则继续下面逻辑 然后弹出大根堆的堆顶，可以做的项目中挑选一个最大的，然后W+=Pi 手里的钱要加上利润，K++,然后循环步骤2 ### 代码 \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;IPO问题代码 转载JAVA\u0026lt;/summary\u0026gt;  Java public class Code_03_IPO { public static class Node { public int p; public int c; public Node(int p, int c) { this.p = p; this.c = c; } } public static class MinCostComparator implements Comparator { @Override public int compare(Node o1, Node o2) { return o1.c - o2.c; } } public static class MaxProfitComparator implements Comparator { @Override public int compare(Node o1, Node o2) { return o2.p - o1.p; } } public static int findMaximizedCapital(int k, int W, int[] Profits, int[] Capital) { Node[] nodes = new Node[Profits.length]; for (int i = 0; i \u0026lt; Profits.length; i++) { nodes[i] = new Node(Profits[i], Capital[i]); } PriorityQueue minCostQ = new PriorityQueue\u0026lt;\u0026gt;(new MinCostComparator()); PriorityQueue maxProfitQ = new PriorityQueue\u0026lt;\u0026gt;(new MaxProfitComparator()); for (int i = 0; i \u0026lt; nodes.length; i++) { minCostQ.add(nodes[i]); } for (int i = 0; i \u0026lt; k; i++) { while (!minCostQ.isEmpty() \u0026amp;\u0026amp; minCostQ.peek().c \u0026lt;= W) { maxProfitQ.add(minCostQ.poll()); } if (maxProfitQ.isEmpty()) { return W; } W += maxProfitQ.poll().p; } return W; } }\n\u0026lt;/details\u0026gt; ## 会议室宣讲安排问题 ### 题目定义 一些项目要占用一个会议室宣讲，会议室不能同时容纳两个项目 的宣讲。 给你每一个项目开始的时间和结束的时间(给你一个数组，里面是一个个具体的项目)，你来安排宣讲的日程， 要求会议室进行 的宣讲的场次最多。返回这个最多的宣讲场次。 ### 思路 1. 贪心1 次数最多，谁的会议时间开始越早谁先安排 可以举出反例子，如果最早开始的项目 占用全天时间，别的会议都不能安排了 2. 会议持续时间越短 就安排 也不行，也可以举出反例 A会议[6--\u0026gt;12] B会议[11:30--\u0026gt;14:00] C会议[13:30---\u0026gt;20] 如果安排了B会议。A会议和C会议都不能安排了 3. 这道题正确的贪心是谁的结束时间越早 越先安排 谁的结束时间越早，就安排，然后淘汰因为安排了这个会议不能安排的会议，然后继续挑选结束时间最早的安排(淘汰相关不能安排的) ### 代码 \u0026lt;details\u0026gt; \u0026lt;summary\u0026gt;转载Java\u0026lt;/summary\u0026gt;  Java public class Schedule { public class Project { int start; int end; } public class MostEarlyEndComparator implements Comparator { public int compare(Project p1, Project p2) { return p1.end-p2.end; } } public int solution(Project projects[],int currentTime) { //sort by the end time Arrays.sort(projects, new MostEarlyEndComparator()); int res = 0; for (int i = 0; i \u0026lt; projects.length; i++) { if (currentTime \u0026lt;= projects[i].start) { res++; currentTime = projects[i].end; } } return res; } }\n\u0026lt;/details\u0026gt; ## 打印一个字符串的所有子序列 - 子序列跟字串有区别 字串必须是连续的，子序列不是，但不能改变顺序 - 比如 abc 是 “abcdef”的字串 也是子序列 adf是 “abcedf”的子序列 但不是子串。bac不是\u0026quot;abcedf\u0026quot;的子序列 也不是子串 ### 思路 #### 递归 顺序遍历字符串每一个字符，针对每一个字符都只有2种情况，要或者不要 ![](http://heketong.github.io/donate/打印字符串全部子序列递归思路.jpg) ##### 代码  //begin为从第几个索引位置开始 res为到这个索引已经得到的子序列 void printAllSub(string\u0026amp; str,int begin,string res){ if(begin \u0026gt;=str.length()){//如果全部遍历完成 直接打印即可 cout\u0026lt;\u0026lt;res\u0026lt;\u0026lt;endl; return; } printAllSub(str,begin+1,res);//不要begin位置的字符 printAllSub(str,begin+1,res+str[begin]); } int main(){ string str=\u0026ldquo;abc\u0026rdquo;; printAllSub(str,0,\u0026ldquo;\u0026rdquo;); }\n ## 打印字符串的全排列 这种就可以打乱顺序了，但是必须每个字符都要，而且不能重复。 ![](http://heketong.github.io/donate/字符串全排列递归思路.jpg)  public static void printAllPermutations(char[] chs,int index) { //base case if(index == chs.length-1) { System.out.println(chs); return; } for (int j = index; j \u0026lt; chs.length; j++) { swap(chs,index,j); printAllPermutations(chs, index+1); } }\n ## 母牛生牛问题 母牛每年生一只母牛，新出生的母牛成长三年后也能每年生一只母牛，假设不会死。求N年后，母牛的数量。 先画出简单的前面几项 看是否能找到规律 ![](http://heketong.github.io/donate/母牛生牛问题.jpg)  public static int cowNumber(int n) { if (n \u0026lt; 1) { return 0; } if (n == 1 || n == 2 || n == 3) { return n; } return cowNumber(n - 1) + cowNumber(n - 3); }\n ## 递归逆序栈  public static void reverse(Stack stack) { if (stack.isEmpty()) { return; } int i = getAndRemoveLastElement(stack);//得到当前栈最后一个元素(栈底元素 最先入栈的元素) 并且从栈种移除 其它元素不动 reverse(stack);//得到剩余栈最后一个元素 并且从栈种移除 其它元素不动 //如果入栈是1 2 3 那么i顺序得到 3 2 1 stack.push(i);//然后按照顺序入栈3 2 1 就相当于完成了逆序这个栈 } public static int getAndRemoveLastElement(Stack stack) { int result = stack.pop();//持续得到栈顶元素 得到顺序为3 2 1 if (stack.isEmpty()) {//栈为空则 直接返回 return result; } else { int last = getAndRemoveLastElement(stack);//不为空 则继续递归弹出栈顶 最后得到1 栈底元素 stack.push(result); return last; //除了最后一个元素 将依次出栈的元素 按照相关的顺序继续入栈(除了栈底元素出栈外 其它不变) 同时一直返回栈底元素 } }\n ## 链表中倒数第K个节点 #### 题目描述 输入一个链表，输出该链表中倒数第k个结点。 ### 整体思路： 1. 假象有一个节点tmp 它的下一个节点指向第一个节点head。 p1,p2都指向tmp 2. p1先往前走k步 3. 然后p1 p2都逐步往前走，当p1==null 此时p2就是倒数第k个节点(因为p1先走了k步)  public ListNode FindKthToTail(ListNode head,int k) { //input check if(head == null || k \u0026lt;= 0){ return null; } ListNode tmp = new ListNode(0); tmp.next = head; ListNode p1 = tmp, p2 = tmp; while(k \u0026gt; 0 \u0026amp;\u0026amp; p1.next != null){ p1 = p1.next; k\u0026ndash;; } //length \u0026lt; k if(k != 0){ return null; } while(p1 != null){ p1 = p1.next; p2 = p2.next; }\ntmp = null; //help gc return p2;  }\n ## 合并2个排序链表 ### 题目描述 输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则 ### 思路 利用归并排序的合并步骤 完成次操作 ### 代码  public ListNode Merge(ListNode list1,ListNode list2) { if(list1 == null || list2 == null){ return list1 == null ? list2 : list1; } ListNode newHead = list1.val \u0026lt; list2.val ? list1 : list2; ListNode p1 = (newHead == list1) ? list1.next : list1; ListNode p2 = (newHead == list2) ? list2.next : list2; ListNode p = newHead; while(p1 != null \u0026amp;\u0026amp; p2 != null){ if(p1.val \u0026lt;= p2.val){ p.next = p1; p1 = p1.next; }else{ p.next = p2; p2 = p2.next; } p = p.next; } while(p1 != null){ p.next = p1; p = p.next; p1 = p1.next; } while(p2 != null){ p.next = p2; p = p.next; p2 = p2.next; } return newHead; }\n ## 判断是否为树的子结构 ### 题目描述 输入两棵二叉树A，B，判断B是不是A的子结构。（ps：我们约定空树不是任意一个树的子结构） ### 思路： 树的很多解法都是递归，这道题也是如此。递归判断头节点 左子树 右子树 。大值分为2种情况 1. 如果root1.val==root2.val 并且root2.left也是root1.left的子结构(递归) 并且root2.right也是root1.right的子结构(递归) 2. 否则 就要看 root2是否为root1.left的子结构(递归) 或者root1.right的子结构(递归) 难点是base-case,也就是递归终止的条件 - 子过程`root2=null`那么说明在自上而下的比较过程中`root2`的结点已被罗列比较完了，这时无论`root1`是否为`null`，该子过程都应该返回`true` ![](http://heketong.github.io/donate/判断是否为树的子结构1.jpg) - ``` root2 != null`而`root1 = null`，则应返回`false  代码 public class Solution { public boolean HasSubtree(TreeNode root1,TreeNode root2) { if(root1 == null || root2 == null){ return false; } return process(root1, root2); } public boolean process(TreeNode root1, TreeNode root2){ if(root2 == null){ return true; } if(root1 == null \u0026amp;\u0026amp; root2 != null){ return false; } if(root1.val == root2.val){ if(process(root1.left, root2.left) \u0026amp;\u0026amp; process(root1.right, root2.right)){ return true; } } return process(root1.left, root2) || process(root1.right, root2); } }  二叉树镜像 题目描述 操作给定的二叉树，将其变换为源二叉树的镜像。\n思路： ​ 仔细看图，对于每个节点交换左右孩子 递归交换 注意base-case那就是节点已经到空节点了 那就return\n代码 public void Mirror(TreeNode root) { if(root == null){ return; } TreeNode tmp = root.left; root.left = root.right; root.right = tmp; Mirror(root.left); Mirror(root.right); }  栈的压入、弹出序列 题目描述 输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否可能为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如序列1,2,3,4,5是某栈的压入顺序，序列4,5,3,2,1是该压栈序列对应的一个弹出序列，但4,3,5,1,2就不可能是该压栈序列的弹出序列。（注意：这两个序列的长度是相等的）\n思路 要冷静分析找规律\n可以使用两个指针i,j，初始时i指向压入序列的第一个，j指向弹出序列的第一个，试图将压入序列按照顺序压入栈中：\n 如果arr1[i] != arr2[j]，那么将arr1[i]压入栈中并后移i（表示arr1[i]还没到该它弹出的时刻） 如果某次后移i之后发现arr1[i] == arr2[j]，那么说明此刻的arr1[i]被压入后应该被立即弹出才会产生给定的弹出序列，于是不压入arr1[i]（表示压入并弹出了）并后移i，j也要后移（表示弹出序列的arr2[j]记录已产生，接着产生或许的弹出记录即可）。 因为步骤2和3都会后移i，因此循环的终止条件是i到达arr1.length，此时若栈中还有元素，那么从栈顶到栈底形成的序列必须与arr2中j之后的序列相同才能返回true。  代码 public boolean IsPopOrder(int [] arr1,int [] arr2) { //input check if(arr1 == null || arr2 == null || arr1.length != arr2.length || arr1.length == 0){ return false; } Stack\u0026lt;Integer\u0026gt; stack = new Stack(); int length = arr1.length; int i = 0, j = 0; while(i \u0026lt; length \u0026amp;\u0026amp; j \u0026lt; length){ if(arr1[i] != arr2[j]){ stack.push(arr1[i++]); }else{ i++; j++; } } while(j \u0026lt; length){ if(arr2[j] != stack.peek()){ return false; }else{ stack.pop(); j++; } } return stack.empty() \u0026amp;\u0026amp; j == length; }  二叉搜索树的后序遍历序列 题目描述 输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历的结果。如果是则输出Yes,否则输出No。假设输入的数组的任意两个数字都互不相同。\n参考以下这颗二叉搜索树：\n 5 / \\  2 6 / 1 3 示例 1：\n输入: [1,6,3,2,5] 输出: false 示例 2：\n输入: [1,3,2,6,5] 输出: true\n来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/er-cha-sou-suo-shu-de-hou-xu-bian-li-xu-lie-lcof\n思路 post的遍历顺序为“左右根”，每一层判断左右子树和根节点的大小关系，如果满足则继续向下判断；否则直接返回失败 具体做法是： （1）遍历本层数组，找到比根节点(即数组最后一个数)大的第一个节点，此节点向左都是左子树，此节点向右都是右子树 （2）上一步已经把左子树的合法性证实了，只需要证实右子树的合法性，即判断右子树所有值大于根节点。右子树合法则继续下一层判断，否则直接返回false\n作者：yyc-13 链接：https://leetcode-cn.com/problems/er-cha-sou-suo-shu-de-hou-xu-bian-li-xu-lie-lcof/solution/jian-zhi-offer-33-er-cha-sou-suo-shu-de-hou-xu-b-4/\n代码 class Solution { public: bool verifyPostorder(vector\u0026lt;int\u0026gt;\u0026amp; postorder) { if(postorder.size()\u0026lt;=1){ return true; } return Recur(postorder,0,postorder.size()-1); } bool Recur(vector\u0026lt;int\u0026gt;\u0026amp; postorder,int i,int j){ if(i\u0026gt;=j){ return true; } int m; for(m=0;m\u0026lt;j;m++){ if(postorder[m]\u0026gt;postorder[j]){ break; } } for(int k=m+1;k\u0026lt;j;k++){ if(postorder[k]\u0026lt;postorder[j]){ return false; } } return Recur(postorder,i,m-1)\u0026amp;\u0026amp;Recur(postorder,m,j-1); } };  二叉树中和为某一值的路径 题目描述 输入一颗二叉树的跟节点和一个整数，打印出二叉树中结点值的和为输入整数的所有路径。路径定义为从树的根结点开始往下一直到叶结点所经过的结点形成一条路径。(注意: 在返回值的list中，数组长度大的数组靠前)\n整体思路：  首先我们要从上到下 从根节点到每个叶子节点的遍历 这就是先序遍历，另外遍历的时候需要将结果累计起来 ，同时也要把路过的节点给记录下来(可以用到栈)  代码 public ArrayList\u0026lt;ArrayList\u0026lt;Integer\u0026gt;\u0026gt; FindPath(TreeNode root,int target) { ArrayList\u0026lt;ArrayList\u0026lt;Integer\u0026gt;\u0026gt; res = new ArrayList(); if(root == null){ return res; } Stack\u0026lt;Integer\u0026gt; stack = new Stack\u0026lt;Integer\u0026gt;(); preOrder(root, stack, 0, target, res); return res; } public void preOrder(TreeNode root, Stack\u0026lt;Integer\u0026gt; stack, int sum, int target, ArrayList\u0026lt;ArrayList\u0026lt;Integer\u0026gt;\u0026gt; res){ if(root == null){ return; } stack.push(root.val); sum += root.val; //leaf node if(root.left == null \u0026amp;\u0026amp; root.right == null \u0026amp;\u0026amp; sum == target){ ArrayList\u0026lt;Integer\u0026gt; one = new ArrayList(); one.addAll(stack); res.add(one); } preOrder(root.left, stack, sum, target, res); preOrder(root.right, stack, sum, target, res); sum -= stack.pop(); }  BST转排序双向链表 题目描述 输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的双向链表。要求不能创建任何新的结点，只能调整树中结点指针的指向。\n整体思路： 一、搜索二叉树的特点： （1）其左子树的结点均小于它，其右子树的结点均大于它； （2）其子树也是搜索二叉树； 根据二叉树 特点（2） 可联想到使用递归；\n二、问题分解如下： 设：有任意结点 r step 1 将r的左子树变为有序链表，要输出此有序链表的头尾结点 Lhead、LTail； step 2 将r的右子树变为有序链表，要输出此有序链表的头尾结点 Rhead、RTail； step 3 将r结点与左有序链表和右有序两边连接；即将Ltail结点与r-\u0026gt;left连接；将r-\u0026gt;right 与 Rhead与其连接； step 4 返回以r结点为根的树的头与尾 ：Lhead、RTail 截止条件：r 为叶子结点\n作者：JameyGo 链接：https://leetcode-cn.com/problems/er-cha-sou-suo-shu-yu-shuang-xiang-lian-biao-lcof/solution/di-gui-yi-li-jie-by-jameygo/\n代码 class Solution { public: Node* treeToDoublyList(Node* root) { if (root == NULL){//如果树为空 则直接返回 return NULL; } Node* head, *tail; //找到其双向链表的头尾节点 listTree(root, head, tail); head-\u0026gt;left = tail;//头的前驱指向尾节点 tail-\u0026gt;right = head;//尾的后继指向头节点 return head;//返回头节点 } //针对每个节点将其看成单独的树 找到其双向链表的头节点和尾节点 void listTree(Node* r, Node* \u0026amp;head, Node* \u0026amp;tail){ if (r == NULL){//如果达到叶子节点 则直接返回 return; } Node* lhead, *ltail,*rhead,*rtail;//分别是左子树链表的头节点和尾节点 右子树的头节点和尾部节点 lhead = r;//左子树链表的头节点先指向当前节点 if (r-\u0026gt;left!=NULL){//如果有左孩子 递归调用listTree找到左子树链表的头尾节点 listTree(r-\u0026gt;left, lhead, ltail); r-\u0026gt;left = ltail;//当前节点的前驱指向左子树链表 尾节点 ltail-\u0026gt;right = r;//左子树链表 尾节点的后继指向当前节点 } rtail = r;//右子树链表的尾部节点也先指向当前节点 if (r-\u0026gt;right != NULL){//如果有右孩子 递归调用listTree找到右子树链表的头尾节点 listTree(r-\u0026gt;right, rhead, rtail); r-\u0026gt;right = rhead;//当前节点后继节点指向右子树链表的头节点 rhead-\u0026gt;left = r;//右子树链表的头节点的前驱指向当前节点 } head = lhead;//左子树右子树都处理完毕 整个链表的头节点就是左子树链表的头节点 tail = rtail;//整个链表的尾节点就是右子树链表的尾节点 } };  ","id":4,"section":"posts","summary":"时间复杂度 常数时间操作O(1) 操作时间是固定的次数，跟数据量本身没有关系，就是其时间复杂度是O(1),比如总是比较1次或者3次，比如总是累加","tags":["数据结构"],"title":"常用数据结构","uri":"http://heketong.github.io/2020/05/%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","year":"2020"},{"content":" 冒泡排序 介绍 ​ 冒泡排序是一种比较简单的排序，之所以叫冒泡，是因为在两两比较的过程中较大的数就像冒泡一样被换到后面。详细解释：依次比较相邻的两个数，前面的数大于后面的数，则交换，将较大的数挪动到后面\n 第1轮: 比较1 \u0026ndash; N 经过依次相邻两两比较交换 最大的数则放到了最后 第2轮: 比较1 \u0026ndash;N-1 经过依次相邻两两比较交换 第2大的数则放到了N-1的位置 第N-1轮:比较1 \u0026ndash; 2 前2个数两两比较交换 整个过程完成  代码  BubbleSort\nfunc BubbleSort(a []int) { if len(a) \u0026lt; 2 { //一个数或者为空 不用排序 return } //外层循环控控制每轮循环两两比较的最大下标 第1次为N-1 最后一次为1(也就是最前面的2个元素) for endPos := len(a) - 1; endPos \u0026gt; 0; endPos-- { //内层循环完成两两比较交换 for i := 0; i \u0026lt; endPos; i++ { if a[i] \u0026gt; a[i+1] { a[i], a[i+1] = a[i+1], a[i] } } } }  \n时间复杂度 ​ O($N^2$)\n稳定性 ​ 稳定 因为如果2个数相等 则他们的相对位置 并没有发生改变\n优化 ​ 看内层循环 如果并没有发生数据交换 则证明所有数据已经排序完成，这个时候直接结束即可 加一个标志判断即可\n BubbleSortOpt\nfunc BubbleSort(a []int) { if len(a) \u0026lt; 2 { //一个数或者为空 不用排序 return } isChg := false //外层循环控控制每轮循环两两比较的最大下标 第1次为N-1 最后一次为1(也就是最前面的2个元素) for endPos := len(a) - 1; endPos \u0026gt; 0; endPos-- { //内层循环完成两两比较交换 for i := 0; i \u0026lt; endPos; i++ { if a[i] \u0026gt; a[i+1] { a[i], a[i+1] = a[i+1], a[i] isChg = true } } if !isChg { //如果内层循环没有发生数据交换 则表明所有数据都已经排序完成 直接退出循环即可 break } } }  \n网搜图解 ​ 摘自: https://www.cnblogs.com/onepixel/p/7674659.html\n插入排序 介绍 ​ 插入排序顾名思义就是将一个待排序的元素，插入到一组已经排好序的元素中，如果形象比喻下，可以想象一下打牌，拿起来第一张牌自然就是排好序的，拿起第二张则跟第一张进行比较，插入到合适的位置。接下来拿第三张 跟前面2张已经排好序的比较，插入合适的位置，依次类推，拿完所有的牌，顺序自然也排好了。\n​ 将待排序的元素分为有序区和无序区，按照顺序每次从无序区拿一个元素，插入插入到有序区，直到所有无序区的元素都插入有序区，整个排序过程结束。第一次有序区为第1个元素，无序区为第2\u0026mdash;N个元素，拿出第2个元素插入到有序区。\n代码  InsertSort\nfunc InsertSort(a []int) { if len(a) \u0026lt; 2 { //一个数或者为空 不用排序 return } //j为无序区的第一个元素 对应下标从1开始，每次后移一个位置 for j := 1; j \u0026lt; len(a); j++ { //内层循环完成比较插入 倒序依次跟有序区的元素进行比较，如果小于有序区的元素 则交换 for i := j; i \u0026gt; 0; i-- { if a[i] \u0026lt; a[i-1] { a[i], a[i-1] = a[i-1], a[i] } } } }  \n时间复杂度 ​ O($N^2$)\n算法稳定性 ​ 稳定 没有改变两个相等元素的相对位置\n优化 ​ 上面代码内层循环在查找待插入位置时是倒序逐个比较的，在查找待插入位置时候是可以优化的，采用二分查找可以有效减少比较次数，但优化后的插入算法则变为不稳定的\n InsertSortOpt\n//BinSerachInsertIndex 二分查找在a数组 begin到end区间 key元素的插入位置 func BinSerachInsertIndex(a []int, begin int, end int, key int) int { pos := -1 //需要插入的位置 for begin \u0026lt;= end { mid := begin + (end-begin)/2 if a[mid] == key { //如果等于key 则找到位置 pos = mid + 1 break } else if a[mid] \u0026lt; key { begin = mid + 1 } else { end = mid - 1 } } if pos == -1 { pos = begin } return pos } func InsertSortOpt(a []int) { if len(a) \u0026lt; 2 { //一个数或者为空 不用排序 return } for j := 1; j \u0026lt; len(a); j++ { begin, end, key := 0, j-1, a[j] //找到插入的位置 pos := BinSerachInsertIndex(a, begin, end, key) //将pos到end区间的元素逐个后移 for index := j; index \u0026gt; pos; index-- { a[index] = a[index-1] } //插入待排序元素 a[pos] = key } }  \n网搜图解 ​ 摘自:https://www.cnblogs.com/onepixel/p/7674659.html\n归并排序 介绍 ​ MergeSort 合并两个有序的序列为1的大的有序的序列，最典型的归并排序可以分2个大的步骤：\n1 采用递归思想 将一个大的序列:二分为大致平均的子序列，然后针对每个子序列都再递归二分(最后每个子序列长度都为1)\n2 两两子序列合并为有序序列 直到所有子序列合并完成\n​ 整体归并排序也用到了很重要的分治思想，也就是将大的问题分为小的问题 逐个解决\n代码  MergeSort\nfunc MergeSort(a []int, left int, right int) { //校验 if len(a) \u0026lt; 2 || left \u0026lt; 0 || right \u0026gt; len(a) || left \u0026gt;= right { return } mid := left + (right-left)/2 //数组中间位置 MergeSort(a, left, mid) //左边归并排序 MergeSort(a, mid+1, right) //右边递归排序 MergeSlice(a, left, mid, right) //合并2个子序列为大的有序序列 } func MergeSlice(a []int, left int, mid int, right int) { //先生成1个辅助空间 长度 容量都是right-left+1 help := make([]int, right-left+1, right-left+1) helpIndex := 0 //help数组起始位置 填入一个数值 往后移动一位 //定义2个下标 开始分别指向2个子区间的最开始位置 然后逐个遍历 LIndex := left RIndex := mid + 1 for LIndex \u0026lt;= mid \u0026amp;\u0026amp; RIndex \u0026lt;= right { if a[LIndex] \u0026lt;= a[RIndex] { //左边区间数值较小 左边进辅助空间 help[helpIndex] = a[LIndex] LIndex++ } else { help[helpIndex] = a[RIndex] RIndex++ } helpIndex++ //不管左边区间进辅助还是右边区间 辅助数组下标下移一个位置 因为必定进了一个数 } for LIndex \u0026lt;= mid { //如果遍历完成 左边区间还有数没放进辅助数组 那就说明剩下的左边区间数较大 依次cp进辅助 help[helpIndex] = a[LIndex] LIndex++ helpIndex++ } for RIndex \u0026lt;= right { //如果遍历完成 左边区间还有数没放进辅助数组 那就说明剩下的左边区间数较大 依次cp进辅助 help[helpIndex] = a[RIndex] RIndex++ helpIndex++ } //辅助空间已经排好序 覆盖填回原数组 for i := 0; i \u0026lt; helpIndex; i++ { a[left+i] = help[i] } }  \n时间复杂度 ​ O( NLogN)\n算法稳定性 ​ 稳定\n优化 规模较小的时候 不用归并，改为插排 ​ 递归其实非常消耗性能 规模较小的时候可以不再递归 较少递归调用次数\n MergeSortOpt\nfunc MergeSortOpt(a []int, left int, right int) { //一个数 为空 下标不合法 拆分完成 if len(a) \u0026lt; 2 || left \u0026lt; 0 || right \u0026gt; len(a) || left \u0026gt;= right { return } if left+20 \u0026gt;= right {//这里增加几行代码 规模较小 改为插排 InsertSort(a[left : right+1]) return } mid := left + (right-left)/2 //数组中间位置 MergeSort(a, left, mid) //左边归并排序 MergeSort(a, mid+1, right) //右边递归排序 MergeSlice(a, left, mid, right) //合并2个子序列为大的有序序列 }  \n检查合并前两个数组是否已经有序 没有必要再调用合并了  MergeSortOpt2\nfunc MergeSortOpt2(a []int, left int, right int) { //一个数 为空 下标不合法 拆分完成 if len(a) \u0026lt; 2 || left \u0026lt; 0 || right \u0026gt; len(a) || left \u0026gt;= right { return } if left+20 \u0026gt;= right {//这里增加几行代码 规模较小 改为插排 InsertSort(a[left : right+1]) return } mid := left + (right-left)/2 //数组中间位置 MergeSort(a, left, mid) //左边归并排序 MergeSort(a, mid+1, right) //右边递归排序 if a[mid]\u0026lt;=a[mid+1]{//如果2个子序列本身已经有序 无需再合并 return } MergeSlice(a, left, mid, right) //合并2个子序列为大的有序序列 }  \n网搜图解 选择排序 介绍 ​ 每轮都选择一个极值(最大或者最小)放到数组的某一端，其实也是分为有序区和无序区，刚开始全是无序区，\n第1轮 遍历N个数 挑选极值放到数组最左侧 有序区有1个数\n第2轮 遍历剩下的N-1个数，挑选极值放入数组第2个位置，也就是依次放入有序区\n\u0026hellip;\n直到剩下最后一个元素 这个元素自然是整个数组的极值 整个数组排序完成\n代码  SelectSort\nfunc SelectSort(a []int) { if len(a) \u0026lt; 2 { //一个数或者为空 不用排序 return } for j := 0; j \u0026lt; len(a)-1; j++ {//控制每轮循环 遍历比较的元素个数 min := j\t//min记录最小元素下标 for i := j + 1; i \u0026lt; len(a); i++ { if a[min] \u0026gt; a[i] { min = i } } a[j], a[min] = a[min], a[j] //将最小元素依次放入有序区 } }  \n时间复杂度 ​ O($N^2$)\n算法稳定性 ​ 不稳定 会改变两个相等元素本身的相对位置 如 (7) 2 4 8 3 4 [7] 1 第一轮下来(7)会跑到最后\n优化 ​ 修改内层循环，每一轮遍历 不仅找到最小下标 也要找到最大下标 最小放数组左边，最大放数组右边，减少循环次数，当然外层循环条件也要修改，最开始无序区为整个数组 每一轮下来 数组两端2个元素变为有序，有序区从两端往中间扩大，直到所有元素都为有序  SelectSortOpt\nfunc SelectSortOPT(a []int) { if len(a) \u0026lt; 2 { //一个数或者为空 不用排序 return } //刚开始left right分别为数组最小和最大下标 每轮循环left和rignt分别放置最小和最大值 //终止条件为left==right 每轮循环后left右移 right左移 for left, right := 0, len(a)-1; left \u0026lt; right; left, right = left+1, right-1 { minIndex, maxIndex := left, right for i := left; i \u0026lt;= right; i++ { if a[i] \u0026lt; a[minIndex] { //找到最小值下标 minIndex = i } if a[i] \u0026gt; a[maxIndex] { //找到最大值下标 maxIndex = i } } a[left], a[minIndex] = a[minIndex], a[left]//最小的放当前无序区最左边 if left == maxIndex { //如最大下标就是刚开始的最小下标 因为已经交换到了minIndex位置 所以最大下标也要跟着修改 maxIndex = minIndex } a[maxIndex], a[right] = a[right], a[maxIndex]//最大值放到当前无序区最右边 } }  \n网搜图解 ​ 摘自： https://www.cnblogs.com/onepixel/p/7674659.html\n堆排序 介绍 二叉堆介绍 堆排序是借助堆这种数据结构进行排序，又分为最大堆和最小堆。堆也分很多种，这里用二叉堆，下面从网上找到的2张图展示下最大堆和最小堆。\n​ 最大堆 所有父节点都\u0026gt;=两个子节点 最小堆 所有父节点都\u0026lt;=两个子节点\n​ 最大堆 可用于升序排序 最小堆可用于降序排序\n​ 二叉堆实现方式不止一种，这里选择最简单的数组实现，下图展示二叉堆如何用数组存放以及父子节点关系如何对应到数组下标关系。\n堆排序大致过程  首选遍历数组 构建二叉堆(数组实现)\n 交换堆头尾两个元素，也就是数组头尾元素，最大值放到了数组最后一个元素。因为根节点发生变化\n  所以重新堆化，范围不包括最后一个元素，最后一个元素相当于已经输出排序完成，为最大值。\n 对于重新堆化的前面N-1个元素 循环执行第2步 直到输出所有堆节点 完成最终排序  代码 最大堆  MaxHeapSort\nfunc MaxHeapSort(a []int) { size:=len(a)//数组长度 if size \u0026lt; 2 { return } for i := 0; i \u0026lt; len(a); i++ {//遍历数组 构建堆 MaxHeapInsert(a, i) } for size \u0026gt; 0 { a[0], a[size-1] = a[size-1], a[0] //将当前堆顶也就是最大值放到最后 把最后的元素换到堆顶 然后重塑堆 size-- MaxHeapify(a, 0, size) } } func MaxHeapInsert(a []int, index int) { //如果插入节点大于父节点 则需要向上调整 先跟父节点交换 然后再比较上面的父节点 for parentIndex := (index - 1) / 2; a[index] \u0026gt; a[parentIndex]; index, parentIndex = parentIndex, (index-1)/2 { a[index], a[parentIndex] = a[parentIndex], a[index] } } //大堆 重新堆化过程 func MaxHeapify(a []int, index int, size int) { for maxIndex := -1; maxIndex != index; { maxIndex = index leftIndex := 2*index + 1 rightIndex := 2*index + 2 //求当前节点 左孩子 右孩子中最大值对应的下标 if leftIndex \u0026lt; size \u0026amp;\u0026amp; a[maxIndex] \u0026lt; a[leftIndex] { maxIndex = leftIndex } if rightIndex \u0026lt; size \u0026amp;\u0026amp; a[maxIndex] \u0026lt; a[rightIndex] { maxIndex = rightIndex } if maxIndex != index { a[index], a[maxIndex] = a[maxIndex], a[index] //跟左孩子、右孩子中最大的交换 index = maxIndex maxIndex = -1 } } }  \n最小堆  MinHeapSort\nfunc MinHeapSort(a []int) { if len(a) \u0026lt; 2 { return } for i := 0; i \u0026lt; len(a); i++ { MinHeapInsert(a, i) } size := len(a) for size \u0026gt; 0 { a[0], a[size-1] = a[size-1], a[0] //将当前堆顶也就是最大值放到最后 把最后的元素换到堆顶 然后重塑堆 size-- MinHeapify(a, 0, size) } } //MinHeapInsert 创建大堆 数组实现 index为要插入的元素下标 //节点下标为i 对应左孩子为2*i+1 右边孩子为2*i+2 //节点下标为i 对应父节点为(i-1)/2 func MinHeapInsert(a []int, index int) { parentIndex := (index - 1) / 2 for a[index] \u0026lt; a[parentIndex] { //如果插入节点小于父节点 则需要向上调整 先跟父节点交换 然后再比较上面的父节点 a[index], a[parentIndex] = a[parentIndex], a[index] index = parentIndex parentIndex = (index - 1) / 2 } } //MinHeapify 下标index发生了变化 重塑堆 一路向下调整 如果两个孩子中有一个比自己小 则交换 然后继续往下调整找到比自己小的孩子 然后跟其交换 //节点下标为i 对应左孩子为2*i+1 右边孩子为2*i+2 //节点下标为i 对应父节点为(i-1)/2 func MinHeapify(a []int, index int, size int) { for minIndex := -1; minIndex != index; { minIndex = index leftIndex := 2*index + 1 rightIndex := 2*index + 2 //求当前节点 左孩子 右孩子中最小值对应的下标 if leftIndex \u0026lt; size \u0026amp;\u0026amp; a[minIndex] \u0026gt; a[leftIndex] { minIndex = leftIndex } if rightIndex \u0026lt; size \u0026amp;\u0026amp; a[minIndex] \u0026gt; a[rightIndex] { minIndex = rightIndex } if minIndex != index { a[index], a[minIndex] = a[minIndex], a[index] //跟左孩子、右孩子中最小的交换 index = minIndex minIndex = -1 } } }  \n时间复杂度 ​ O(NlogN)\n算法稳定性 ​ 不稳定\n优化 ​ 当前实现的就是原地堆排序，没有使用额外的辅助空间，暂无好的优化思路，待补充\n网搜图解 希尔排序 介绍 ​ 希尔排序是直接插入排序的优化版本，由一个叫shell的人提出来的，核心思想是按照步长分组，然后每组分组插排，然后缩短步长分组，继续每组插排，最后步长为1，变为直接插排。\n​ 关于步长及缩短步长如何选择，有很多种方案，可以直接分半，然后再除以2 最后为1，这里采用的Knuth序列，也就是按照下面的规律递增\ngap=1\u0026mdash;\u0026ndash;\u0026gt;\u0026gt;gap=3*gap+1\n代码  ShellSort\nfunc ShellSort(a []int) { //步长采用knuth序列 变化规律为 h=1 ---\u0026gt; h = 3*h+1 h := 1 for h \u0026lt;= len(a)/3 { h = 3*h + 1 } //控制gap递减 最后变为1 for gap := h; gap \u0026gt; 0; gap = (gap - 1) / 3 { //控制分组 for j := gap; j \u0026lt; len(a); j++ { //每组进行直接插排 for i := j; i \u0026gt; gap-1; i = i - gap { if a[i] \u0026lt; a[i-gap] { a[i], a[i-gap] = a[i-gap], a[i] } } } } }  \n时间复杂度 O($N^3\u0026frasl;2$)\n算法稳定性 ​ 不稳定\n优化 ​ 待补充\n网搜图解 快速排序 介绍 ​ 快速排序主要用到了分治和递归思想，跟归并排序差不多，快速排序一般要选择一个基准值(pivot),然后将小于这个基准的放左边，大于这个基准的放右边，基准值放那边无所谓，这样一轮下来，数组分成了2个区域，左边区域比右边区域小，然后对2个区域用递归的方法继续快排。\n​ 这里的快速用荷兰国旗问题分成了3个区域，pivot 然后递归 pivot的区域 继续分区快排序\n​ 关于基准值的选取可以有很多种，可以随机选取，可以最前面的，可以最后面的，这里采用的是最常见(选取最末端元素)\n代码  QuickSort\nfunc QuickSort(a []int, left int, right int) { if len(a) \u0026lt; 2 || left \u0026gt;= right { return } base := a[right] //基准选取最末端元素 equalArea := PartitionIntSlice(a, left, right, base) QuickSort(a, left, equalArea[0]-1) //递归快排小于区间 QuickSort(a, equalArea[1]+1, right) //递归快排大于区间 } //PartitionIntSlice 给定一个数组，左边界left 右边界right 比较基准base //返回一个2个数值的int数组 该数组第一个值为等于base的开始位置 第二个值为等于base的结束位置 //所以下标小于该数组第一个值的区间都小于base 下标大于数组第二个值的区间都大于base func PartitionIntSlice(a []int, left int, right int, base int) [2]int { l := left - 1 //l为小于区间的结束下标 刚开始指向最小下标左边 r := right + 1 //l为大于区间的开始下标 刚开始指向最大下标右边 cur := left //当前遍历的数设置为整个区间最左边 for cur \u0026lt; r { if a[cur] \u0026lt; base { //如果当前数小于基数 当前数和小于区间的下一个数交换 小于区间扩一个 a[cur], a[l+1] = a[l+1], a[cur] l++ cur++ } else if a[cur] \u0026gt; base { //如果当前数大于基数 则cur下标++ a[cur], a[r-1] = a[r-1], a[cur] r-- } else { //当前数跟基数相等 不变 cur++ } } return [2]int{l + 1, r - 1} }  \n时间复杂度 ​ O(NlogN)\n算法稳定性 ​ 不稳定\n优化 ​ 可以选择双轴快排序，也就是选择2个base(不相同,相同的话就又变成了荷兰国旗) 分区为 maxbase\n代码后续补充\n网搜图解 计数排序 介绍 ​ 计数排序的应用场景比较清晰，也是桶排序的一种。明确的知道一个数组有N的整数，量比较大，但是数据范围比较小 都是[0,MAX), 然后创建一个计数数组，长度为MAX,计数数组值都初始化为0，然后遍历原数组，将原数组的值和计数数组的下标对应起来，比如原数组某个元素值为1，则计数数组下标为1的元素加1，表示1的元素出现过一次，这个步骤可以叫做入桶。然后顺序遍历计数数组，如果该下标的元素出现过(也就是值\u0026gt;0)，数组元素值为多少，则该下标出桶多少次，依次填回原数组即可。\n​\n代码  CountingSort\nfunc CountSort(a []int, max int) { if len(a) \u0026lt; 2 { return } count := make([]int, max, max) //创建计数的桶 for i := 0; i \u0026lt; len(a); i++ { count[a[i]]++ } indexOfa := 0 for i := 0; i \u0026lt; len(count); i++ { for count[i] \u0026gt; 0 { a[indexOfa] = i indexOfa++ count[i]-- } } }  \n时间复杂度 O(N)\n算法稳定性 ​ 直接计数排序本身是不稳定的，如果采用累加计数数组，然后倒序遍历原数组结合累加计数数组 则可以实现成稳定的，下面优化版本给出了一个稳定版本\n优化 ​ 分桶方法可以有很多种，比如0号桶 存放0-9数据 1号桶存放10-19等等都是可以的，每个桶可以再放一个数组 然后对于这个数组进行快排或者插排之类的\n如果某个桶数量太大，可以针对这个桶继续分桶等等 这里不再赘述，后续有兴趣再补充。\n这里列出一个稳定版本的计数排序\n CountSortStable\n//CountSortStable 桶排序的一种 应用场景 知道一个数组有N个整数 并且范围都是[0 ,MAX) //也就是量大 但是数据范围比较小 稳定版本 采用累加计数数组+倒序遍历原数组 func CountSortStable(a []int, max int) { if len(a) \u0026lt; 2 { return } count := make([]int, max, max) //创建桶 for i := 0; i \u0026lt; len(a); i++ { count[a[i]]++ } //累加计数数组 从下标1开始 其值等于count[i]+count[i-1] for i := 1; i \u0026lt; len(count); i++ { count[i] += count[i-1] //记录原数组元素在原数组出现的最后一个位置 } //然后倒序遍历原数组 这里要用到一个附加数组 help := make([]int, len(a), len(a)) for k := len(a) - 1; k \u0026gt;= 0; k-- { count[a[k]]-- lastIndex := count[a[k]] //这里为了代码好理解 多写一行 help[lastIndex] = a[k] } for i := 0; i \u0026lt; len(help); i++ { a[i] = help[i] } }  \n网搜图解 基数排序 介绍 ​ 基数排序也是桶排序的一种，主要思想是按照低优先级先排序 然后再按照高优先级再排序，最后完成排序。\n比如整数排序，先按照个位排序，再按照十位排序 再按照百位、千位排序，可以参看图解，比较一目了然\n代码  RadixSort\n//GetMax 返回数组中的最大值 func GetMax(a []int) int { max := a[0] for i := 1; i \u0026lt; len(a); i++ { if a[i] \u0026gt; max { max = a[i] } } return max } //radixSort 传入按照什么基数排序 1 个位 10十位 100百位... func radixSort(a []int, radix int) { help := make([]int, len(a), len(a)) //无论是个位、十位、百位... 都只有0-9 10个数字 所以准备10个桶 bucket := make([]int, 10, 10) for i := 0; i \u0026lt; len(a); i++ { radixNum := (a[i] / radix) % 10 //得到某个基数位的数字 比如345 传入radix是1 也就是个位数也就是3 bucket[radixNum]++ } //这个for循环完成 也就完成了个位数桶计数 比如bucket[1]=3 也就是个位数是1的数字有3个 for j := 1; j \u0026lt; len(bucket); j++ { bucket[j] += bucket[j-1] } //这个for循环完成 桶计数含义发生改变 bucket[1]=3表示个位数\u0026lt;=1的数字有3个 //倒序遍历原数组 按照基数位排序后输出到辅助数组 for k := len(a) - 1; k \u0026gt;= 0; k-- { bucket[(a[k]/radix)%10]-- help[bucket[(a[k]/radix)%10]] = a[k] } for i := 0; i \u0026lt; len(a); i++ { a[i] = help[i] } } //RadixSort 基数排序 先按照个位排序 再按照10位排序 再按照百位排序 ... func RadixSort(a []int) { max := GetMax(a) for radix := 1; max/radix \u0026gt; 0; radix *= 10 { radixSort(a, radix) //依次按照个位 十位 百位 ...排序 } }  \n时间复杂度 ​ O(X*2N) 这里的X 主要是指分了多少个基数 比如个位、十位、百位 那X=3 对于每个基数 内部都至少需要2N的时间复杂度\n算法稳定性 ​ 上面实现的是稳定的 就是采用累加计数 然后倒序遍历数组的方法\n优化 ​ 待补充\n网搜图解 桶排序 介绍 计数排序和基数排序是最常见的2种桶排序思想，不是基于比较的排序思想，桶排序的前提假设大致如下：   假设原数据是大值均匀分布的 量也比较大 在原数据上建立1个函数映射关系 将原数据映射到有限个数的桶上 然后针对每个桶再想办法排序(比如插排、快排等) 最后按照桶顺序依次输出桶里的元素 就完成了整个排序  代码 ​ 这里不写代码了\n时间复杂度 ​ 去掉常数项就是O(N)\n算法稳定性 可以做到稳定\n优化 待补充\n网搜图解 待补充\n","id":5,"section":"posts","summary":"冒泡排序 介绍 ​ 冒泡排序是一种比较简单的排序，之所以叫冒泡，是因为在两两比较的过程中较大的数就像冒泡一样被换到后面。详细解释：依次比较相邻的两","tags":["数据结构","算法","排序"],"title":"排序_数据结构与算法","uri":"http://heketong.github.io/2020/05/%E6%8E%92%E5%BA%8F_%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/","year":"2020"},{"content":" 高并发性能相关指标或术语回顾 连接相关 服务端能保持，管理，处理多少客户端的连接\n 活跃连接数：所有ESTABLISHED状态的TCP连接，某个瞬时，这些连接正在传输数据。如果您采用的是长连接的情况，一个连接会同时传输多个请求。也可以间接考察后端服务并发处理能力，注意不同于并发量。 非活跃连接数：表示除ESTABLISHED状态的其它所有状态的TCP连接数。 并发连接数：所有建立的TCP连接数量。=活跃连接数+非活跃连接数。 新建连接数：在统计周期内，从客户端连接到服务器端，新建立的连接请求的平均数。主要考察应对 突发流量或从正常到高峰流量的能力。如：秒杀、抢票场景。 丢弃连接数：每秒丢弃的连接数。如果连接服务器做了连接熔断处理，这部分数据即熔断的连接  在linux上socket连接体现上就是文件描述符，高并发中相关的参数一定要调优。\n流量相关 ​ 主要是网络带宽的配置。\n 流入流量：从外部访问服务器所消耗的流量。 流出流量：服务器对外响应的流量。  数据包数 数据包是TCP三次握手建立连接后，传输的内容封装\n 流入数据包数：服务器每秒接到的请求数据包数量。 流出数据包数：服务器每秒发出的数据包数量。  如果数据包太大可以考虑压缩，因为传输的数据包小 效率一般会提升，但解压缩也需要性能消耗，不能无限制压缩\n应用传输协议 ​ 传输协议压缩率好，传输性能好，对并发性能提升高。但是也需要看调用双方的语言可以使用协议才行。可以自己定义，也可以使用成熟的传输协议。比如redis的序列化传输协议、json传输协议、Protocol Buffers传输协议、http协议等。 尤其在 rpc调用过程中，这个传输协议选择需要仔细甄别选型。\n长连接、短连接  长连接是指在一个TCP连接上，可以重用多次发送数据包，在TCP连接保持期间，如果没有数据包发送，需要双方发检测包以维持此连接。 半开连接的处理：当客户端与服务器建立起正常的TCP连接后，如果客户主机掉线（网线断开）、电源掉电、或系统崩溃，服务器将永远不会知道。长连接中间件，需要处理这个细节。linux默认配置2小时，可以配置修改。不过现实项目一般不用系统的这个机制，很多直接使用客户端心跳包维持连接，服务端启动定时器，超时就close掉连接 短连接是指通信双方有数据交互时，就建立一个TCP连接，数据发送完成后，则断开此TCP连接。但是每次建立连接需要三次握手、断开连接需要四次挥手。 关闭连接最好由客户端主动发起，TIME_WAIT这个状态最好不要在服务器端，减少占用资源，当然如果是使用短连接，客户端高频的出现TIME_WAIT也要注意临时端口耗尽的问题，可以有很多优化(比如SO_REUSEADDR选项、SO_LINGER选项，临时端口范围调优等)  选择建议：\n 在客户端数量少场景一般使用长连接。后端中间件、微服务之间通信最好使用长连接。如：数据库连接，duboo默认协议等。 而大型web、app应用，使用http短连接（http1.1的keep alive变相的支持长连接，但还是串行请求/响应交互）。http2.0支持真正的长连接。 长连接会对服务端耗费更多的资源，上百万用户，每个用户独占一个连接，对服务端压力多大，成本多高。IM、push应用会使用长连接，但是会做很多优化工作。 由于https需要加解密运算等，最好使用http2.0（强制ssl），传输性能很好。但是服务端需要维持更多的连接。  并发连接和并发量  并发连接数：=活跃连接数+非活跃连接数。所有建立的TCP连接数量。网络服务器能并行管理的连接数。 并发量：瞬时通过活跃连接传输数据的量，这个量一般在处理端好评估。跟活跃连接数没有绝对的关系。网络服务器能并行处理的业务请求数。 rt响应时间：各类操作单机rt肯定不相同。比如：从cache中读数据和分布式事务写数据库，资源的消耗不同，操作时间本身就不同。 吞吐量：QPS/TPS，每秒可以处理的查询或事务数，这个是关键指标。  IO多路复用 相关观念回顾 用户空间与内核空间  linux操作系统采用虚拟存储器技术，对于32位操作系统，内存寻址空间就是4G(2^32)。操作系统的核心叫做内核kernel，独立于普通的Application，内核是可以访问受保护的内存空间，也有访问底层硬件的权限。为了保证用户进程不能直接操作内核(内核要足够稳定)，所以操作系统将虚拟空间划分2部分，一部分叫做内核空间，一部分叫做用户空间。\n linux操作系统32位，将最高的1G(虚拟地址0xC0000000到0xFFFFFFFF) 是给内核使用的，叫做内核空间，而较低的3G字节(虚拟地址从0x00000000到0xBFFFFFFF)，给各个应用进程使用，叫做用户空间。\n 每个进程可以通过系统调用进入内核，因此linux内核有系统内的所有进程共享，空间分配图大致如下:\n   linux系统内部结构大值图示:   当一个任务(往往是进程或者线程)执行系统调用也就是执行内核代码，进程就进入内核态，当任务执行用户自己的代码，称为处于用户运行态(用户态)  进程切换  为了控制各个进程的执行，内核必须有能力挂起某个正在运行的进程(正在使用cpu)，并具有恢复以前挂起进程并执行的能力。这种挂起与恢复执行往往被称为进程切换，任何进程都是在操作系统内核的支持下才能正常运行，跟内核密切相关。 进程切换大致涉及内容：\n 保存处理机的上下文，比如程序计数器、寄存器 更新进程PCB(Process Control Block)信息 将进程PCB放入相应的队列，如就绪队列，某些时间的阻塞等待队列等等 选择另外一个进程执行，更新其PCB信息 更新内存管理的数据结构 恢复处理机上下文  linux一个注释\n 当一个进程在执行时,CPU的所有寄存器中的值、进程的状态以及堆栈中的内容被称为该进程的上下文。当内核需要切换到另一个进程时，它需要保存当前进程的所有状态，即保存当前进程的上下文，以便在再次执行该进程时，能够必得到切换时的状态执行下去。在LINUX中，当前进程上下文均保存在进程的任务数据结构中。在发生中断时,内核就在被中断进程的上下文中，在内核态下执行中断服务例程。但同时会保留所有需要用到的资源，以便中继服务结束时能恢复被中断进程的执行   进程阻塞  正在执行的进程，由于等待某些事件(等待系统资源，等待某种操作完成，新的数据尚未到达或者没有新的工作等)，则会有操作系统自动执行阻塞原语(Block),使自己由运行状态变为阻塞状态，进度阻塞状态之后，进程不占用cpu资源，等待的事件完成后再由内核将其唤醒。  文件描述符  File Descriptor为计算机科学中的一个术语，是一个抽象概念，用于表述指向文件的引用 在形式上是一个非负整数，实际上是一个索引值，指向内核为每个进程维护的一个打开文件的记录表。 当进程打开一个现有文件或者创建一个新文件，内核将返回其一个文件描述符 一些类Unix底层程序往往会围绕文件描述符展开工作  缓冲I/O  linux有I/O缓存机制，操作系统会将I/O数据缓存在文件系统的页缓存(page catch)中，也就是数据往往先被操作系统拷贝到内核的缓冲区，然后再由操作系统内核的缓冲区拷贝到用户程序的地址空间。 缓存I/O机制导致数据在传输过程中需要用户空间和内核空间进行多次拷贝，这就必然导致cpu和内存开销  常见I/O模式复习  就拿read距离，数据先被拷贝到内核缓存区，然后再拷贝到用户地址空间，所以会经过2个阶段\n 内核等待数据准备(Waiting for the data to be ready) 数据从内核拷贝到进程(Copying the data from the kernel to the process)  正是因为I/O缓存机制带来的2阶段，所以有了linux系统常见的5种I/O模式\n 阻塞I/O ( blocking IO)\n 非阻塞I/O (nonblocking IO)\n I/O多路复用 (IO multiplexing)\n 信号驱动I/O (signal driven IO)\n 异步I/O ( asynchronous IO)\n  其中信号驱动IO实际开发中用到的不太多，下面复习下几个常用的IO模式\n  Blocking IO 阻塞IO  默认linux所有的socket都是blocking的(有API设置为nonblocking),典型读操作流程如下:   process call recv/recvform \u0026mdash;\u0026gt;process blocking 进程执行系统调用 进程阻塞\n Kernel wait for the data 内核等待缓冲区数据达到(网络IO数据到缓冲区一般需要一定时间) process still blocking Data is ready ,copy data to user 数据达到后 内核将其拷贝到用户空间 process unblock to run 进程解除阻塞，这个地方也需要cpu调度，其实也需要时间   blocking IO的特点就是IO执行的2个阶段，进程一致处于阻塞状态 不能执行其它任务\n下面再摘一个图:\nNonBlocking IO 非阻塞IO  可以调用API将socket设置为non-blocking 大致流程如下  while ( recv(data)!=OK ){//系统调用recv不会阻塞，如果data is not ready,内核立马返回失败 wait sometime;//进程判断失败 往往休眠一定时间 再次调用recv系统调用 }   因为没有阻塞 系统调用会立马返回，但往往数据不会立马ready，所以非阻塞IO往往要不断的执行系统调用询问内核数据是否准备好了  IO multiplexing IO多路复用  这里常常就是指的select、pol、epoll，多路是指管理多个文件描述符，复用是指同一个进程或者一个线程，所以总结起来就是同一个进程(线程)管理多个文件描述符，提高IO处理效率的技术 select方式多路复用图解 select过程大致如下\n 进程首先要将需要管理的描述符扔进select集合 进程调用select API(往往会设置超时时间，因为不设置没有数据到达就需要循环select)，此时进程进入blocking状态 内核收到api调用就会循环监视注册的文件描述符对应的数据是否准备好了 如果有一个好了，select就立马返回 然后进程收到select返回 再调用read操作，将数据从内核拷贝到用户进程  select模式跟阻塞IO模式没有太大的不同，而且有2次系统调用(select、recv)，普通的阻塞只有一个recv,但select的优势在于一个进程可以管理很多个文件描述符，也就是同时处理多个链接(socket conn)\n 如果需要处理的连接数不高的话，单任务select/poll/epoll的服务器 不一定比多任务的blocking IO性能高，因为让内核轮询每个描述符也是需要花费时间的，有可能延迟会更大，IO多路复用的优势在于能够处理更多的连接，而不是单个连接的处理速度更快。\n IO多路复用下一般都将socket设置为non-blocking，而且要注意此时进程还是blocking的 只不过是被select/poll/epoll调用blocking,之前是被recvfrom调用blocking，但这个blocking的代价较小，因为我们可以管理更多的套接字。\n  Asynchronous IO 异步IO  异步IO个人接触的也不多，也是大致了解流程，看个图：   用户发起异步read操作后，kernel直接返回，进程也该干嘛干嘛，没有blocking kernel等数据ready后 copy to user，然后给用户进程发送一个信号(singnal) 进程收到信号，调用注册的处理函数进行数据读取 貌似异步IO非常NB，但其实linux并没有实现一个完美的AIO，而且异步IO必须预先分配缓存，这个可能造成内存浪费，这都可能是AIO没有流行的原因  Blocking与non-blocking 阻塞与非阻塞  通常是说调用操作后，如何数据尚未到达，或者不具备条件，kernel是否返回，如果立马返回(不管有无数据)，就是non-blocking,如果kernel等待数据到达，没有立马返回，那就是阻塞  Synchronous IO与asynchronous IO Posix定义如下：\n A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes An asynchronous I/O operation does not cause the requesting process to be blocked  如果执行IO操作 进程被block就是同步，否则就是异步 上面的4种IO模式，除了最后的AIO都是同步IO，IO多路复用虽然将socket设置为non-blocking,但其实调用select/poll/epoll还是会blocking\n几种IO模式比较图 同步阻塞BIO 服务端单任务 listenFd=socket(...);//创建socket bind(listenFd,...);//绑定端口 listen(listenFd,...);//开启监听 while(1) { // accept阻塞 client_fd = accept(listen_fd);//这里会阻塞 导致没法及时处理已经连接的客户端的请求 if (recv(client_fd)) {//读取客户端请求数据 这里也会阻塞，会导致没法接受新的客户端请求 // logic send(client_fd,...);//回包 这里也会阻塞，会导致没法接受新的客户端请求 } } // 这种模式教学可以，实际项目中没法处理高并发的请求  同步非阻塞 服务端单任务 listenFd=socket(...);//创建socket setNonblocking(listen_fd) bind(listenFd,...);//绑定端口 listen(listenFd,...);//开启监听 while(1) { // accept阻塞 client_fd = accept(listen_fd);//这里会阻塞 导致没法及时处理已经连接的客户端的请求 setNonblocking(client_fd)；//设置为非阻塞 fds.add(client_fd);//加入轮询集合; for( fd in fds){//循环检查 if (recv(client_fd)) {//读取客户端请求数据 这里也会阻塞，会导致没法接受新的客户端请求 // logic send(client_fd,...);//回包 这里也会阻塞，会导致没法接受新的客户端请求 } } } //处理小量并发是没有问题，但比较浪费cpu，因为每一轮循环都要针对每一个客户端套接字执行检查 //同时因为是单任务，遇到高并发肯定也要歇菜，假设有1000个client，第一个发送了请求，但是for循环检查的时候跳过了，然后要等到其它999个连接都检查处理完了，才能轮到这个client，很有可能已经超时了  同步阻塞BIO 服务端多并发任务 listenFd=socket(...);//创建socket bind(listenFd,...);//绑定端口 listen(listenFd,...);//开启监听 while(1) { // accept阻塞 client_fd = accept(listen_fd);//主进程 或者主线程只负责accept新的client连接 new ThreadProcess(client_fd){//这里开启多任务(多线程或者多进程)，一个client一个处理任务线程(进程) if (recv(fd)) {// // logic process send(client_fd,...);//回包 } } } //并发量不是很大的时候，这种模式是能够良好应对的，但如果并发量很大，比如上万，大量的线程或者进程也会占用大量内存，而且进程切换或者线程切换都会浪费cpu，就会导致真正工作的任务比例往往很低，所以这种模式遇到真正高并发也会歇菜。 //用go语言实现一个这样的模式非常简单 来一个client就开启一个routine去处理即可  IO多路复用\u0026mdash;select API原型  //将一个fd从关心的fdset中移除 其实就是将对应的坑位置0 void FD_CLR(fd, fd_set *fdset); // 检查fd是否在对应的fdset中 也就是检查对应的坑位是否为1 int FD_ISSET(fd, fd_set *fdset); //将fd增加到要关心的fdset集合中 也就是将对应fdset坑位置1 比如客户端socket fd为9，就是将fdset[9]设置为1 void FD_SET(fd, fd_set *fdset); // 清空要关心的fdset集合 将fdset数组全部置0 void FD_ZERO(fd_set *fdset); // nfds为最大检查描述符 select将对fdset数组0\u0026mdash;\u0026gt;ndfs下标做检查 如果下标对应的value为1 则需要检查描述符是否具备条件了 不用1024个都检查，传入这个最大检查描述符是为了提高select轮询的效率 //readfds为关心读事件的描述符集合 writefds为关心写事件的描述符集合 errorfds为关心异常事件的描述符集合 //timeout为一个结构体 如何设置为null，则对应3个fdset若都没有就绪的描述符 进程将一直blocking //timeout如果设置为0 则select检查一轮将直接返回 不会等待 //timeout如果设置为具体的秒+微秒 则select最多等待设置的时间，如果没有就返回 //同时要说明的是select是轮询所有设置fdset中的所有value为1的描述符，如何符合要求就全部都返回 int select(int nfds, fd_set *restrict readfds, fd_set *restrict writefds, fd_set *restrict errorfds, struct timeval *restrict timeout); 关于 fd_set一般是一个int类型数组 一般初始化大小为1024 用来保存哪些fd需要检查，这个1024是可以调整的，但比较麻烦这也是select不足的地方，而且能监控的一般没有1024，因为进程或者线程一般都有打开的文件描述符，比如标准输入输出出错，或者打开的有日志文件等等。  不足  能监控的描述符数量有限 修改起来也比较麻烦 每次select都需要全部设置一遍需要关心的fdset集合，这就涉及到用户态到内核态的拷贝 效率不会很高 select内部实现是轮询，不管描述符对应是否就绪，所以性能也不会太高 ，当然如果监控的套接字都非常活跃，那这个轮询性能问题也可以忽略(但正是因为都非常活跃，所以select返回后单任务处理也会遇到瓶颈，因为大量活跃的连接等待处理，但是只有一个单任务进程/线程在处理)  其它说明  select监控的socketfd 跟socketfd本身是否是blocking没有关系，所有套接字是阻塞时真正recv或者write的时候 如果数据不具备条件则内核直接返回或者阻塞等待，selelct只是检查数据是否具备读条件了，没有发生真正读写，而且是内核直接判断读写缓冲区是否符合条件的 但不能说调用select的进程是不阻塞的，理论上调用了select也是一直阻塞的，只是阻塞时间的长短(timeout设置为0 只轮询一次就返回，如果为null，无限等待直到至少有一个套接字符合条件，如果设置为具体时间，则最多等待这个设置时间)，只是进程不是因为调用recv或者write阻塞，而是调用select阻塞，而且返回的可以是多个符合读写的fd。  代码  select示例代码转载加注释，简单优化c\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;netinet/in.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;sys/select.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;netinet/in.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #define IPADDR \u0026quot;127.0.0.1\u0026quot; #define PORT 8787 #define MAXLINE 1024 #define LISTENQ 5 #define MAXCLIENTSIZE 10 //当前套接字连接信息结构体 typedef struct server_context_st { int cli_cnt; /*已连接过的客户端个数*/ int clifds[MAXCLIENTSIZE]; /*客户端套接字集合*/ fd_set allfds; /*句柄集合*/ int maxfd; /*句柄最大值*/ } server_context_st; static server_context_st *s_srv_ctx = NULL; /*=========================================================================== createSocketAndListen 根据传入字符串格式ip和端口port，创建socket并且开启监听 * ==========================================================================*/ static int createSocketAndListen(const char* ip,int port){ int fd; struct sockaddr_in servaddr; //int socket(int domain, int type, int protocol); fd = socket(AF_INET, SOCK_STREAM,0); if (fd == -1) { fprintf(stderr, \u0026quot;create socket fail,erron:%d,reason:%s\\n\u0026quot;, errno, strerror(errno)); return -1; } /*一个端口释放后会等待一段时间后(比如两分钟)才能再被使用，SO_REUSEADDR是让端口释放后立即就可以被再次使用。*/ int reuse = 1; if (setsockopt(fd, SOL_SOCKET, SO_REUSEADDR, \u0026amp;reuse, sizeof(reuse)) == -1) { return -1; } //套接字结构体初始化为0 bzero(\u0026amp;servaddr,sizeof(servaddr)); servaddr.sin_family = AF_INET; //ip ASCII字符串转为二进制 inet_pton(AF_INET,ip,\u0026amp;servaddr.sin_addr); //port转为网络字节序 servaddr.sin_port = htons(port); //套接字绑定ip和端口 if (bind(fd,(struct sockaddr*)\u0026amp;servaddr,sizeof(servaddr)) == -1) { perror(\u0026quot;bind error: \u0026quot;); return -1; } //开启监听 if ( listen(fd,LISTENQ) == -1){ perror(\u0026quot;listen error: \u0026quot;); return -1; } return fd; } /*=========================================================================== accept_client_proc 传入服务端监听套接字，接受客户端连接 * ==========================================================================*/ static int accept_client_proc(int srvfd) { struct sockaddr_in cliaddr; socklen_t cliaddrlen; cliaddrlen = sizeof(cliaddr); int clifd = -1; printf(\u0026quot;accpet clint proc is called.\\n\u0026quot;); ACCEPT: clifd = accept(srvfd,(struct sockaddr*)\u0026amp;cliaddr,\u0026amp;cliaddrlen); if (clifd == -1) { if (errno == EINTR) { goto ACCEPT; } else { fprintf(stderr, \u0026quot;accept fail,error:%s\\n\u0026quot;, strerror(errno)); return -1; } } //打印客户端套接字信息 fprintf(stdout, \u0026quot;accept a new client: %s:%d\\n\u0026quot;, inet_ntoa(cliaddr.sin_addr),cliaddr.sin_port); //将新的连接描述符添加到数组中 int i = 0; for (i = 0; i \u0026lt; MAXCLIENTSIZE; i++) { if (s_srv_ctx-\u0026gt;clifds[i] \u0026lt; 0) { s_srv_ctx-\u0026gt;clifds[i] = clifd; s_srv_ctx-\u0026gt;cli_cnt++; break; } } //已经达到最大连接数 打印错误日志报错返回 if (i == MAXCLIENTSIZE) { fprintf(stderr,\u0026quot;too many clients.\\n\u0026quot;); return -1; } return 0; } /*=========================================================================== handle_client_msg 传入客户端套接字和缓存 处理客户端请求消息 实现回射 * ==========================================================================*/ static int handle_client_msg(int fd, char *buf) { assert(buf); printf(\u0026quot;recv buf is :%s\\n\u0026quot;, buf);//打印客户端消息 if ( write(fd, buf, strlen(buf) +1) \u0026lt;0){ perror(\u0026quot;write to client error\u0026quot;); return -1; }//并原样返回给客户端 return 0; } /*=========================================================================== recv_client_msg 传入fdset指针 处理可读的客户端套接字 * ==========================================================================*/ static void recv_client_msg(fd_set *readfds) { int i = 0, n = 0; int clifd; char buf[MAXLINE] = {0}; for (i = 0;i \u0026lt;= s_srv_ctx-\u0026gt;cli_cnt;i++) { clifd = s_srv_ctx-\u0026gt;clifds[i]; if (clifd \u0026lt; 0) { continue; } /*判断客户端套接字是否有数据*/ if (FD_ISSET(clifd, readfds)) { //接收客户端发送的信息 n = read(clifd, buf, MAXLINE); if (n \u0026lt;= 0) { /*n==0表示读取完成，客户都关闭套接字*/ FD_CLR(clifd, \u0026amp;s_srv_ctx-\u0026gt;allfds); close(clifd); s_srv_ctx-\u0026gt;clifds[i] = -1; continue; } //回传给客户端 handle_client_msg(clifd, buf); } } } /*=========================================================================== handle_client_proc 主处理函数 传入监听套接字 接受客户端连接 逐个处理客户端请求 * ==========================================================================*/ static void handle_client_proc(int srvfd) { int clifd = -1; int retval = 0; fd_set *readfds = \u0026amp;s_srv_ctx-\u0026gt;allfds; struct timeval tv; int i = 0; while (1) { /*每次调用select前都要重新设置文件描述符和时间，因为事件发生后，文件描述符和时间都被内核修改啦 这个也是使用select的缺点*/ FD_ZERO(readfds); /*添加监听套接字*/ FD_SET(srvfd, readfds); s_srv_ctx-\u0026gt;maxfd = srvfd; tv.tv_sec = 30;//超时时间30秒 tv.tv_usec = 0; /*添加客户端套接字*/ for (i = 0; i \u0026lt; s_srv_ctx-\u0026gt;cli_cnt; i++) { clifd = s_srv_ctx-\u0026gt;clifds[i]; /*去除无效的客户端句柄 比如客户端已经close*/ if (clifd != -1) { FD_SET(clifd, readfds); } //计算最大fd s_srv_ctx-\u0026gt;maxfd = (clifd \u0026gt; s_srv_ctx-\u0026gt;maxfd ? clifd : s_srv_ctx-\u0026gt;maxfd); } /*开始轮询接收处理服务端和客户端套接字*/ retval = select(s_srv_ctx-\u0026gt;maxfd + 1, readfds, NULL, NULL, \u0026amp;tv); if (retval == -1) { fprintf(stderr, \u0026quot;select error:%s.\\n\u0026quot;, strerror(errno)); return; } if (retval == 0) { fprintf(stdout, \u0026quot;select is timeout.\\n\u0026quot;); continue; } if (FD_ISSET(srvfd, readfds)) { /*监听客户端请求*/ accept_client_proc(srvfd); } else { /*接受处理客户端消息*/ recv_client_msg(readfds); } } } /*=========================================================================== server_uninit 程序退出前相关工作处理 * ==========================================================================*/ static void server_uninit() { if (s_srv_ctx) { free(s_srv_ctx); s_srv_ctx = NULL; } } /*=========================================================================== server_init 服务器初始化主要是初始化套接字管理结构体 * ==========================================================================*/ static int server_init() { //申请内存 s_srv_ctx = (server_context_st *)malloc(sizeof(server_context_st)); if (s_srv_ctx == NULL) { return -1; } //memset初始化 memset(s_srv_ctx, 0, sizeof(server_context_st)); //初始化客户端套接字具柄为-1 int i = 0;//最大处理客户端为MAXCLIENTSIZE for (;i \u0026lt; MAXCLIENTSIZE; i++) { s_srv_ctx-\u0026gt;clifds[i] = -1; } return 0; } //main函数 int main(int argc,char *argv[]) { int srvfd; /*初始化服务端context*/ if (server_init() \u0026lt; 0) { return -1; } /*创建服务,开始监听客户端请求*/ srvfd = createSocketAndListen(IPADDR, PORT); if (srvfd \u0026lt; 0) { fprintf(stderr, \u0026quot;socket create or bind fail.\\n\u0026quot;); goto err; } /*开始接收并处理客户端请求 进入主函数处理*/ handle_client_proc(srvfd); //准备退出 退出前工作处理 server_uninit(); return 0; err: server_uninit(); return -1; }  \nIO多路复用\u0026mdash;poll API原型 # include \u0026lt;poll.h\u0026gt; int poll ( struct pollfd * fds, unsigned int nfds, int timeout); struct pollfd { int fd; /* 要监控的文件描述符 如果为负值 内核会直接忽略 可以通过修改为-1 让内核不再监控*/ short events; /* 期待等待的事件 */ short revents; /* 实际发生了的事件 */ } ;   poll跟select整体机制是一样的 也是传入需要监控的fd集合 然后轮询 只是数据结构不是用int数组，而是改为pollfd结构体数组，所以没有了大小数量限制，对于每个关心的描述符可以更灵活的设置期待时间 代码使用起来更加灵活\n 第一个参数fds为需要监控的fd信息结构体数组指针 每次poll之前都可以动态的添加或者移除(通常直接设置对应的fd为-1)\n nfds为第一个参数fds的size也就是需要监控的fd的个数\n timeout为超时时间\n If timeout is greater than zero, it specifies a maximum interval (in milliseconds) to wait for any file descriptor to  become ready. \u0026gt;0 单位毫秒 内核最多等待timeout毫秒\n If timeout is zero, then poll() will return without blocking. =0 如果没有描述符就位，直接返回不阻塞，如果有就位的就会立马返回 If the value of timeout is -1, the poll blocks indefinitely 如果是-1，则一直阻塞，直到至少一个描述符期待的事件发生  pollfd对应的events和revents取值解释\n  | | | events | revents | | \u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; | | 事件 | 描述 | 可作为输入 | 可作为输出 | | POLLIN | 数据可读（包括普通数据\u0026amp;优先数据） | 是 | 是 | | POLLOUT | 数据可写（普通数据\u0026amp;优先数据） | 是 | 是 | | POLLRDNORM | 普通数据可读 | 是 | 是 | | POLLRDBAND | 优先级带数据可读（linux不支持） | 是 | 是 | | POLLPRI | 高优先级数据可读，比如TCP带外数据 | 是 | 是 | | POLLWRNORM | 普通数据可写 | 是 | 是 | | POLLWRBAND | 优先级带数据可写 | 是 | 是 | | POLLRDHUP | TCP连接被对端关闭，或者关闭了写操作，由GNU引入 | 是 | 是 | | POPPHUP | 挂起 | 否 | 是 | | POLLERR | 错误 | 否 | 是 | | POLLNVAL | 文件描述符没有打开 | 否 | 是 |\n 可能的返回码  正常返回fds数组中revents不为0的文件描述符的个数 如果超时之前没有任何事件发生 则poll返回0 失败时 poll返回-1 errno设置如下： 不同os返回码可能不一致 可以man下 EBADF　一个或多个结构体中指定的文件描述符无效 EFAULT　指针指向的地址超出进程的地址空间。 EINTR　请求的事件之前产生一个信号，调用可以重新发起 EINVAL　参数超出PLIMIT_NOFILE值 ENOMEM　可用内存不足，无法完成请求   不足及改进  相比select 没有了数量的限制 此为改进 每次poll fd数组都要经过用户态拷贝到内核态 性能还是会受影响 还是轮询机制 监控的fd数量如果太多 不论文件描述符是否就绪 开销随着监控数量增加而线性增大  代码  poll示例代码_转载整理加注释、简单优化 C\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;netinet/in.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;poll.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #define IPADDRESS \u0026quot;127.0.0.1\u0026quot; #define PORT 8787 #define MAXLINE 1024 #define LISTENQ 5 #define OPEN_MAX 1000 #define INFTIM -1 //函数声明 //创建套接字并进行绑定然后启动监听 static int createSocketAndListen(const char* ip,int port); //IO多路复用poll static void do_poll(int listenfd); //处理多个连接 static void handle_connection(struct pollfd *connfds,int num); int main(int argc,char *argv[]) { int listenfd,connfd,sockfd; struct sockaddr_in cliaddr; socklen_t cliaddrlen; listenfd = createSocketAndListen(IPADDRESS,PORT); do_poll(listenfd); return 0; } /*=========================================================================== createSocketAndListen 根据传入字符串格式ip和端口port，创建socket并且开启监听 * ==========================================================================*/ static int createSocketAndListen(const char* ip,int port) { int listenfd; struct sockaddr_in servaddr; listenfd = socket(AF_INET,SOCK_STREAM,0); if (listenfd == -1) { perror(\u0026quot;socket error:\u0026quot;); exit(1); } bzero(\u0026amp;servaddr,sizeof(servaddr)); servaddr.sin_family = AF_INET; inet_pton(AF_INET,ip,\u0026amp;servaddr.sin_addr); servaddr.sin_port = htons(port); if (bind(listenfd,(struct sockaddr*)\u0026amp;servaddr,sizeof(servaddr)) == -1) { perror(\u0026quot;bind error: \u0026quot;); exit(1); } //开启监听 if ( listen(listenfd,LISTENQ) == -1){ perror(\u0026quot;listen error: \u0026quot;); exit(1); } return listenfd; } /*=========================================================================== do_poll 传入监听监听套接字 执行主流程 * ==========================================================================*/ static void do_poll(int listenfd) { int connfd,sockfd; struct sockaddr_in cliaddr; socklen_t cliaddrlen; struct pollfd clientfds[OPEN_MAX];//常见pollfd数组 int maxi;//需要监控fd数组中最大不为-1的下标位置 可以计算出来当前真正需要监控的fd数量 int i; int nready; //添加监听描述符 clientfds[0].fd = listenfd;//第一个元素设置为监听套接字 clientfds[0].events = POLLIN;//期待读事件 //初始化客户连接描述符 for (i = 1;i \u0026lt; OPEN_MAX;i++) clientfds[i].fd = -1; maxi = 0; //循环处理 for ( ; ; ) { //获取可用描述符的个数 nready = poll(clientfds,maxi+1,INFTIM); if (nready == -1) { perror(\u0026quot;poll error:\u0026quot;); exit(1); } //测试监听描述符是否准备好 if (clientfds[0].revents \u0026amp; POLLIN) { cliaddrlen = sizeof(cliaddr); //接受新的连接 if ((connfd = accept(listenfd,(struct sockaddr*)\u0026amp;cliaddr,\u0026amp;cliaddrlen)) == -1) { if (errno == EINTR) continue; else { perror(\u0026quot;accept error:\u0026quot;); exit(1); } } fprintf(stdout,\u0026quot;accept a new client: %s:%d\\n\u0026quot;, inet_ntoa(cliaddr.sin_addr),cliaddr.sin_port); //将新的连接描述符添加到数组中 找到fd数组可以插入的位置 是-1就可以插入 而且是下标从小到达开始查找 for (i = 1;i \u0026lt; OPEN_MAX;i++) { if (clientfds[i].fd \u0026lt; 0)//顺序查找哪个槽位可以使用 刚开始只有第一个不为-1 { clientfds[i].fd = connfd;//加进pollfd数组 break; } } if (i == OPEN_MAX)//这里只是为了测试 超过这个数量的客户端 程序报错退出 { fprintf(stderr,\u0026quot;too many clients.\\n\u0026quot;); exit(1); } //将新的描述符添加到读描述符集合中 clientfds[i].events = POLLIN; //记录客户连接套接字的个数 maxi = (i \u0026gt; maxi ? i : maxi); if (--nready \u0026lt;= 0)//如果除了监听套接字没有就绪的事件 那就continue继续下次poll轮询 continue; } //处理客户连接 handle_connection(clientfds,maxi); } } /*=========================================================================== handle_connection 传入poll返回的fd数组 逐个处理就绪的客户端套接字 * ==========================================================================*/ static void handle_connection(struct pollfd *connfds,int num) { int i,n; char buf[MAXLINE]; memset(buf,0,MAXLINE); for (i = 1;i \u0026lt;= num;i++) { if (connfds[i].fd \u0026lt; 0) continue; //测试客户描述符是否准备好 if (connfds[i].revents \u0026amp; POLLIN) { //接收客户端发送的信息 n = read(connfds[i].fd,buf,MAXLINE); if (n == 0) { close(connfds[i].fd); connfds[i].fd = -1;//如果客户端关闭了套接字 从监控套接字数组中移除 continue; } // printf(\u0026quot;read msg is: \u0026quot;); write(STDOUT_FILENO,buf,n); //向客户端发送buf write(connfds[i].fd,buf,n); } } }  \nIO多路复用\u0026mdash;epoll API原型 #include \u0026lt;sys/epoll.h\u0026gt; int epoll_create(int size); int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); struct epoll_event { __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; events可以是以下几个宏的集合： EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）； EPOLLOUT：表示对应的文件描述符可以写； EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）； EPOLLERR：表示对应的文件描述符发生错误； EPOLLHUP：表示对应的文件描述符被挂断； EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。 EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里   epoll_create\n 创建一个epoll文件描述符，size是要告诉内核这个监听套接字的数量，创建好epoll句柄后，就会占用一个fd值，在linux系统以下目录/proc/pid/fd是可以看到的，所以epoll结束 好习惯也要close掉  epoll_ctl\n ctl就是control控制的缩写，是一个事件注册函数，epfd为epoll_create函数返回的epoll句柄 第二个参数op为操作类型 有以下三个 EPOLL_CTL_ADD：注册新的fd到epfd中 EPOLL_CTL_MOD：修改已经注册的fd的监听事件 EPOLL_CTL_DEL：从epfd中删除一个fd 第三个参数fd为需要监听的套接字句柄 第四个参数是告诉内核针对fd要监听什么事件 events枚举上面有列出来  epoll_wait\n 类似select、poll调用名字也有wait，就是等待事件产生 第一个参数epfd为epoll_create返回的epoll句柄 第二个参数events用来从内核得到事件集合，内核会将就绪的描述符及发生的事件写到这个列表中 第三个参数是告知内核 这个列表有多大，不能大于调用epoll_create(int size)传入的size 第四个参数超时时间 单位毫秒 ： timeout\u0026gt;0 如果没有套接字就绪 内核最多等到timeout毫秒 timeout=0 如果没有套接字就绪 内核直接返回 不阻塞 timeout=-1 会一直阻塞 直到有套接字就绪  epoll两者工作模式\n LT(level trigger) 水平触发模式  epoll_wait检测到fd事件发生并将此事件通知应用程序，如果应用程序不立即处理，下次调用epoll_wait会再次告知应用程序\n ET(edge trigger) 边缘触发模式  当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件\n ET模式很大程度减少了epoll事件被重复触发的次数，相对于LT效率更高，在ET模式下，必须使用非阻塞套接字，以避免由于一个套接字阻塞读写导致整个处理多套接字的任务搞死。\n   改进、不足  相对于select没有数量限制 相对于select、poll 对于监控的描述符集合 不用每次都从用户态拷贝到内核态，只是在epoll_ctl添加的时候拷贝一次 epoll_wait不是轮询机制 而是采用回调函数的机制 所以效率更高 epoll目前只有linux有 是从linux内核2.6开始提出的 不过windows和Mac(bsd)也有类似的实现  代码  epoll示例代码 转载加注释 简单优化 C\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;netinet/in.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;sys/epoll.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #define IPADDRESS \u0026quot;127.0.0.1\u0026quot; #define PORT 8787 #define MAXSIZE 1024 #define LISTENQ 5 #define FDSIZE 1000 #define EPOLLEVENTS 100 //函数声明 //创建套接字并进行绑定 static int socket_bind(const char* ip,int port); //IO多路复用epoll static void do_epoll(int listenfd); //事件处理函数 static void handle_events(int epollfd,struct epoll_event *events,int num,int listenfd); //处理接收到的连接 static void handle_accpet(int epollfd,int listenfd); //读处理 static void handle_connection(int epollfd,int fd); //写处理 static void sendToClient(int epollfd,int fd,char *buf); //添加事件 static void add_event(int epollfd,int fd,int state); //修改事件 static void modify_event(int epollfd,int fd,int state); //删除事件 static void delete_event(int epollfd,int fd,int state); int main(int argc,char *argv[]) { int listenfd; listenfd = socket_bind(IPADDRESS,PORT); listen(listenfd,LISTENQ); do_epoll(listenfd); return 0; } /*=========================================================================== socket_bind 创建监听套接字 * ==========================================================================*/ static int socket_bind(const char* ip,int port) { int listenfd; struct sockaddr_in servaddr; listenfd = socket(AF_INET,SOCK_STREAM,0); if (listenfd == -1) { perror(\u0026quot;socket error:\u0026quot;); exit(1); } /*一个端口释放后会等待一段时间后(比如两分钟)才能再被使用，SO_REUSEADDR是让端口释放后立即就可以被再次使用。*/ int reuse = 1; if (setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, \u0026amp;reuse, sizeof(reuse)) == -1) { return -1; } bzero(\u0026amp;servaddr,sizeof(servaddr)); servaddr.sin_family = AF_INET; inet_pton(AF_INET,ip,\u0026amp;servaddr.sin_addr); servaddr.sin_port = htons(port); if (bind(listenfd,(struct sockaddr*)\u0026amp;servaddr,sizeof(servaddr)) == -1) { perror(\u0026quot;bind error: \u0026quot;); exit(1); } return listenfd; } /*=========================================================================== epoll处理主函数 需要传入监听套接字 * ==========================================================================*/ static void do_epoll(int listenfd) { int epollfd; struct epoll_event events[EPOLLEVENTS]; int ret; //创建一个描述符 epollfd = epoll_create(FDSIZE); //添加监听描述符事件 add_event(epollfd,listenfd,EPOLLIN); for ( ; ; ) { //获取已经准备好的描述符事件 ret = epoll_wait(epollfd,events,EPOLLEVENTS,-1); handle_events(epollfd,events,ret,listenfd); } close(epollfd); } /*=========================================================================== handle_events epoll_wait 返回后针对就绪套接字 逐个处理 * ==========================================================================*/ static void handle_events(int epollfd,struct epoll_event *events,int num,int listenfd) { int i; int fd; //对内核返回就绪的events列表 遍历处理 for (i = 0;i \u0026lt; num;i++) { fd = events[i].data.fd; //根据描述符的类型和事件类型进行处理 if ((fd == listenfd) \u0026amp;\u0026amp;(events[i].events \u0026amp; EPOLLIN))//监听套接字 需要accept同时将连接好的clientfd加入epollfd handle_accpet(epollfd,listenfd); else if (events[i].events \u0026amp; EPOLLIN)//读事件 handle_connection(epollfd,fd); else{ perror(\u0026quot;非accept可读、非clinet可读\u0026quot;); } } } /*=========================================================================== handle_accpet 监听套接字 需要accept同时将连接好的clientfd加入epollfd * ==========================================================================*/ static void handle_accpet(int epollfd,int listenfd) { int clifd; struct sockaddr_in cliaddr; socklen_t cliaddrlen; clifd = accept(listenfd,(struct sockaddr*)\u0026amp;cliaddr,\u0026amp;cliaddrlen); if (clifd == -1) perror(\u0026quot;accpet error:\u0026quot;); else { printf(\u0026quot;accept a new client: %s:%d\\n\u0026quot;,inet_ntoa(cliaddr.sin_addr),cliaddr.sin_port); //添加一个客户描述符和事件 add_event(epollfd,clifd,EPOLLIN); } } /*=========================================================================== do_read 处理读事件就绪的客户端连接套接字 * ==========================================================================*/ static void handle_connection(int epollfd,int fd) { char buf[MAXSIZE]; memset(buf,0,MAXSIZE); int nread; nread = read(fd,buf,MAXSIZE); if (nread == -1) { perror(\u0026quot;read error:\u0026quot;); close(fd); delete_event(epollfd,fd,EPOLLIN); } else if (nread == 0) { fprintf(stderr,\u0026quot;client close.\\n\u0026quot;); close(fd); delete_event(epollfd,fd,EPOLLIN); } else { printf(\u0026quot;read message is : %s\\n\u0026quot;,buf); //直接回复给客户端 sendToClient(epollfd,fd,buf); } } static void sendToClient(int epollfd,int fd,char *buf) { int nwrite; nwrite = write(fd,buf,strlen(buf)); if (nwrite == -1) { perror(\u0026quot;write error:\u0026quot;); close(fd); delete_event(epollfd,fd,EPOLLIN); } } static void add_event(int epollfd,int fd,int state) { struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_ADD,fd,\u0026amp;ev); } static void delete_event(int epollfd,int fd,int state) { struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_DEL,fd,\u0026amp;ev); } static void modify_event(int epollfd,int fd,int state) { struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_MOD,fd,\u0026amp;ev); }  \n多线程 为什么需要多进程多线程  本质原因cpu、内存IO、磁盘IO因为介质不同，工作效率天壤之别，cpu速度远远大于内存，内存速度又远远大于磁盘。所以这么一来最开始的计算使用者就发现，cpu太闲了，而cpu贵，实在是太浪费了，所以后面就想尽办法办法，让cpu忙起来 下面的是简单的发展历史\n 单任务时代  计算机只负责计算，不能直接写入指令和输出结果，程序员把程序写到纸上，然后穿孔称卡片，再把卡片输入到计算机，计算机计算结果打印出来，程序员最后拿到结果。这个时代的计算机cpu是很闲的，程序员干半天，计算机一会完事。\n 批处理  程序由卡片改为了磁带，这时候一次可以录入更多的程序，一次批处理的方式执行多个任务，但计算机同时还是只能干一件事情，进行IO的时候不能计算，进行计算的时候不能IO，而cpu干活又贼快，所以cpu整体还是很闲。\n 支持多道程序设计 多进程时代  出现了多进程，每个进程拥有自己独立的内存空间，不同进程之间互不干涉，因为cpu太快而且又贵，所以大家就轮着用，也就是cpu时间片的概念，不同的进程使用cpu由操作系统统一管理，争取公平的分配给每个进程所需要的cpu时间片，一个进程用一会cpu，操作系统就保存现场，同时把cpu转给其它进程(也就是进程切换)，这个时代进程如果够多，cpu其实已经很忙了，因为一堆进程轮番上阵，无休止的车轮战。\n 多线程时代  因为进程切换比较消耗时间，现场保存和切换工作因为进程比较重所以比较消耗时间和资源，所以就来了多线程，线程更加轻量级，一个进程的多个线程间共享进程的内存空间，所以切换起来更快，当然cpu也就会更累。\n因为多线程的出现，cpu变得更加繁忙。\n 多cpu 多线程  进入了多线程时代后，终于彻底可以把cpu搞死了，所以人们开始嫌弃cpu没有那么快了，所以就想着搞多个cpu，让多个cpu同时工作，这个时候其实才是真正的任务并行了，之前是多个任务不断的抢一个cpu，因为cpu太快了，所以基本没什么感觉，进入多核cpu后才真正的让多个任务并行了。\n  多cpu并发可能产生的问题 多个cpu缓存导致的可见性问题  还是因为cpu太快，内存磁盘太慢所以有了cpu缓存，所以cpu执行数据操作过层导致如下：\n 从磁盘加载数据到内存 从内存加载到cpu缓存 执行相关计算操作 更新cpu缓存 更新内存 更新磁盘  多核cpu，就有多个cpu缓存，而它们彼此不可见，每个cpu也是操作的自己独立的cpu缓存，这就必然产生不可见性，比如a=a+1\n  cpu1修改了对应的cpu缓存，而此时cpu2是不知道的，必须等缓存同步以后才知道。\n 所以线程见如果操作共享资源要注意加锁，否则可能出现意想不到的结果 例子：2个线程 同时++一个变量10W次  cpu切换线程导致的原子性问题  原子性就是一个操作(多个相关子操作)在执行的过程中不能被打断，要么都执行，要么都不执行。\n 例子 int number=0;number=number+1;\n  number=number+1的指令可能如下：\n指令1：CPU把number从内存拷贝到CPU缓存。\n指令2：把number进行+1的操作。\n指令3：把number回写到内存.\n 如果有2个线程都在执行上面的例子，cpu的执行流程可能如下：  执行细节：\n​ 1、CPU先执行线程A的执行，把number=0拷贝到CUP寄存器。\n​ 2、然后CPU切换到线程B执行指令。\n​ 3、线程B 把number=0拷贝到CUP寄存器。\n​ 4、线程B 执行number=number+1 操作得到number=1。\n​ 5、线程B把number执行结果回写到缓存里面。\n​ 6、然后CPU切换到线程A执行指令。\n​ 7、线程A执行number=number+1 操作得到numbe=1。\n​ 8、线程A把number执行结果回写到缓存里面。\n​ 9、最后内存里面number的值为1。\n编译器优化带来的指令重排序问题  编译器的有些优化会打乱执行本来人为理解的顺序\n 例子： 单例模式的double check，其实用了很长一段时间，直到内存reorder问题发现。\npublic class Singleton { private Singleton() {} private static Singleton sInstance; public static Singleton getInstance() { if (sInstance == null) {\t//第一次验证是否为null synchronized (Singleton.class) { //加锁 if (sInstance == null) {\t//第二次验证是否为null sInstance = new Singleton(); //创建对象 } } } return sInstance; } }   Instance = new Singleton();这行代码时会分解成三个指令执行。\n1、为对象分配一个内存空间。\n2、在分配的内存空间实例化对象。\n3、把Instance 引用地址指向内存空间\n而且2 3的顺序可能发生变化，如果先执行3，然后另外一个线程抢到cpu 发现对象指针不为空，直接返回然后使用，而这个时候对象还没有完成初始化工作，是会出问题的。\nc++11 多线程 创建线程 c++11 创建一个线程相对比较简单 大致步骤如下： 1. #include\u0026lt;thread\u0026gt; 2. 定义线程代码执行路径(线程就是可以单独执行代码的通道，要定义线程启动后要从哪个地方开始从上往下执行代码) 3. 在main主线程 创建一个thread对象(这个时候线程就自动生成并且运行了) 4. 主线程做一些线程管理工作(比如调用join函数阻塞等待某个线程，也可以调用detach函数 跟某个线程脱离关系，让init进程接管然后去后台运行）  线程代码执行入口的常见方式  普通的函数\n//普通函数作为线程执行入口 void ordinaryFunc(){ cout\u0026lt;\u0026lt;\u0026quot;线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is running\u0026quot;\u0026lt;\u0026lt;endl; sleep(1);//休眠一秒钟 cout\u0026lt;\u0026lt;\u0026quot;线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is ready to exit \u0026quot;\u0026lt;\u0026lt;endl; } int main(){ cout\u0026lt;\u0026lt;\u0026quot; 主线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is running\u0026quot;\u0026lt;\u0026lt;endl; thread t1(ordinaryFunc); t1.join();//main函数阻塞 等待子线程退出 cout\u0026lt;\u0026lt;\u0026quot; 主线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is ready to return\u0026quot;\u0026lt;\u0026lt;endl; } -----输出 主线程id:0x11a916dc0 is running 线程id:0x700001438000 is running 线程id:0x700001438000 is ready to exit 主线程id:0x11a916dc0 is ready to exit  函数对象(重载了()运算符的对象)\n//函数对象作为线程执行入口 class FuncObj{ public: void operator()(){ cout\u0026lt;\u0026lt;\u0026quot;线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is running\u0026quot;\u0026lt;\u0026lt;endl; sleep(1);//休眠一秒钟 cout\u0026lt;\u0026lt;\u0026quot;线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is ready to exit \u0026quot;\u0026lt;\u0026lt;endl; } }; int main(){ cout\u0026lt;\u0026lt;\u0026quot; 主线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is running\u0026quot;\u0026lt;\u0026lt;endl; thread t1( ( FuncObj() )); t1.join(); cout\u0026lt;\u0026lt;\u0026quot; 主线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is ready to exit\u0026quot;\u0026lt;\u0026lt;endl; }  类成员函数\n//类成员函数作为线程执行入口 class ObjTest{ public: void run(){ cout\u0026lt;\u0026lt;\u0026quot;线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is running\u0026quot;\u0026lt;\u0026lt;endl; sleep(1);//休眠一秒钟 cout\u0026lt;\u0026lt;\u0026quot;线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is ready to exit \u0026quot;\u0026lt;\u0026lt;endl; } }; int main(){ cout\u0026lt;\u0026lt;\u0026quot; 主线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is running\u0026quot;\u0026lt;\u0026lt;endl; ObjTest runtest; thread t1(\u0026amp;ObjTest::run,\u0026amp;runtest);//类成员函数作为线程执行入口要多传入一个对象的this指针 t1.join(); cout\u0026lt;\u0026lt;\u0026quot; 主线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is ready to exit\u0026quot;\u0026lt;\u0026lt;endl; }  lambda表达式\nint main(){ cout\u0026lt;\u0026lt;\u0026quot; 主线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is running\u0026quot;\u0026lt;\u0026lt;endl; auto lambdaThread=[]{ cout\u0026lt;\u0026lt;\u0026quot;线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is running\u0026quot;\u0026lt;\u0026lt;endl; sleep(1);//休眠一秒钟 cout\u0026lt;\u0026lt;\u0026quot;线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is ready to exit \u0026quot;\u0026lt;\u0026lt;endl; }; thread t1(lambdaThread); t1.join(); cout\u0026lt;\u0026lt;\u0026quot; 主线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is ready to exit\u0026quot;\u0026lt;\u0026lt;endl; }   线程执行入口传递参数  创建线程会复制新的堆栈 参数统一都会复制，如果要传递引用 可以使用std::ref()，否则即使函数参数写的是引用，最后也不是真的引用。 线程之间如果使用的是同一个变量，要注意作用域问题，特别是detach后，很可能一个线程已经挂了，另外一个线程还在使用某个挂了的线程中的变量，就会差生奇怪的后果。  线程管理函数  join  主线程 执行了t1.join()后，主线程就会阻塞的等待子线程结束\n detach  主线程执行了t1.detach()后，t1线程就跑到后台执行了 跟当前主线程就没有关系了，但如果主线程退出，那么进程也会退出，所有的线程也都会退出，并不是说detach后线程就真的常驻了，只是跟主线程脱离控制关系了。\n锁(资源竞争)  互斥量\n#include\u0026lt;mutex\u0026gt; std::mutex s1; s1.lock(); //加锁 doSomething();//处理 s1.unlock();//解锁 最简单的可以通过互斥量来解决问题。只有锁成功的线程 才能对共享资源做处理 否则就要等待 //如果不想显示的unlock的 或者担心忘记写unlock也可以用std::lock_guard代为管理 { std::mutex s1; std::lock_guard\u0026lt;std::mutex\u0026gt; lg(s1); //加锁 会在构造函数内部 调用s1的lock函数 //doSomething();//处理 }//退出这个大括号 lg对象会析构，析构的时候会调用s1的unlock函数  死锁问题\n//死锁测试 class DeadLock{ public: void func1(){ for (int i=0;i\u0026lt;10000;++i){ m1.lock();// m2.lock(); cout\u0026lt;\u0026lt;\u0026quot;this is func1\u0026quot;\u0026lt;\u0026lt;endl; m2.unlock(); m1.unlock(); } } void func2(){ for (int i=0;i\u0026lt;10000;++i){ m2.lock(); m1.lock(); cout\u0026lt;\u0026lt;\u0026quot;this is func2\u0026quot;\u0026lt;\u0026lt;endl; m1.unlock(); m2.unlock(); } } private: std::mutex m1,m2; }; int main(){ cout\u0026lt;\u0026lt;\u0026quot; 主线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is running\u0026quot;\u0026lt;\u0026lt;endl; DeadLock deadLockTest; thread t1(\u0026amp;DeadLock::func1,\u0026amp;deadLockTest); thread t2(\u0026amp;DeadLock::func2,\u0026amp;deadLockTest); t1.join(); t2.join(); cout\u0026lt;\u0026lt;\u0026quot; 主线程id:\u0026quot;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026quot; is ready to exit\u0026quot;\u0026lt;\u0026lt;endl; } //----------大致死锁过程---------- //t1线程 执行func1函数 先锁了m1 准备去锁m2 //然后cpu切换到t2线程 //t2线程 先锁了m2 准备去锁m1 发现m1被锁了 等待 //cpu切换到t1线程 去锁m2 发现m2被锁了，等待 //2个线程一直等待下去 //不同线程之间加锁解锁顺序应该一致 避免死锁  std::lock() 一次锁多个互斥量 要么全部成功 要么全部失败 有原子性\nstd::mutex m1,m2; std::lock(m1,m2);//这里m1 m2要么同时锁成功 要么都不加锁 doSomething();// m1.lock(); m2.lock();  std::lock_guardstd::mutex l1(m1,std::adopt_lock)\n  加上adopt_lock标记，必须m1在之前已经被锁了 就不再锁了，但析构l1的时候还是会尝试unlock m1\n std::unique_lock\u0026lt;\u0026gt;模版类\n std::unique_lock\u0026lt;std::mutex\u0026gt; ul1(m2,std::try_to_lock);//尝试去拿锁 不会阻塞 if( ul1.owns_lock){ //加锁处理 }else{ //做其它事情 }  std::unique_lock\u0026lt;std::mutex\u0026gt; ul1(m2,std::defer_lock);//没有加锁 ul1.lock(); //共享资源处理 ul1.unlock();//暂时解锁 //处理非共享资源 ul1.lock(); //处理共享资源 //ul1析构的时候 还是会unlock unique_lock相对更加灵活 但性能上也会有所损失  std::unique_lock\u0026lt;std::mutex\u0026gt; ul1(m2,std::defer_lock);//没有加锁 只是跟m2这个互斥量关联 if (ul1.try_lock()==true){//不会阻塞 //处理共享资源或者共享代码段 }else{ //没有加锁成功 做些别的事情 } std::unique_lock\u0026lt;std::mutex\u0026gt; ul2(std::move(ul1)); //转移所有权 相当于un1.release ul2根m2互斥量绑定 //ul1.release()//会放弃跟关联的互斥量之间的关系 那么就需要自己unlock了  加锁的粒度要控制得当，因为加锁会影响效率，锁的东西必须是涉及资源竞争的东西，不要在lock()和unlock()之间加太多不涉及共享的代码，会影响效率\n std::recursive_mutex 递归的独占互斥量 可以lock多次 效率低\n std::timed_mutex 抢锁 只不过有超时时间\n```\n   std::timed_mutex timedMutex; std::chrono::milliseconds timeout(100); if( timedMutex.try_lock_for(timeout)){//等待100毫秒 如果抢到了锁就执行 //共享资源处理 timedMutex.unlock(); }else{ std::this_thread::sleep_for(timeout);//抢不到就超时 然后做些别的事情 } timedMutex.try_lock_until(futureTime);/到未来的时间如果还没抢到锁 则超时 否则继续处理\n ### 条件变量 ​ 是c++11的一个新的类，如果线程之间需要按照预定的先后顺序来执行，就可以使用条件变量这个类了。 假设一个线程生产数据，一个线程消费数据，如果没有数据，**消费线程一直加锁解锁 非常消耗cpu资源**，所以希望加锁后发现没有数据就等着，然后希望生产线程生产了数据就唤醒消费线程起来干活。比较常见的代码如下： - 消费线程  std::mutex myMutex; std::condition_variable cv; vector myVec; ///\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;以下为消费线程代码逻辑 while(true){ std::unique_lockstd::mutex uniquelock1(myMutex); cv.wait(uniquelock1,[](){ return myVec.size()\u0026gt;0;} ); //加锁后如果没有数据 wait就释放锁 同时消费线程则阻塞在这里等待 //如果生产线程 唤醒了它，wait这里还要加锁 同时判断队列是否有数据，有数据并且加锁成功了 就会执行下面的消费逻辑 //\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;消费数据\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; }\n - 生产线程  std::mutex myMutex; std::condition_variable cv; vector myVec; ///\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;以下为生产线程代码逻辑 while(true){ std::unique_lockstd::mutex uniquelock1(myMutex); //\u0026mdash;\u0026mdash;\u0026ndash;生产数据\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; myVec.push_back(\u0026ldquo;xxx\u0026rdquo;); //\u0026mdash;\u0026mdash;-生产完毕 先解锁 uniquelock1.unlock(); //\u0026mdash;\u0026ndash;然后唤醒消费线程干活 cv.notify_all();//cv.notify_one();//唤醒因为cv条件不满足等待的所有线程或者某一个线程\n}\n ### Std::async与std::future - std::async创建一个后台线程执行传递的任务，这个任务只要是callable object均可，然后返回一个std::future。future储存一个多线程共享的状态,当调用future.get时会阻塞直到绑定的task执行完毕 - 创建async的时候指定一个launch policy - std::launch::async当返回的future失效前会强制执行task，即不调用future.get也会保证task的执行 创建新线程 - std::launch::deferred仅当调用future.get时才会执行task 不创建新线程 只是延迟执行 - 不指定策略，系统随机。 - Wait_for可以指定时间 然后获取状态(ready 成功执行完毕、timeout超时、deferred延期的尚未执行的) - 只能get一次 如果想get多次 可以**std::shared_future** resultShare(result.share());// - 这种方式可以很方便的获取线程的计算结果。  bool printThead(){ cout\u0026lt;\u0026lt;\u0026ldquo;线程id:\u0026rdquo;\u0026lt;result=std::async(printThead); //std::future result=std::async(std::launch::deferred,printThead);//如果换成这行 主线程不等子线程 直接退出，子线程根本没有被执行 必须调用future的wait或者get才会被执行 cout\u0026lt;\u0026lt;\u0026rdquo; 主线程id:\u0026rdquo;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026rdquo; is ready to exit\u0026rdquo;\u0026lt;\u0026lt;endl;//执行到这里主线程不会退出 printThead线程会被强制执行完成 默认策略是std::launch::async } \u0026mdash;\u0026ndash;输出\u0026mdash;\u0026ndash; 主线程id:0x113812dc0 is running 主线程id:0x113812dc0 is ready to exit 线程id:0x700006f48000 is running \u0026hellip;sleeping 线程id:0x700006f48000 is ready to exit\n////main函数可以改为如下的： int main(){ cout\u0026lt;\u0026lt;\u0026rdquo; 主线程id:\u0026rdquo;\u0026lt;result=std::async(std::launch::deferred,printThead); cout\u0026lt;\u0026lt;\u0026ldquo;调用future的get方法 开始启动printThread线程执行 同时主线程阻塞等待\u0026rdquo;\u0026lt;\u0026lt;endl; cout\u0026lt;\u0026lt;\u0026ldquo;printThread线程执行结果为:\u0026rdquo;\u0026lt;\u0026lt;result.get()\u0026lt;\u0026lt;endl;//调用get方法 或者wait方法 主线程会阻塞等待 可以控制主线程执行时机 cout\u0026lt;\u0026lt;\u0026rdquo; 主线程id:\u0026rdquo;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026rdquo; is ready to exit\u0026rdquo;\u0026lt;\u0026lt;endl; }\n ### std::packaged_task  bool printThead(){ cout\u0026lt;\u0026lt;\u0026ldquo;线程id:\u0026rdquo;\u0026lt;myThreadPackage(printThead);//打包一个线程执行入口函数 thread t1(std::ref(myThreadPackage));//用打包好的入口函数 启动一个线程 t1.join(); // t1.detach();//detach也没有 调用了get就会阻塞等待的 std::future result=myThreadPackage.get_future();//得到返回结果 cout\u0026lt;\u0026lt;\u0026ldquo;printThread线程执行结果为:\u0026rdquo;\u0026lt;\u0026lt;result.get()\u0026lt;\u0026lt;endl; cout\u0026lt;\u0026lt;\u0026rdquo; 主线程id:\u0026rdquo;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026rdquo; is ready to exit\u0026rdquo;\u0026lt;\u0026lt;endl; }\n 也可以包装任何可执行对象 下面是lambda表达式  std::packaged_task myThreadPackage( [](){ \u0026hellip;\u0026hellip;. return true; } );\n std::packaged_task也可以直接调用 相当于函数调用 而不是启动线程 ### Std::promise 类模版 保存线程计算结果  void promiseTest(std::promise \u0026amp;result,int num){ cout\u0026lt;\u0026lt;\u0026ldquo;线程promiseTest id:\u0026rdquo;\u0026lt;myResult; thread t1(promiseTest,std::ref(myResult),999); t1.join(); std::future result=myResult.get_future(); cout\u0026lt;\u0026lt;\u0026ldquo;线程运算结果为:\u0026rdquo;\u0026lt;\u0026lt;result.get()\u0026lt;\u0026lt;endl; cout\u0026lt;\u0026lt;\u0026rdquo; 主线程id:\u0026rdquo;\u0026lt;\u0026lt;std::this_thread::get_id()\u0026lt;\u0026lt;\u0026rdquo; is ready to exit\u0026rdquo;\u0026lt;\u0026lt;endl; } \u0026mdash;\u0026ndash;输出结果\u0026mdash;\u0026mdash;- 主线程id:0x107f2bdc0 is running 线程promiseTest id:0x70000a5e8000 is running 线程promiseTest id:0x70000a5e8000 is ready to exit 线程运算结果为:1004 主线程id:0x107f2bdc0 is ready to exit\n ### 原子操作std::atomic  int count=0; void myTest(){ for (int i=0;icount=0;就不会出现问题了 但不是所有的操作都支持原子操作，比如count++没问题 但是 count=count+1就不支持了，使用时候要查看api说明 原子操作的赋值需要使用API特定的方法\n ### Std::thread和std::async区别 - thread创建线程 如果资源紧张，可能创建失败，可能系统崩溃 - Std::async 可能还是在主线程进行的，更方便的 ### thread_local ​ thread_local定义的变量会在每个线程保存一份副本，而且互不干扰，在线程退出的时候自动摧毁  #include  #include  #include  thread_local int g_k = 0; void func1(){ while (true){ ++g_k; } }\nvoid func2(){ while (true){ std::cout \u0026lt;\u0026lt; \u0026ldquo;func2 thread ID is : \u0026ldquo; \u0026lt;\u0026lt; std::this_thread::get_id() \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026ldquo;func2 g_k = \u0026ldquo; \u0026lt;\u0026lt; g_k \u0026lt;\u0026lt; std::endl; std::this_thread::sleep_for(std::chrono::milliseconds(1000)); } } int main(){ std::thread t1(func1); std::thread t2(func2); t1.join(); t2.join(); return 0; } \u0026mdash;-在func1()对g_k循环加1操作，在func2()每个1000毫秒输出一次g_k的值\u0026mdash;\u0026ndash; func2 thread ID is : 15312 func2 g_k = 0 func2 thread ID is : 15312 func2 g_k = 0 func2 thread ID is : 15312 \u0026hellip;..可以看出func2()中的g_k始终保持不变\n # 经典IO模型实现 ## PPC、TPC - Process Per Connection、Process Per Connection ### 整体思路总结及网搜图解 #### 连接来时创建线程 1. 主进程/主线程负责创建监听socket、启动监听 2. 对每一个新的client 创建对应的处理进程/线程(完成read---\u0026gt;business process---\u0026gt;send) ![](http://heketong.github.io/donate/ppc_tpc_notPreModel.jpeg) - 多进程需要close掉connfd，多线程不需要 #### 预先创建号处理进程或者线程 1. 提前创建好多个处理进程/线程 2. 连接进来分配到预先创建好的处理进程/线程 ![](http://heketong.github.io/donate/ppc_tpc_prework.jpeg) - 注意accept惊群(TCP_IP文章有讲解)，解决方案(自己加accept_mutex锁、新一点的内核直接设置SO_REUSEPORT选项也是可以的内核会随机分配、....) ### 总结 - 优点：开发简单 - 缺点: 能给管理的连接数太少了，因为1个进程/线程 管理一个client套接字，而单机硬件条件限制(cpu、内存)，所以同时管理的任务进程和线程是有限了(进程上下文切换太重，线程上千级别往往调度也是非常消耗时间了)，所以想要高并发，ppc和tpc往往直接可以pass了。 ## Reactor思想 - 每个进程/线程通过IO多路复用技术，实现一个进程管理多个连接(共用一个阻塞对象 比如epollfd),应用只阻塞在epollfd上。当连接有数据可以处理的时候，通过系统调用让内核通知应用，然后进程/线程就从阻塞状态返回，进行业务处理。 - reactor处理思想大多也会有一个分发的思想存在(Dispatch),或则叫做拆分，也就将listen、accept、(send read)、business process分开，连接有数据可以处理，就分发给对应的handler处理，当然handler可以再拆出worker线程池等等。 - 往设计模式的Observe模式上理解，觉得也可以，当消息来了，就通知对应的进程/线程来处理(当然处理可以再次拆分) - 讨论一些具体reactor模式实现的时候 里面的reactor一般是指负责监听和分发任务的角色 ## 单Reactor+单线程处理(整体就一个线程)---redis - redis就是一个典型的代表 下面是redis这个io模型的简单理解 ### 整体思路： 1. 线程创建socket启动监听 注册epoll 2. epoll_wait等待客户端连接或者请求数据，拿到所有可以处理的fd，然后顺序遍历处理即可 - 如果是accept事件 就也注册到epoll - 如果是connfd的请求 就读取请求---\u0026gt;处理---\u0026gt;回包 ![](http://heketong.github.io/donate/redis_IO简单理解.jpeg) ### 总结 - 优点： - 模型简单，因为就一个线程 不用考虑并发 易开发，前面IO复用里面也有epoll的例子就是这个套路 - 适合短耗时业务(主业务处理逻辑不能太耗时，否则必然影响新连接的建议或者其他客户端的处理等待) - 缺点： - 性能会有瓶颈的 只有一个线程，无法利用多核cpu优势 - 因为是顺序处理请求，遇到长耗时的客户端请求，会延迟所有业务，这也是redis禁用耗时命令的原因 - redis因为处理全在内存，单个请求处理非常快，所以适合这么处理，redis据说可以有10W的QPS吞吐量 ## 单Reactor+单队列+业务进程/线程池---thrift0.10.0 nonblocking server ### 整体思路 1. 主线程启动套接字监听 注册epoll ，有新的客户端连接就也注册到epoll 2. 主线程epoll_wait 监控请求数据到达 3. 主线程从connfd客户端套接字read请求数据 入请求队列 4. 子线程从队列取出请求，进行business process，处理完成应答报文还是交由主线程send给client(clientfd在主线程hold) ![](http://heketong.github.io/donate/单reactor_单队列_worker线程池.jpeg) - 客户端套接字可以想象成一个队列 reactor将这个队列通过IO多路复用转换成了真正的业务请求数据队列。 - 业务线程池线程池，从队列中拿到数据进行真正的业务处理，将结果返回Handler。Handler收到响应结果后，send结果给客户端 - thrift0.10.0版本中 nonblocking server 使用这种模型 ### 总结 - 优点： - 多线程加快了真正业务数据处理的速度，这个是很有必要的，因为业务处理大都是比较耗时的(跟数据库打交道，远程RPC等等) - 可能出现的缺点： - 性能瓶颈很大可能出现在请求队列，因为主线程写和worker线程读是线程并发的，所以需要锁(多进程一样)，要采用高性能的读写锁 ## 单 Reactor+N队列+N线程---memcached ### 整体思路 1. 主线程创建socket监听，同时accept，将accept的connfd采用Robin轮询的方式，扔给worker线程的队列 2. 每个worker线程 采用IO多路复用技术从自己的队列中取出connfd，然后read---\u0026gt;business process--\u0026gt;send 3. 每个worker线程的队列存放的是connfd，我理解这种其实也算是主从Reactor模式(master Reactor只accept，然后扔给多个subReactor) ![](http://heketong.github.io/donate/memcached_IO模型.png) ![](http://heketong.github.io/donate/memcached_IO模型1.jpeg) ### 总结 - 优点：解决单队列的性能瓶颈，而且这里的多队列里面放的connfd，不存在上面多个线程同时读一个队列的锁竞争性能消耗 - 缺点：负载均衡可能导致有些队列很忙，有些队列很闲。比如队列1里面放的客户端，发送请求比较频繁，队列2里面放的客户端发送请求比较空闲。 ## 主进程管理+多进程(accept+epoll_wait+处理)--nginx ### 整体思路 1. 主进程先创建socket 启动监听，然后fork出一堆worker进程（ 主进程不accept 只是管理多个worker进程 比如动态增加worker之类的） 2. 每个worker进程 同时accept客户端连接(accept_mutex锁解决惊群问题)，也就是每个worker自己抢客户，同时处理自己抢到的多个客户(epoll_wait) 3. worker进程根据自身负载情况，选择性地不去accept新fd，从而实现负载均衡 ![](http://heketong.github.io/donate/nginx_IO模型.jpeg) ### 总结 - 优点： - 某个worker进程挂掉不会影响整个服务 - 是由**worker主动实现负载均衡的**，这种负载均衡方式比由master来处理更简单 - 缺点： - 多进程模型编程相对复杂，开发有一定难度 - 进程的开销是比线程更多的 ## 主从多reactor多线程处理 ### 整体思路： 1. 主线程创建socket 启动监听，启动accept线程池(可以是1个或者多个) 这个线程池只负责accept客户端连接 - 每个accept线程 接收客户端连接之后 将connfd传给subReactor线程池中的某个线程 2. subReactor线程池处理思路: - 每个subReactor线程都会处理用epoll的方式监控多个connfd 负责处理read 和write事件 业务处理转发给worker线程池 3. worker线程池处理： - 接受请求处理事件 进行业务处理(计算、数据库处理之类的) 处理完成交给subReactor线程回报给client ![](http://heketong.github.io/donate/主从多reactor多线程IO模型.png) ## 总结： 这种模式理论上是性能最完美的模型，相对就是开发难度相对较大，可以使用一些现成的框架降低开发难度(Java.Netty、c++改造libevent等等) # unix编程API 转载 ## 1.字节序函数 \\#include \u0026lt;netinet.h\u0026gt; uint16_t htons(uint16_t host16bitvalue); uint32_t htonl(uint32_t host32bitvalue); 返回：网络字节序值 uint16_t ntohs(uint16_t net16bitvalue); uint32_t ntohl(uint32_t net32bitvalue); 返回：主机字节序值 一个测试本机字节序的程序，可参见见unpv12e：intro/byteorder.c。 ------ ## 2.字节操作函数 \\#include \u0026lt;strings.h\u0026gt; void bzero(void *dest, size_t nbytes); void bcopy(const void *src, void *dest, size_t nbytes); int bcmp(const void *ptr1, const void *ptr2, size_t nbytes); 返回：0—相等，非0—不相等 \\#include \u0026lt;string.h\u0026gt; void *memset(void *dest, int c, size_t len); void *memcpy(void *dest, void *src, size_t nbytes); int memcmp(const void *ptr1, const void *ptr2, size_t nbytes); 返回：0—相同，\u0026gt;0或\u0026lt;0—不相同；进行比较操作时，假定两个不相等的字节均为无符号字符（unsigned char）。 ------ ## 3.地址转换函数 \\#include \u0026lt;arpa/inet.h\u0026gt; int inet_aton(const char *strptr, struct in_addr *addrptr); 返回：1—串有效，0—串有错。 in_addr_t inet_addr(const char *strptr); 返回：若成功，返回32为二进制的网络字节序地址；若有错，则返回INADDR_NONE。 char *inet_ntoa(struct in_addr inaddr); 返回：指向点分十进制数串的指针。 int inet_pton(int family, const char *strptr, void *addrptr); 返回：1—成功；0—输入不是有效的表达格式，-1—出错。 const char *inet_ntop(int family, const void *addrptr, char *strptr, size_t len); 返回：指向结果的指针—成功，NULL—失败。 说明： - inet_aton函数的指针若为空，则函数仍然执行输入串的有效性检查，但不存储任何结果。 - inet_addr的缺陷：出错返回值INADDR_NONE等于255.255.255.255（IPv4的有限广播地址），所以该函数不能处理此地址。 尽量使用inet_aton，不使用inet_addr。 - inet_ntoa函数的执行结果放在静态内存中，是不可重入的。 - 参数family可以是AF_INET，也可以是AF_INET6，若参数family不被支持，则出错，errno置为EAFNOSUPPORT。 - 指针addrptr是结构指针。 - len指定目标的大小，避免缓冲区溢出。如果len太小，则返回一个空指针，errno置为ENOSPC。为有助于规定该大小，有如下定义： \\#include \u0026lt;netinet.h\u0026gt; \\#define INET_ADDRSTRLEN 16 /*fro IPv4 dotted-decimal */ \\#define INET6_ADDRSTRLEN 46 /*for IPv6 hex string */ - inet_ntop函数的参数strptr不能为空指针，成功时，此指针即是函数的返回值。 实现IPv4版本的inet_pton和inet_ntop的程序，参见：unpv12e：libfree/inet_pton_ipv4.c和libfree/inet_ntop_ipv4.c。 ------ ## 4.readn、writen和readline 函数原型如下： ssize_t readn(int filedes, void *buff, size_t nbytes); ssize-t writen(int filedes, void *buff, size_t nbytes); ssize_t readline(int filedes, void *buff, size_t maxlen); 返回：读写字节数，-1—出错。 实现程序见：unpv12e：lib/readn.c、lib/writen.c、lib/readline1.c和lib/readline.c。 ------ ## 5.测试描述符类型 \\#include \u0026lt;sys/stat.h\u0026gt; int isfdtype( int fd, int fdtype); 返回：1—是指定类型，0—不是指定类型，-1—出错。 要测试是否为套接口描述子，fdtype应设为S_IFSOCK。 该函数的一个实现程序，参见unpv12e：lib/isfdtype.c ------ ## 6.socket函数 \\#include \u0026lt;sys/socket.h\u0026gt; int socket(int family, int type, int protocol); 返回：非负描述字—成功，-1—出错。 family指定协议族，有如下取值： - AF_INET IPv4协议 - AF_INET6 IPv6协议 - AF_LOCAL Unix域协议 - AF_ROUTE 路由套接口 - AF_KEY 密钥套接口 type指定套接口类型： - SOCK_STREAM 字节流套接口 - SOCK_DGRAM 数据报套接口 - SOCK_RAW 原始套接口 protocol一般设为0，除非用在原始套接口上。 并非所有family和type的组合都是有效的。 AF_LOCAL等于早期的AF_UNIX。 ------ ## 7.connect函数 \\#include \u0026lt;sys/socket.h\u0026gt; int connect(int sockfd, const struct sockaddr *servaddr, socklen_t addrlen); 返回：0—成功，-1—出错。 sockfd是socket函数返回的套接口描述字，servaddr和addrlen是指向服务器的套接口地址结构指针和结构大小。 在调用connect之前不必非得调用bind函数。 如果是TCP，则connect激发TCP的三路握手过程，在阻塞情况下，只有在连接建立成功或出错时该函数才返回， 出错情况： - 没有收到SYN分节的响应，在规定时间内经过重发仍无效，则返回ETIMEDOUT； - 如果对SYN分节的响应是RST，表示服务器在指定端口上没有相应的服务，返回ECONNREFUSED； - 如果发出 SYN在中间路由器上引发一个目的地不可达ICMP错误，在规定时间内经过重发仍无效，则返回EHOSTUNREACH或ENETUNREACH错误。 注意：如果connect失败，则套接口将不能再使用，必须关闭，不能对此套接口再调用函数connect。 ------ ## 8.bind函数 \\#include \u0026lt;sys/socket.h\u0026gt; int bind(int sockfd, const struct sockaddr *maddr, socklen_t addrlen); 返回：0—成功，-1—出错。 进程可以把一个特定的IP地址捆绑到他的套接口上，但此IP地址必须是主机的一个接口。 对于IPv4，通配地址是INADDR_ANY，其值一般为0；使用方法如下： struct sockaddr_in servaddr; servaddr.sin_addr.s_addr = htonl(INADDR_ANY); 对于IPv6，方法如下： struct sockaddr_in6 serv; serv.sin6_addr = in6addr_any; （系统分配变量in6addr_any并将其初始化为常值IN6ADDR_ANY_INIT。） 如果让内核选择临时端口，注意的是bind并不返回所选的断口值，要得到一个端口，必须使用getsockname函数。 bind失败的常见错误是EADDRINUSE（地址已使用）。 ------ ## 9.listen函数 \\#include \u0026lt;sys/socket.h\u0026gt; int listen(int sockfd, int backlog); 返回：0—成功，-1—出错。 listen把未连接的套接口转化为被动套接口，指示内核应接受指向此套接口的连接请求。第二个参数规定了内核为此套接口排队的最大连接数。 参数backlog曾经规定为监听套接口上的未完成连接队列和已完成连接队列总和的最大值，但各个系统的定义方法都不尽相同；历史上常把backlog置为5，但对于繁忙的服务器是不够的；backlog的设置没有一个通用的方法，依情况而定，但不要设为0。 ------ ## 10.accept函数 \\#include \u0026lt;sys/socket.h\u0026gt; int accept(int sockfd, struct sockaddr *cliaddr, socklen_t *addrlen); 返回：非负描述字—OK，-1—出错。 accept从已完成连接队列头返回下一个连接，若已完成连接队列为空，则进程睡眠（套接口为阻塞方式时）。 参数cliaddr和addrlen返回连接对方的协议地址，其中addrlen是值-结果参数，调用前addrlen所指的整数值要置为cliaddr所指的套接口结构的长度，返回时由内核修改。 accept成功执行后，返回一个连接套接口描述字。 如果对客户的协议地址没有兴趣，可以把cliaddr和addrlen置为空指针。 ------ ## 11.close函数 \\#include \u0026lt;unistd.h\u0026gt; int close(int sockfd); 返回：0—OK，-1—出错。 TCP套接口的close缺省功能是将套接口做上“已关闭”标记，并立即返回到进程。这个套接口描述字不能再为进程使用，但TCP将试着发送已排队待发的任何数据，然后按正常的TCP连接终止序列进行操作。 close把描述字的访问计数减1，当访问计数仍大于0时，close并不会引发TCP的四分组连接终止序列。若确实要发一个FIN，可以用函数shutdown。 ------ ## 12.getsockname和getpeername \\#include \u0026lt;sys/socket.h\u0026gt; int getsockname(int sockfd, struct sockaddr *localaddr, socklen_t *addrlen); int getpeername(int sockfd, struct sockaddr *peeraddr, socklen_t *addrlen); 返回：0—OK，-1—出错。 getsockname函数返回与套接口关联的本地协议地址。 getpeername函数返回与套接口关联的远程协议地址。 addrlen是值-结果参数。 使用场合： - 在不调用bind的TCP客户，当connect成功返回后，getsockname返回分配给此连接的本地IP地址和本地端口号； - 在以端口号为0调用bind后，使用getsockname返回内核分配的本地端口号； - getsockname可用来获取某套接口的地址族； - 在捆绑了通配IP地址的TCP服务器上，当连接建立后，可以使用getsockname获得分配给此连接的本地IP地址； - 当一个服务器调用exec启动后，他获得客户身份的唯一途径是调用getpeername函数。 ------ ## 13.select函数 \\#include \u0026lt;sys/select.h\u0026gt; \\#include \u0026lt;sys/time.h\u0026gt; int select(int maxfdp1, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct timeval *timeout); 返回：准备好描述字的正数目，0—超时，-1—出错。 结构timeval的定义： struct timeval { long tv_sec; /* seconds */ long tv_usec; /* microseconds */ }; timeout取值的三种情况： - 永远等下去：仅在有一个描述字准备好I/O时才返回，设置timeout为空指针； - 等待固定时间：在有一个描述字准备好I/O时返回，但不超过由timeout参数所指定的秒数和微秒数； - 根本不等待：检查描述字后立即返回，将timeout中的秒数和微秒数都设置为0。 在等待过程中，若进程捕获了信号并从信号处理程序返回，等待一般被中断，为了可移植性，必须准备好select返回EINTR错误。 timeout的值在返回时并不会被select修改（const标志）。 readset、writeset、exceptset指定我们要让内核测试读、写和异常条件所需的描述字。 当前支持的异常条件有两个： 1. 套接口带外数据的到达； 2. 控制状态信息的存在，可从一个已置为分组方式的伪终端主端读到。 描述字集的使用： 数据类型：fd_set； void FD_ZERO(fd_set *fdset); void FD_SET(int fd, fd_set *fdset); void FD_CLR(int fd, fd_set *fdset); void FD_ISSET(int fd, fd_set *fdset); 参数maxfdp1指定被测试的描述字个数，它的值是要被测试的最大描述字加1。描述字0，1，2，…，maxfdp1-1都被测试。 readset、writeset、exceptset是值-结果参数，select修改三者所指的描述字集。所以，每次调用select时，我们都要将所有描述字集中关心的位置为1。 套接口准备好读的条件： - 套接口接收缓冲区中的数据字节数大于等于套接口接收缓冲区低潮限度的当前值。对这样的套接口的读操作将不阻塞并返回一个大于0的值（即准备好读入的数据量）。可以用套接口选项SO_RCVLOWAT来设置低潮限度，对于TCP和UDP，缺省值为1； - 连接的读这一半关闭（接收了FIN的TCP连接）。对这样的套接口读操作将不阻塞并且返回0（即文件结束符）； - 套接口是一个监听套接口且已完成的连接数为非0； - 有一个套接口错误待处理。对这样的套接口读操作将不阻塞且返回一个错误，errno设置成明确的错误条件。这些待处理错误也可以通过指定套接口选项SO_ERROR调用getsockopt来取得并清除。 套接口准备好写的条件： - 套接口发送缓冲区中的可用字节数大于等于套接口发送缓冲区低潮限度的当前值，且或者（1）套接口已连接，或者（2）套接口不要求连接（如UDP套接口）。可以用套接口选项SO_SNDLOWAT来设置此低潮限度，对于TCP和UDP，缺省值为2048； - 连接的写这一半关闭。对这样的套接口写将产生信号SIGPIPE； - 有一个套接口错误待处理。对这样的套接口写操作将不阻塞且返回一个错误，errno设置成明确的错误条件。这些待处理错误也可以通过指定套接口选项SO_ERROR调用getsockopt来取得并清除。 如果一个套接口存在带外数据或者仍处于带外标记，那它有异常条件待处理。 一个套接口出错时，它被select标记为既可读又可写。 ------ ## 14.shutdown函数 \\#include \u0026lt;sys/socket.h\u0026gt; int shutdown(int sockfd, int howto); 返回：0—成功，-1—失败。 函数的行为依赖于参数howto的值： - SHUT_RD：关闭连接的读这一半，不再接收套接口中的数据且留在套接口缓冲区中的数据都作废。进程不能再对套接口任何读函数。调用此函数后，由TCP套接口接收的任何数据都被确认，但数据本身被扔掉。 - SHUT_WR：关闭连接的写这一半，在TCP场合下，这称为半关闭。当前留在套接口发送缓冲区中的数据都被发送，后跟正常的TCP连接终止序列。此半关闭不管套接口描述字的访问计数是否大于0。进程不能再执行对套接口的任何写函数。 SHUT_RDWR：连接的读这一半和写这一半都关闭。这等效于调用shutdown两次：第一次调用时用SHUT_RD，第二次调用时用SHUT_WR。 ------ ## 15.pselect函数 \\#include \u0026lt;sys/select.h\u0026gt; \\#include \u0026lt;signal.h\u0026gt; \\#include \u0026lt;time.h\u0026gt; int pselect(int maxfdp1, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct timespec *timeout, const sigset_t *sigmask); 返回：准备好描述字的个数，0—超时，-1—出错。 pselect是Posix.1g发明的。相对select的变化： 1. pselect使用结构timespec： struct timespec { time_t tv_sec; /* seconds */ long tv_nsec; /* nanoseconds */ }; 新结构中的tv_nsec规定纳秒数。 2. pselect增加了第六个参数：指向信号掩码的指针。允许程序禁止递交某些信号。 ------ ## 16.poll函数 \\#include \u0026lt;poll.h\u0026gt; int poll(struct pollfd *fdarray, unsigned long nfds, int timeout); 返回：准备好描述字的个数，0—超时，-1—出错。 第一个参数是指向一个结构数组的第一个元素的指针，每个数组元素都是一个pollfd结构： struct pollfd { int fd; /* descriptor to check */ short events; /* events of interest on fd */ short revents; /* events that occurred on fd */ }; 要测试的条件由成员events规定，函数在相应的revents成员中返回描述字的状态（一个描述字有两个变量：一个为调用值，一个为结果）。 第二个参数指定数组中元素的个数。 第三个参数timeout指定函数返回前等待多长时间，单位是毫秒。可能值如下： - INFTIM，永远等待； - 0，立即返回，不阻塞； - \\\u0026gt;0，等待指定数目的毫秒数。 标志的范围： | 常量 | 能作为events的输入吗？ | 能作为revents的结果吗？ | 解释 | | ---------- | ---------------------- | ----------------------- | ------------------------ | | POLLIN | yes | yes | 普通或优先级带数据可读 | | POLLRDNORM | yes | yes | 普通数据可读 | | POLLRDBAND | yes | yes | 优先级带数据可读 | | POLLPRI | yes | yes | 高优先级数据可读 | | POLLOUT | yes | yes | 普通或优先级带数据可写 | | POLLWRNORM | yes | yes | 普通数据可写 | | POLLWRBAND | yes | yes | 优先级带数据可写 | | POLLERR | | yes | 发生错误 | | POLLHUP | | yes | 发生挂起 | | POLLNVAL | | yes | 描述字不是一个打开的文件 | 图可分为三部分：处理输入的四个常值；处理输出的三个常值；处理错误的三个常值。 poll识别三个类别的数据：普通（normal）、优先级带（priority band）、高优先级（high priority）。术语来自流的概念。 返回条件： - 所有正规TCP数据和UDP数据都被认为是普通数据； - TCP的带外数据被认为是优先级带数据； - 当TCP连接的读这一半关闭时（如接收了一个FIN），这也认为是普通数据，且后续的读操作将返回0； - TCP连接存在错误既可以认为是普通数据，也可以认为是错误（POLLERR）。无论哪种情况，后续的读操作将返回-1，并将errno置为适当的值，这就处理了诸如接收到RST或超时等条件； - 在监听套接口上新连接的可用性既可认为是普通数据，也可以认为是优先级带数据，大多数实现都将其作为普通数据考虑。 - 如果不关心某个特定的描述字，可将其pollfd结构的fd成员置为一个负值，这样就可以忽略成员events，且返回时将成员revents的值置为0。 poll没有select存在的最大描述字数目问题。但可移植性select要好于poll。 ------ ## 17.getsockopt和setsockopt \\#include \u0026lt;sys/socket.h\u0026gt; int getsockopt(int sockfd, int level, int optname, void *optval, socklen_t *optlen); int setsockopt(int sockfd, int level, int optname, void *optval, socklen_t *optlen); 返回：0—OK，-1—出错。 sockfd必须是一个打开的套接口描述字；level（级别）指定系统中解释选项的代码：普通套接口代码或特定于协议的代码）；optval是一个指向变量的指针；此变量的大小由最后一个参数决定。 对于某些套接口选项，什么时候进行设置或获取是有差别的。下面的套接口选项是由TCP已连接套接口从监听套接口继承来的： - SO_DEBUG； - SO_DONTROUTE； - SO_KEEPALIVE； - SO_LINGER； - SO_OOBINLINE； - SO_RCVBUF； - SO_SNDBUF。 如果想在三路握手完成时确保这些套接口选项中的某一个是给已连接套接口设置的，我们必须先给监听套接口设置此选项。 ------ ## 18.套接口选项列表 | level | Optname | get | set | 说明 | 标志 | 数据类型 | | -------------- | -------------------- | ---- | ---- | ------------------------------ | ---- | -------------- | | | | | | | | | | SOL_SOCKET | SO_BROADCAST | y | y | 允许发送广播数据报 | y | int | | | SO_DEBUG | y | y | 使能调试跟踪 | y | int | | | SO_DONTROUTE | y | y | 旁路路由表查询 | y | int | | | SO_ERROR | y | | 获取待处理错误并消除 | | int | | | SO_KEEPALIVE | y | y | 周期性测试连接是否存活 | y | int | | | SO_LINGER | y | y | 若有数据待发送则延迟关闭 | | linger{} | | | SO_OOBINLINE | y | y | 让接收到的带外数据继续在线存放 | y | int | | | SO_RCVBUF | y | y | 接收缓冲区大小 | | int | | | SO_SNDBUF | y | y | 发送缓冲区大小 | | int | | | SO_RCVLOWAT | y | y | 接收缓冲区低潮限度 | | int | | | SO_SNDLOWAT | y | y | 发送缓冲区低潮限度 | | int | | | SO_RCVTIMEO | y | y | 接收超时 | | timeval{} | | | SO_SNDTIMEO | y | y | 发送超时 | | timeval{} | | | SO_REUSEADDR | y | y | 允许重用本地地址 | y | int | | | SO_REUSEPORT | y | y | 允许重用本地地址 | y | int | | | SO_TYPE | y | | 取得套接口类型 | | int | | | SO_USELOOPBACK | y | y | 路由套接口取得所发送数据的拷贝 | y | int | | | | | | | | | | IPPROTO_IP | IP_HDRINCL | y | y | IP头部包括数据 | y | int | | | IP_OPTIONS | y | y | IP头部选项 | | 见后面说明 | | | IP_RECVDSTADDR | y | y | 返回目的IP地址 | y | int | | | IP_RECVIF | y | y | 返回接收到的接口索引 | y | int | | | IP_TOS | y | y | 服务类型和优先权 | | int | | | IP_TTL | y | y | 存活时间 | | int | | | IP_MULTICAST_IF | y | y | 指定外出接口 | | in_addr{} | | | IP_MULTICAST_TTL | y | y | 指定外出TTL | | u_char | | | IP_MULTICAST_LOOP | y | y | 指定是否回馈 | | u_char | | | IP_ADD_MEMBERSHIP | | y | 加入多播组 | | ip_mreq{} | | | IP_DROP_MEMBERSHIP | | y | 离开多播组 | | ip_mreq{} | | | | | | | | | | IPPROTO_ICMPV6 | ICMP6_FILTER | y | y | 指定传递的ICMPv6消息类型 | | icmp6_filter{} | | | | | | | | | | IPPROTO_IPV6 | IPV6_ADDRFORM | y | y | 改变套接口的地址结构 | | int | | | IPV6_CHECKSUM | y | y | 原始套接口的校验和字段偏移 | | int | | | IPV6_DSTOPTS | y | y | 接收目标选项 | y | int | | | IPV6_HOPLIMIT | y | y | 接收单播跳限 | y | int | | | IPV6_HOPOPTS | y | y | 接收步跳选项 | y | int | | | IPV6_NEXTHOP | y | y | 指定下一跳地址 | y | sockaddr{} | | | IPV6_PKTINFO | y | y | 接收分组信息 | y | int | | | IPV6_PKTOPTIONS | y | y | 指定分组选项 | | 见后面说明 | | | IPV6_RTHDR | y | y | 接收原路径 | y | int | | | IPV6_UNICAST_HOPS | y | y | 缺省单播跳限 | | int | | | IPV6_MULTICAST_IF | y | y | 指定外出接口 | | in6_addr{} | | | IPV6_MULTICAST_HOPS | y | y | 指定外出跳限 | | u_int | | | IPV6_MULTICAST_LOOP | y | y | 指定是否回馈 | y | u_int | | | IPV6_ADD_MEMBERSHIP | | y | 加入多播组 | | ipv6_mreq{} | | | IPV6_DROP_MEMBERSHIP | | y | 离开多播组 | | ipv6_mreq{} | | | | | | | | | | IPPROTO_TCP | TCP_KEEPALIVE | y | y | 控测对方是否存活前连接闲置秒数 | | int | | | TCP_MAXRT | y | y | TCP最大重传时间 | | int | | | TCP_MAXSEG | y | y | TCP最大分节大小 | | int | | | TCP_NODELAY | y | y | 禁止Nagle算法 | y | int | | | TCP_STDURG | y | y | 紧急指针的解释 | y | int | **详细说明：** ### SO_BROADCAST 使能或禁止进程发送广播消息的能力。只有数据报套接口支持广播，并且还必须在支持广播消息的网络上（如以太网、令牌环网等）。 如果目的地址是广播地址但此选项未设，则返回EACCES错误。 ### SO_DEBUG 仅仅TCP支持。当打开此选项时，内核对TCP在此套接口所发送和接收的所有分组跟踪详细信息。这些信息保存在内核的环形缓冲区内，可由程序trpt进行检查。 ### SO_DONTROUTE 此选项规定发出的分组将旁路底层协议的正常路由机制。 该选项经常由路由守护进程（routed和gated）用来旁路路由表（路由表不正确的情况下），强制一个分组从某个特定接口发出。 ### SO_ERROR 当套接口上发生错误时，源自Berkeley的内核中的协议模块将此套接口的名为so_error的变量设为标准的UNIX Exxx值中的一个，它称为此套接口的待处理错误（pending error）。内核可立即以以下两种方式通知进程： 1. 如果进程阻塞于次套接口的select调用，则无论是检查可读条件还是可写条件，select都返回并设置其中一个或所有两个条件。 2. 如果进程使用信号驱动I/O模型，则给进程或进程组生成信号SIGIO。 进程然后可以通过获取SO_ERROR套接口选项来得到so_error的值。由getsockopt返回的整数值就是此套接口的待处理错误。so_error随后由内核复位为0。 当进程调用read且没有数据返回时，如果so_error为非0值，则read返回-1且errno设为so_error的值，接着so_error的值被复位为0。如果此套接口上有数据在排队，则read返回那些数据而不是返回错误条件。 如果进程调用write时so_error为非0值，则write返回-1且errno设为so_error的值，随后so_error也被复位。 ### SO_KEEPALIVE 打开此选项后，如果2小时内在此套接口上没有任何数据交换，TCP就会自动给对方发一个保持存活探测分节，结果如下： 1. 对方以期望的ACK响应，则一切正常，应用程序得不到通知； 2. 对方以RST响应，套接口的待处理错误被置为ECONNRESET，套接口本身则被关闭； 3. 对方对探测分节无任何响应，经过重试都没有任何响应，套接口的待处理错误被置为ETIMEOUT，套接口本身被关闭；若接收到一个ICMP错误作为某个探测分节的响应，则返回相应错误。 此选项一般由服务器使用。服务器使用它是为了检测出半开连接并终止他们。 ### SO_LINGER 此选项指定函数close对面向连接的协议如何操作（如TCP）。缺省close操作是立即返回，如果有数据残留在套接口缓冲区中则系统将试着将这些数据发送给对方。 SO_LINGER选项用来改变此缺省设置。使用如下结构： struct linger { int l_onoff; /* 0 = off, nozero = on */ int l_linger; /* linger time */ }; 有下列三种情况： 1. l_onoff为0，则该选项关闭，l_linger的值被忽略，等于缺省情况，close立即返回； 2. l_onoff为非0，l_linger为0，则套接口关闭时TCP夭折连接，TCP将丢弃保留在套接口发送缓冲区中的任何数据并发送一个RST给对方，而不是通常的四分组终止序列，这避免了TIME_WAIT状态； 3. l_onoff 为非0，l_linger为非0，当套接口关闭时内核将拖延一段时间（由l_linger决定）。如果套接口缓冲区中仍残留数据，进程将处于睡眠状态，直到（a）所有数据发送完且被对方确认，之后进行正常的终止序列（描述字访问计数为0）或（b）延迟时间到。此种情况下，应用程序检查close的返回值是非常重要的，如果在数据发送完并被确认前时间到，close将返回EWOULDBLOCK错误且套接口发送缓冲区中的任何数据都丢失。close的成功返回仅告诉我们发送的数据（和FIN）已由对方TCP确认，它并不能告诉我们对方应用进程是否已读了数据。如果套接口设为非阻塞的，它将不等待close完成。 l_linger的单位依赖于实现，4.4BSD假设其单位是时钟滴答（百分之一秒），但Posix.1g规定单位为秒。 让客户知道服务器已经读其数据的一个方法时：调用shutdown（SHUT_WR）而不是调用close，并等待对方close连接的本地（服务器）端。 ### SO_OOBINLINE 此选项打开时，带外数据将被保留在正常的输入队列中（即在线存放）。当发生这种情况时，接收函数的MSG_OOB标志不能用来读带外数据。 ### SO_RCVBUF和SO_SNDBUF 每个套接口都有一个发送缓冲区和一个接收缓冲区，使用这两个套接口选项可以改变缺省缓冲区大小。 当设置TCP套接口接收缓冲区的大小时，函数调用顺序是很重要的，因为TCP的窗口规模选项是在建立连接时用SYN与对方互换得到的。对于客户，SO_RCVBUF选项必须在connect之前设置；对于服务器，SO_RCVBUF选项必须在listen前设置。 TCP套接口缓冲区的大小至少是连接的MSS的三倍，而必须是连接的MSS的偶数倍。 ### SO_RCVLOWAT和SO_SNDLOWAT 每个套接口有一个接收低潮限度和一个发送低潮限度，他们由函数select使用。这两个选项可以修改他们。 接收低潮限度是让select返回“可读”而在套接口接收缓冲区中必须有的数据量，对于一个TCP或UDP套接口，此值缺省为1。发送低潮限度是让select返回“可写”而在套接口发送缓冲区中必须有的可用空间，对于TCP套接口，此值常为2048。 ### SO_RCVTIMEO和SO_SNDTIMEO 使用这两个选项可以给套接口设置一个接收和发送超时。通过设置参数的值为0秒和0微秒来禁止超时。缺省时两个超时都是禁止的。 接收超时影响5个输入函数：read、readv、recv、recvfrom和recvmsg；发送超时影响5个输出函数：write、writev、send、sendto和sendmsg。 ### SO_REUSEADDR和SO_REUSEPORT SO_REUSEADDR提供如下四个功能： 1. SO_REUSEADDR允许启动一个监听服务器并捆绑其众所周知端口，即使以前建立的将此端口用做他们的本地端口的连接仍存在。这通常是重启监听服务器时出现，若不设置此选项，则bind时将出错。 2. SO_REUSEADDR允许在同一端口上启动同一服务器的多个实例，只要每个实例捆绑一个不同的本地IP地址即可。对于TCP，我们根本不可能启动捆绑相同IP地址和相同端口号的多个服务器。 3. SO_REUSEADDR允许单个进程捆绑同一端口到多个套接口上，只要每个捆绑指定不同的本地IP地址即可。这一般不用于TCP服务器。 4. SO_REUSEADDR允许完全重复的捆绑：当一个IP地址和端口绑定到某个套接口上时，还允许此IP地址和端口捆绑到另一个套接口上。一般来说，这个特性仅在支持多播的系统上才有，而且只对UDP套接口而言（TCP不支持多播）。 SO_REUSEPORT选项有如下语义： 1. 此选项允许完全重复捆绑，但仅在想捆绑相同IP地址和端口的套接口都指定了此套接口选项才性。 2. 如果被捆绑的IP地址是一个多播地址，则SO_REUSEADDR和SO_REUSEPORT等效。 使用这两个套接口选项的建议： 1. 在所有TCP服务器中，在调用bind之前设置SO_REUSEADDR套接口选项； 2. 当编写一个同一时刻在同一主机上可运行多次的多播应用程序时，设置SO_REUSEADDR选项，并将本组的多播地址作为本地IP地址捆绑。 ### SO_TYPE 该选项返回套接口的类型，返回的整数值是一个诸如SOCK_STREAM或SOCK_DGRAM这样的值。 ### SO_USELOOPBACK 该选项仅用于路由域（AF_ROUTE）的套接口，它对这些套接口的缺省设置为打开（这是唯一一个缺省为打开而不是关闭的SO_xxx套接口选项）。当此套接口打开时，套接口接收在其上发送的任何数据的一个拷贝。 禁止这些回馈拷贝的另一个方法是shutdown，第二个参数应设为SHUT_RD。 ### IP_HDRINCL 如果一个原始套接口设置该选项，则我们必须为所有发送到此原始套接口上的数据报构造自己的IP头部。 ### IP_OPTIONS 设置此选项允许我们在IPv4头部中设置IP选项。这要求掌握IP头部中IP选项的格式信息。 ### IP_RECVDSTADDR 该选项导致所接收到的UDP数据报的目的IP地址由函数recvmsg作为辅助数据返回。 ### IP_RECVIF 该选项导致所接收到的UDP数据报的接口索引由函数recvmsg作为辅助数据返回。 ### IP_TOS 该选项使我们可以给TCP或UDP套接口在IP头部中设置服务类型字段。如果我们给此选项调用getsockopt，则放到外出IP数据报头部的TOS字段中的当前值将返回（缺省为0）。还没有办法从接收到的IP数据报中取此值。 可以将TOS设置为如下的值： - IPTOS_LOWDELAY：最小化延迟 - IPTOS_THROUGHPUT：最大化吞吐量 - IPTOS_RELIABILITY：最大化可靠性 - IPTOS_LOWCOST：最小化成本 ### IP_TTL 用次选项，可以设置和获取系统用于某个给定套接口的缺省TTL值（存活时间字段）。与TOS一样，没有办法从接收到的数据报中得到此值。 ### ICMP6_FILTER 可获取和设置一个icmp6_filter结构，他指明256个可能的ICMPv6消息类型中哪一个传递给在原始套接口上的进程。 ### IPV6_ADDRFORM 允许套接口从IPv4转换到IPv6，反之亦可。 ### IPV6_CHECKSUM 指定用户数据中校验和所处位置的字节偏移。如果此值为非负，则内核将（1）给所有外出分组计算并存储校验和；（2）输入时检查所收到的分组的校验和，丢弃带有无效校验和的分组。此选项影响出ICMPv6原始套接口外的所有IPv6套接口。如果指定的值为-1（缺省值），内核在此原始套接口上将不给外出的分组计算并存储校验和，也不检查所收到的分组的校验和。 ### IPV6_DSTOPTS 设置此选项指明：任何接收到的IPv6目标选项都将由recvmsg作为辅助数据返回。此选项缺省为关闭。 ### IPV6_HOPLIMIT 设置此选项指明：接收到的跳限字段将由recvmsg作为辅助数据返回。 ### IPV6_HOPOPTS 设置此选项指明：任何接收到的步跳选项都将由recvmsg作为辅助数据返回。 ### IPV6_NEXTHOP 这不是一个套接口选项，而是一个可指定个sendmsg的辅助数据对象的类型。此对象以一个套接口地址结构指定某个数据报的下一跳地址。 ### IPV6_PKTINFO 设置此选项指明：下面关于接收到的IPv6数据报的两条信息将由recvmsg作为辅助数据返回：目的IPv6地址和到达接口索引。 ### IPV6_PKTOPTIONS 大多数IPv6套接口选项假设UDP套接口使用recvmsg和sendmsg所用的辅助数据在内核与应用进程间传递信息。TCP套接口使用IPV6_PKTOPTIONS来获取和存储这些值。 ### IPV6_RTHDR 设置此选项指明：接收到的IPv6路由头部将由recvmsg作为辅助数据返回。 ### IPV6_UNICAST_HOPS 类似于IPv4的IP_TTL，它的设置指定发送到套接口上的外出数据报的缺省跳限，而它的获取则返回内核将用于套接口的跳限值。为了从接收到的IPv6数据报中得到真实的跳限字段，要求使用IPV6_HOPLIMIT套接口选项。 ### TCP_KEEPALIVE 它指定TCP开始发送保持存活探测分节前以秒为单位的连接空闲时间。缺省值至少为7200秒，即2小时。该选项仅在SO_KEEPALIVE套接口选项打开时才有效。 ### TCP_MAXRT 它指定一旦TCP开始重传数据，在连接断开之前需经历的以秒为单位的时间总量。值0意味着使用系统缺省值，值-1意味着永远重传数据。 ### TCP_MAXSEG 允许获取或设置TCP连接的最大分节大小（MSS）。返回值是我们的TCP发送给另一端的最大数据量，他常常就是由另一端用SYN分节通告的MSS，除非我们的TCP选择使用一个比对方通告的MSS小的值。如果此选项在套接口连接之前取得，则返回值为未从另一端收到的MSS选项的情况下所用的缺省值。 ### TCP_NODELAY 如果设置，此选项禁止TCP的Nagle算法。缺省时，该算法是使能的。 Nagle算法的目的是减少WAN上小分组的数目。 Nagle算法常常与另一个TCP算法联合使用：延迟ACK（delayed ACK）算法。 解决多次写导致Nagle算法和延迟ACK算法负面影响的方法： 1. 使用writev而不是多次write； 2. 合并缓冲区，对此缓冲区使用一次write； 3. 设置TCP_NODELAY选项，继续调用write多次，这是最不可取的解决方法。 ### TCP_STDURG 它影响对TCP紧急指针的解释。 ------ ## 19.处理套接口的fcntl函数 \\#include \u0026lt;fcntl.h\u0026gt; int fcntl(int fd, int cmd, … /* arg */); 返回：依赖于参数cmd—成功，-1—失败。 函数fcntl提供了如下关于网络编程的特性： 1. 非阻塞I/O：通过用F_SETFL命令设置O_NONBLOCK文件状态标志来设置套接口为非阻塞型。 2. 信号驱动I/O：用F_SETFL命令来设置O_ASYNC文件状态标志，这导致在套接口状态发生变化时内核生成信号SIGIO。 3. F_SETOWN命令设置套接口属主（进程ID或进程组ID），由它来接收信号SIGIO和SIGURG。SIGIO在设置套接口为信号驱动I/O型时生成，SIGURG在新的带外数据到达套接口时生成。 4. F_GETOWN命令返回套接口的当前属主。 注意事项： - 设置某个文件状态标志时，先取得当前标志，与新标志路逻辑或后再设置标志。 - 信号SIGIO和SIGURG与其他信号不同之处在于，这两个信号只有在已使用命令F_SETOWN给套接口指派了属主后才会生成。F_SETOWN命令的整参数arg既可以是一个正整数，指明接收信号的进程ID，也可以是一个负整数，它的绝对值是接收信号的进程组ID。 - 当一个新的套接口由函数socket创建时，他没有属主，但是当一个新的套接口从一个监听套接口创建时，套接口属主便由已连接套接口从监听套接口继承而来。 ------ ## 20.gethostbyname函数 \\#include \u0026lt;netdb.h\u0026gt; struct hostent *gethostbyname(const char *hostname); 返回：非空指针—成功，空指针—出错，同时设置h_errno。 函数返回的非空指针指向的结构如下： struct hostent { char *h_name; /*规范主机名 */ char **h_aliases; /* 别名列表 */ int h_addrtype; /* AF_INET or AF_INET6 */ int h_length; /* 地址长度 */ char **h_addr_list; /* IPv4或IPv6地址结构列表 */ }; \\#define h_addr h_addr_list[0]; 按照DNS的说法，gethostbyname执行一个对A记录的查询或对AAAA记录的查询，返回IPv4或IPv6地址。 h_addr的定义是为了兼容，在新代码中不应使用。 返回的h_name称为主机的规范（canonical）名字。当返回IPv6地址时，h_addrtype被设置为AF_INET6，成员h_length被设置为16。 gethostbyname的特殊之处在于：当发生错误时，他不设置errno，而是将全局整数h_errno设置为定义在头文件\u0026lt;netdb.h\u0026gt;中的下列常值中的一个： - HOST_NOT_FOUND； - TRY_AGAIN； - NO_RECOVERY； - NO_DATA（等同于NO_ADDRESS）。 有函数hstrerror（），它将h_errno的值作为唯一的参数，返回一个指向相应错误说明的const char *型指针。 ### DNS小常识： DNS中的条目称为资源记录RR（resource record），仅有少数几类RR会影响我们的名字与地址转换： - A：A记录将主机名映射为32位的IPv4地址； - AAAA：“四A”记录将主机名映射为128位的IPv6地址； - PTR：PTR记录（称为“指针记录”）将IP地址映射为主机名； - MX：MX记录指定一主机作为某主机的“邮件交换器”。 - CNAME：CNAME代表“canonical name（规范名字）”，其常见的用法是为常用服务如ftp和www指派一个CNAME记录。 ------ ## 21.gethostbyname2函数 \\#include \u0026lt;netdb.h\u0026gt; struct hostent *gethostbyname2(const char *hostname, int family); 返回：非空指针—成功，空指针—出错，同时设置h_errno。 该函数允许指定地址族，其他与gethostbyname相似。 ------ ## 22.gethostbyaddr函数 \\#include \u0026lt;netdb.h\u0026gt; struct hostent *gethostbyaddr(const char *addr, size_t len, int family); 返回：非空指针—成功，空指针—出错，同时设置h_error。 函数根据一个二进制的IP地址并试图找出相应于此地址的主机名，我们关心的是规范主机名h_name。 参数addr不是char *类型，而是一个真正指向含有IPv4或IPv6地址的结构in_addr或in6_addr的指针；len是该结构的大小，对于IPv4是4，对于IPv6是16；family或为AF_INET或为AF_INET6。 按照DNS的说法，该函数查询PTR记录。 ------ ## 23.uname函数 \\#include \u0026lt;sys/utsname.h\u0026gt; int uname(struct utsname *name); 返回：非负值—成功，-1—失败。 返回当前主机的名字，存放在如下的结构里： \\#define UTS_NAMESIZE 16 \\#define UTS_NODESIZE 256 struct utsname { char sysname[UTS_NAMESIZE]; char nodename[UTS_NODESIZE]; char release[UTS_NAMESIZE]; char version[UTS_NAMESIZE]; char machine[UTS_NAMESIZE]; }; 该函数经常与gethostbyname一起用来确定本机的IP地址：先调用uname获得主机名字，然后调用gethostbyname得到所有的IP地址。 获得本机IP地址的另一个方法是ioctl的命令SIOCGIFCONF。 ------ ## 24.gethostname函数 \\#include \u0026lt;unistd.h\u0026gt; int gethostname(char *name, size_t namelen); 返回：0—成功，-1—失败。 返回当前主机的名字。name是指向主机名存储位置的指针，namelen是此数组的大小，如果有空间，主机名以空字符结束。 主机名的最大大小通常是头文件\u0026lt;sys/param.h\u0026gt;定义的常值MAXHOSTNAMELEN。 ------ ## 25.getservbyname函数 \\#include \u0026lt;netdb.h\u0026gt; struct servent *getservbyname(const char *servname, const char *protoname); 返回：非空指针—成功，空指针—失败。 函数返回如下结构的指针： struct servent { char *s_name; char **s_aliases; int s_port; char *s_proto; }; 服务名servname必须指定，如果还指定了协议（protoname为非空指针），则结果表项必须有匹配的记录。如果没有指定协议名而服务支持多个协议，则返回哪个端口是依赖于实现的。 结构中的端口号是以网络字节序返回的，所以在将它存储在套接口地址结构时，绝对不能调用htons。 ------ ## 26.getservbyport函数 \\#include \u0026lt;netdb.h\u0026gt; struct servent *getservbyport(int port, const char *protname); 返回：非空指针—成功，空指针—出错。 port必须为网络字节序。例如： sptr = getservbyport(htons(53), “udp”); ------ ## 27.recv和send \\#include \u0026lt;sys/socket.h\u0026gt; ssize_t recv(int sockfd, void *buf, size_t nbytes, int flags); ssize_t send(int sockfd, void *buf, size_t nbytes, int flags); 返回：成功返回读入或写出的字节数，出错返回-1。 前三个参数与read和write相同，参数flags的值或为0，或由以下的一个或多个常值逻辑或构成： | flags | 描述 | recv | send | | ------------- | ------------------ | ---- | ---- | | | | | | | MSG_DONTROUTE | 不查路由表 | | y | | MSG_DONTWAIT | 本操作不阻塞 | y | y | | MSG_OOB | 发送或接收带外数据 | y | y | | MSG_PEEK | 查看外来的消息 | y | | | MSG_WAITALL | 等待所有数据 | y | | 下面说明每个标志的作用： - MSG_DONTROUTE：这个标志告诉内核目的主机在直接连接的本地网络上，不要查路由表。这是对提供这种特性的SO_DONTROUTE套接口选项的补充。该标志可以对单个输出操作提供这种特性，而套接口选项则针对某个套接口上的所有输出操作。 - MSG_DONTWAIT：这个标志将单个I/O操作设为非阻塞方式，而不需要在套接口上打开非阻塞标志，执行I/O操作，然后关闭阻塞标志。 - MSG_OOB：用send时，这个标志指明发送的是带外数据，用recv时，该标志指明要读的是带外数据而不是一般数据。 - MSG_PEEK：这个标志可以让我们查看可读的数据，在recv或recvfrom后系统不会将这些数据丢弃。 - MSG_WAITALL：由4.3BSD Reno引入，他告诉内核在没有读到请求的字节数之前不使读操作返回。如果系统支持这个标志，则可以去掉readn函数。即使设定了该标志，如果发生如下情况：（1）捕获了一个信号；（2）连接被终止；（3）在套接口上发生错误，这个函数返回的字节数仍会比请求的少。 ------ ## 28.readv和writev \\#include \u0026lt;sys/uio.h\u0026gt; ssize_t readv(int filedes, const struct iovec *iov, int iovcnt); ssize_t writev(int filedes, const struct iovec *iov, int iovcnt); 返回：读到或写出的字节数，出错返回-1。 readv和writev可以让我们在一个函数调用中读或写多个缓冲区，这些操作被称为分散读和集中写。 iovec结构定义如下： struct iovec { void *iov_base; /* starting address of buffer */ size_t iov_len; /* size of buffer */ }; 在具体的实现中对iovec结构数组的元素个数有限制，4.3BSD最多允许1024个，而Solaris2.5上限是16。Posix.1g要求定义一个常值IOV_MAX，而且它的值不小于16。 readv和writev可用于任何描述字。writev是一个原子操作，可以避免多次写引发的Nagle算法。 ------ ## 29.readmsg和writemsg \\#include \u0026lt;sys/socket.h\u0026gt; ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags); ssize_t sendmsg(int sockfd, struct msghdr *msg, int flags); 返回：成功时为读入或写出的字节数，出错时为-1。 这两个函数是最通用的套接口I/O函数，可以用recvmsg代替read、readv、recv和recvfrom，同样，各种输出函数都可以用sendmsg代替。 参数msghdr结构的定义如下： struct msghdr { void *msg_name; /* protocol address */ socklen_t msg_namelen; /* size of protocol address */ struct iovec *msg_iov; /* scatter/gather array */ size_t msg_iovlen; /* elements in msg_iov */ void *msg_control; /* ancillary data; must be aligned for a cmsghdr structure */ socklen_t msg_controllen; /* length of ancillary data */ int msg_flags; /* flags returned by recvmsg() */ }; 该结构源自4.3BSD Reno，也是Posix.1g中所说明的，有些系统仍使用一种老的msghdr结构，此种结构中没有msg_flags成员，而且 msg_control和msg_controllen成员分别被叫做msg_accrights和msg_accrightslen。老系统中支持的唯一一种辅助数据形式是文件描述字（称为访问权限）的传递。 msg_name和msg_namelen成员用于未经连接的套接口，他们与 recvfrom和sendto的第五和第六个参数类似：msg_name指向一个套接口地址结构，如果不需要指明协议地址，msg_name应被设置为空指针，msg_namelen对sendmsg是一个值，而对recvmsg是一个值-结果参数。 msg_iov和msg_iovlen成员指明输入或输出的缓冲区数组。 msg_control和msg_controllen指明可选的辅助数据的位置和大小，msg_controllen对recvmsg是一个值-结果参数。 msg_flags只用于revmsg，调用recvmsg时，flags参数被拷贝到msg_flags成员，而且内核用这个值进行接收处理，接着它的值会根据recvmsg的结果而更新，sendmsg会忽略msg_flags成员，因为它在进行输出处理时使用flags参数。 内核检查的flags和返回的msg_flags如下表所示： | 标志 | 在send flags、 sendto flags、 sendmsg flags中检查 | 在recv flags、 recvfrom flags、 recvmsg flags中检查 | 在recvmsg msg_flags 中返回 | | ------------- | ------------------------------------------------- | --------------------------------------------------- | -------------------------- | | | | | | | MSG_DONTROUTE | y | | | | MSG_DONTWAIT | y | y | | | MSG_PEEK | | y | | | MSG_WAITALL | | y | | | MSG_EOR | y | | y | | MSG_OOB | y | y | y | | MSG_BCAST | | | y | | MSG_MCAST | | | y | | MSG_TRUNC | | | y | | MSG_CTRUNC | | | y | 前四个标志只检查不返回，下两个标志既检查又返回，最后四个只返回。返回的六个标志含义如下： - MSG_BCAST：当收到的数据报是一个链路层的广播或其目的IP地址为广播地址时，将返回此标志。 - MSG_MCAST：当收到的数据报是链路层的多播时，将返回该标志。 - MSG_TRUNC：这个标志在数据报被截断时返回。 - MSG_CTRUNC：这个标志在辅助数据被截断时返回。 - MSG_EOR：如果返回的数据不是一个逻辑记录的结尾，该标志被清位，反之则置位。TCP不使用这个标志，因为它是一种字节流协议。 - MSG_OOB：这个标志不是为TCP的带外数据返回的，它用于其他协议族（譬如OSI协议等）。 具体的实现可能会在msg_flags中返回一些输入的flags的标志，所以我们应该只检查那些感兴趣的标志的值。 ------ ## 30.socketpair函数 \\#include \u0026lt;sys/socket.h\u0026gt; int socketpair(int family, int type, int protocol, int sockfd[2]); 返回：成功返回0，出错返回-1。 family必须为AF_LOCAL，protocol必须为0，type可以是SOCK_STREAM或SOCK_DGRAM。新创建的两个套接口描述字作为sockfd[0]和sockfd[1]返回。 这两个描述字相互连接，没有名字，即没有涉及隐式bind。 以SOCK_STREAM作为type调用所得到的结果称为流管道（stream pipe）。这与一般的UNIX管道类似，但流管道是全双工的，两个描述字都是可读写的。 ------ ## 31.套接口ioctl函数 \\#include \u0026lt;unistd.h\u0026gt; int ioctl(int fd, int request, … /* void *arg */ ); 返回：成功返回0，出错返回-1。 第三个参数总是一个指针，但指针的类型依赖于request。 ioctl和网络有关的请求可分为如下6类： | 类别 | request | 描述 | 数据类型 | | ------ | -------------- | ---------------------------- | -------------- | | | | | | | 套接口 | SIOCATMARK | 在带外标志上吗 | int | | | SIOCSPGRP | 设置套接口的进程ID或进程组ID | int | | | SIOCGPGRP | 获取套接口的进程ID或进程组ID | int | | | | | | | 文件 | FIONBIO | 设置/清除非阻塞标志 | int | | | FIOASYNC | 设置/清除异步I/O标志 | int | | | FIONREAD | 获取接收缓冲区中的字节数 | int | | | FIOSETOWN | 设置文件的进程ID或进程组ID | int | | | FIOGETOWN | 获取文件的进程ID或进程组ID | int | | | | | | | 接口 | SIOCGIFCONF | 获取所有接口的列表 | struct ifconf | | | SIOCSIFADDR | 设置接口地址 | struct ifreq | | | SIOCGIFADDR | 获取接口地址 | struct ifreq | | | SIOCSIFFLAGS | 设置接口标志 | struct ifreq | | | SIOCGIFFLAGS | 获取接口标志 | struct ifreq | | | SIOCSIFDSTADDR | 设置点到点地址 | struct ifreq | | | SIOCGIFDSTADDR | 获取点到点地址 | struct ifreq | | | SIOCGIFBRDADDR | 获取广播地址 | struct ifreq | | | SIOCSIFBRDADDR | 设置广播地址 | struct ifreq | | | SIOCGIFNETMASK | 获取子网掩码 | struct ifreq | | | SIOCSIFNETMASK | 设置子网掩码 | struct ifreq | | | SIOCGIFMETRIC | 获取接口的测度（metric） | struct ifreq | | | SIOCSIFMETRIC | 设置接口的测度（metric） | struct ifreq | | | SIOCxxx | （有很多，依赖于实现） | | | | | | | | ARP | SIOCSARP | 创建/修改ARP项 | struct arpreq | | | SIOCGARP | 获取ARP项 | struct arpreq | | | SIOCDARP | 删除ARP项 | struct arpreq | | | | | | | 路由 | SIOCADDRT | 增加路径 | struct rtentry | | | SIOCDELRT | 删除路径 | struct rtentry | | | | | | | 流 | I_xxx | | | ### (1)套接口操作 - SIOCATMARK：如果套接口的读指针当前在带外标志上，则通过第三个参数指向的整数返回一个非零值，否则返回零。Posix.1g用sockatmark代替了这种请求。 - SIOCGPGRP：通过第三个参数指向的整数返回为接收来自这个套接口的SIGIO或SIGURG信号而设置的进程ID或进程组ID。这和fcntl的F_GETOWN相同。 - SIOCSPGRP：用第三个参数指向的整数设置进程ID或进程组ID以接收这个套接口的SIGIO或SIGURG信号。这和fcntl的F_SETOWN相同。 ### (2)文件操作 - FIONBIO：套接口的非阻塞标志会根据第三个参数指向的值是否为零而清除或设置。等价于fcntl的F_SETFL设置/清除O_NONBLOCK标志。 - FIOASYNC：根据第三个参数指向的值是否为零决定清除或接收套接口上的异步I/O信号。等价于fcntl的F_SETFL设置和清除O_AYNC标志。 - FIONREAD：在第三个参数指向的整数中返回套接口接收缓冲区中当前的字节数。 - FIOSETOWN：在套接口上等价于SIOCSPGRP。 - FIOGETOWN：在套接口上等价于SIOCGPGRP。 ### (3)接口配置 SIOCGIFCONF：从内核中获取系统中配置的所有接口。它使用了结构ifconf，ifconf又使用了ifreq结构。 结构定义如下： struct ifconf { int ifc_len; /* size of buffer, value-result */ union { caddr_t ifcu_buf; /* input from user-\u0026gt;kernel */ struct ifreq *ifcu_req; /* return from kernel-\u0026gt;user */ }ifc_ifcu; }; \\#define ifc_buf ifc_ifcu.ifcu_buf \\#define ifc_req ifc_ifcu.ifcu_req \\#define IFNAMSIZ 16 struct ifreq { char ifr_name[IFNAMSIZ]; union { struct sockaddr ifru_addr; struct sockaddr ifru_dstaddr; struct sockaddr ifru_broadaddr; short ifru_flags; int ifru_metric; caddr_t ifru_data; }ifr_ifru; }; \\#define ifr_addr ifr_ifru.ifru_addr \\#define ifr_dstaddr ifr_ifru.ifru_dstaddr \\#define ifr_broadaddr ifr_ifru.broadaddr \\#define ifr_flags ifr_ifru.ifru_flags \\#define ifr_metric ifr_ifru.ifru_metric \\#define ifr_data ifr_ifru.ifru_data 在调用ioctl之前分配一个缓冲区和一个ifconf结构，然后初始化后者，iotctl的第三个参数指向ifconf结构。 一个实现获取所有接口的程序，可参见unpv12e：lib/get_ifi_info.c ### (4)接口操作 - SIOCGIFCONF：从内核中获取系统中配置的所有接口。 ### (5)ARP高速缓存操作 ### (6)路由表操作 http://www.cnblogs.com/riky/archive/2006/11/24/570713.aspx 转自：http://blog.chinaunix.net/space.php?uid=20564848\u0026amp;do=blog\u0026amp;id=73226 # 进程间通信IPC Inter-Process Communication ## 信号Signal ### 什么是信号 - 信号在现实世界就是用来传递的某种信息的一种手段，比如一个眼神，一个声音、一个约定的手势等等 - 计算机世界信号是软件层次上对中断机制的一种模拟。 - 信号是异步的，进程不用做什么操作来等待信号到达，也不清楚信号什么时候能够到达，用来异步通知一个进程某种事情发生了，进程通过实现注册某些函数，来异步等待相应信号发生的时候做相应的处理。 ### 信号的来源 - 硬件来源 - (比如我们按下了键盘上的某些键【Control+C之类的】 或者某些硬件出现了故障等等) - 软件来源 - 通过kill, raise,alarm,setitimer,sigqueue,abort系统函数 向特定进程发送信号 - 一些非常运算操作 比如除以0等等 ### 收到信号如何处理 - 忽略信号 - 也就是不做任何处理 SIGKILL、SIGSTOP不能忽略 - 捕捉信号，定义自己的信号处理函数，当信号来了，执行相应处理 - 执行缺省操作，不走上面2个步骤，默认就是这个，linux对每个信号都有默认操作 ### 相关系统函数说明 - kill函数  #include  #include  int kill(pid_t pid,int signo) 对指定的进程发送什么信息。 pid\u0026gt;0 进程 ID 为 pid 的进程； pid=0 同一个进程组的进程； pid\u0026lt;0 pid!=-1进程组 ID 为 -pid 的所有进程； pid=-1 除发送进程自身外，所有进程 ID 大于1的进程。\n - raise函数  #include  int raise(int signo) 向进程本身发送信号，参数为即将发送的信号值。 调用成功返回 0；否则，返回 -1\n - sigqueue函数  #include  #include  int sigqueue(pid_t pid, int sig, const union sigval val) 调用成功返回 0；否则，返回 -1。 第一个参数是指定接收信号的进程 ID，第二个参数确定即将发送的信号，第三个参数是一个联合数据结构 union sigval，指定了信号传递的参数，sigqueue() 比 kill() 传递了更多的附加信息，但 sigqueue() 只能向一个进程发送信号，而不能发送信号给一个进程组\n - alarm函数  #include  unsigned int alarm(unsigned int seconds) 为 SIGALRM 信号而设，在指定的时间 seconds 秒后，将向进程本身发送 SIGALRM 信号，又称为闹钟时间。 进程调用 alarm 后，任何以前的 alarm() 调用都将无效。 如果参数 seconds 为零，那么进程内将不再包含任何闹钟时间。 返回值，如果调用 alarm 前，进程中已经设置了闹钟时间，则返回上一个闹钟时间的剩余时间，否则返回 0。\n - setitimer函数  #include  int setitimer(int which, const struct itimerval *value, struct itimerval *ovalue)); 比 alarm功能强大，支持3种类型的定时器： ITIMER_REAL： 设定绝对时间；经过指定的时间后，内核将发送SIGALRM信号给本进程； ITIMER_VIRTUAL 设定程序执行时间；经过指定的时间后，内核将发送SIGVTALRM信号给本进程； ITIMER_PROF 设定进程执行以及内核因本进程而消耗的时间和，经过指定的时间后，内核将发送ITIMER_VIRTUAL信号给本进程；\n - abort函数  #include  void abort(void); 向进程发送 SIGABORT 信号，默认情况下进程会异常退出，当然可定义自己的信号处理函数。 即使 SIGABORT 被进程设置为阻塞信号，调用 abort() 后，SIGABORT 仍然能被进程接收。该函数无返回值。\n ### 如何注册信号处理 - **确定信号值及进程针对该信号值的动作之间的映射关系，即进程将要处理哪个信号；该信号被传递给进程时，将执行何种操作** - signal函数  #include  void (signal(int signum, void (handler))(int)))(int); \u0026mdash;\u0026mdash;-或者\u0026mdash;\u0026mdash;\u0026ndash; #include  typedef void (*sighandler_t)(int); sighandler_t signal(int signum, sighandler_t handler)); 第一个参数指定信号的值，第二个参数指定针对前面信号值的处理，可以忽略该信号（参数设为 SIG_IGN）； 可以采用系统默认方式处理信号(参数设为 SIG_DFL)； 也可以自己实现处理方式(参数指定一个函数地址)。 如果 signal() 调用成功，返回最后一次为安装信号 signum 而调用signal() 时的 handler值；失败则返回 SIG_ERR。\n - sigaction函数  #include  int sigaction(int signum,const struct sigaction *act,struct sigaction *oldact)); sigaction函数 用于改变进程接收到特定信号后的行为。 该函数的第一个参数为信号的值，可以为除SIGKILL及SIGSTOP外的任何一个特定有效的信号（为这两个信号定义自己的处理函数，将导致信号安装错误）。 第二个参数是指向结构 sigaction 的一个实例的指针，在结构sigaction 的实例中，指定了对特定信号的处理，可以为空，进程会以缺省方式对信号处理； 第三个参数 oldact 指向的对象用来保存原来对相应信号的处理，可指定 oldact 为 NULL。如果把第二、第三个参数都设为NULL，那么该函数可用于检查信号的有效性。 第二个参数最为重要，其中包含了对指定信号的处理、信号所传递的信息、信号处理函数执行过程中应屏蔽掉哪些函数等等。\n ### 缺点 - 能够传递的信息是有限的，不能传递更为复杂的信息。 ## 文件 file - 这种应该是最简单 最容易理解的一种通信方式 一个进程往文件写信息，另外一个进程读信息，也就完成了通信过程。 - 通信本身没有任何顺序控制，可能没有写完，另外一个进程就读到了，另外一个进程本身可能也能够写 - 可以通过信号来控制有序 - 文件通信没有访问规则 - 文件访问的速度是很慢的，所以一般不常用 ## 管道 pipe/named pipe - pipe - 半双工 数据流向是单一的，如果双方通信时 需要建立2个pipe - 使用范围只能是父子进程/兄弟进程 - 在内存中的文件系统 - 一个进程写入输入到管道 可以被另外一端的进程读出，写入的内容每次都添加到管道缓冲区的尾部，相应的另外一端进程每次都从缓冲区的头部读取。  #include  int pipe(int fd[2]) 一端只能用于读，由描述字 fd[0] 表示，称其为管道读端 一端则只能用于写，由描述字 fd[1] 来表示，称其为管道写端 试图从管道写端读取数据，或者向管道读端写入数据都将导致错误发生 fd创建后 fd[0]/fd[1]就可以当作普通的文件描述符使用了 比如close read write等\n - Named pipe - 可以在任意进程间使用来完成通信工作 - 会在文件系统创建一个真实存在的文件，但实际是将其映射到内存中的一个特殊区域 文件本身可以设置相应的权限控制  #include  #include  int mkfifo(const char * pathname, mode_t mode) 该函数的第一个参数是一个普通的路径名，也就是创建后 FIFO 的名字。 第二个参数与打开普通文件的 open() 函数中的mode 参数相同。 如果 mkfifo 的第一个参数是一个已经存在的路径名时，会返回EEXIST 错误，所以一般典型的调用代码首先会检查是否返回该错误，如果确实返回该错误，那么只要调用打开 FIFO 的函数就可以了。一般文件的 I/O 函数都可以用于 FIFO，如 close、read、write 等等。\n - 管道在进程间通信中使用的比较频繁，尤其是父子多进程间通信 用的非常多 ## 共享内存 shm ### 什么是共享内存 - 顾名思义就是多个进程可以访问同一片内存空间，共享内存允许多个进程共享一个存储区，因为数据不用来回的复制，所以是是最快的IPC形式，这个共享内存是独立与 所有进程空间之外的。 - 进程对于共享内存的主要使用可能有以下几点 - 向内核提交申请 创建一个共享内存区域 - 申请使用一个已经存在的共享内存区域 - 申请释放某一个共享内存区域 - 可以通过mmap()映射普通文件(**特殊情况下还可以采用匿名映射**）机制实现，也可以通过系统V共享内存机制实现 - 应用接口和原理很好理解，但内部实现机制复杂，往往为了安全通信，要引入信号灯，锁等同步机制共同使用 ### 创建及使用 - mmap()映射一个普通文件实现共享内存 - 通过shm共享内存机制创建(每个共享内存区域对应特殊文件系统shm中的一个文件)  int shmget(key_t key, size_t size, int shmflg); //返回值是共享内存的标号shmid int shmid = shmget(key, 256, IPC_CREAT | IPC_EXCL | 0755)； key_t 是一个 long 类型，是 IPC 资源外部约定的 key (关键)值，通过 key 值映射对应的唯一存在的某一个 IPC 资源 通过 key_t 的值就能够判断某一个对应的共享内存区域在哪，是否已经创建等等 一个 key 值只能映射一个共享内存区域，但同时还可以映射一个信号量，一个消息队列资源，于是就可以使用一个 key 值管理三种不同的资源\n共享内存的控制信息可以通过 shmctl() 方法获取，会保存在struct_shmid_ds 结构体中 int shmctl(int shmid, int cmd, struct shmid_ds *buf) cmd：看执行什么操作(1、获取共享内存信息；2、设置共享内存信息；3、删除共享内存)。\nvoid * shmat(int shmid, const void *shmaddr, int shmflg); 将这个内存区域映射到本进程的虚拟地址空间 int shmdt(const void *shmaddr); 取消共享内存映射\n ## 信号量semaphore ### 概念 - 不同进程间/同一进程的不同线程间的一种同步手段 - 为了解决访问共享资源时候的冲突问题 ### 访问规则 ​ sem：表示的是一种共享资源的个数，对共享资源的访问规则 ​ 1）用一种数量单位去标识某一种共享资源的个数。 ​ 2）当有进程需要访问对应的共享资源的时候，则需要先查看申请，根据当前资源对应的可用数量进行申请。 ​ 3）资源的管理者（也就是操作系统内核）就使用当前的资源个数减去要申请的资源的个数。如果结果 \u0026gt;=0 表示有可用资源，允许该进程的继续访问；否则表示资源不可用，通知进程（暂停或立即返回）。 ​ 4）资源数量的变化就表示资源的占用和释放。占用：使得可用资源减少；释放：使得可用资源增加。 ### 相关API  //创建信号量集 int semid = semget(key_t key, int nsems, int semflg) 信号量 ID 事实上是信号量集合的ID，一个ID 对应的是一组信号量，此时就使用信号量ID 设置整个信号量集合 这个时候操作分两种： （1）针对信号量集合中的一个信号量进行设置；信号量集合中的信号量是按照数组的方式被管理起来的，从而可以直接使用信号的数组下标来进行访问。\n（2）针对整个信号量集和进行统一的设置 int semctl(int semid, int semnum, int cmd, \u0026hellip;) 如果 cmd 是 GETALL、SETALL、GETVAL、SETVAL\u0026hellip;的话，则需要提供第四个参数。第四个参数是一个共用体，这个共用体在程序中必须的自己定义（作用：初始化资源个数），定义格式如下： union semun{ int val; /* Value for SETVAL */ struct semid_ds buf; / Buffer for IPC_STAT, IPC_SET */ unsigned short array; / Array for GETALL, SETALL */ struct seminfo __buf; / Buffer for IPC_INFO (Linux-specific) */ };\n//semop()方法。(op：operator操作) int semop(int semid, struct sembuf sops, unsigned nsops); 第二个参数需要借助结构体 struct sembuf： struct sembuf{ unsigned short sem_num; / semaphore number 数组下标 / short sem_op; / semaphore operation / short sem_flg; / operation flags 默认0*/ }； 通过下标直接对其信号量 sem_op 进行加减即可。\n ### 特点 - 如果有进程通过信号量申请共享资源，而且此时资源个数已经小于0，则此时对于该进程有两种可能性：等待资源，不等待。 - 如果此时进程选择等待资源，则操作系统内核会针对该信号量构建进程等待队列，将等待的进程加入到该队列之中。 - 如果此时有进程释放资源则会： (1)、先将资源个数增加； (2)、从等待队列中抽取第一个进程； (3)、根据此时资源个数和第一个进程需要申请的资源个数进行比较，结果大于 0，则唤醒该进程；结果小于 0，则让该进程继续等待。 所以一般结合信号量的操作和共享内存使用来达到进程间的通信 ## 消息队列 Message ### 概念 - 消息队列就是一个消息的链表。可以把消息看作一个记录，具有特定的格式以及特定的优先级 - 对消息队列有写权限的进程可以向中按照一定的规则添加新消息；对消息队列有读权限的进程则可以从消息队列中读走消息 - 消息队列是随内核持续的；克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点 - 消息队列是随内核持续的，只有在内核重起或者显示删除一个消息队列时，该消息队列才会真正被删除。因此系统中记录消息队列的数据结构（struct ipc_ids msg_ids）位于内核中，系统中的所有消息队列都可以在结构msg_ids中找到访问入口 ### 结构 ​ 消息队列就是一个消息的链表。每个消息队列都有一个队列头，用结构struct msg_queue来描述。队列头中包含了该消息队列的大量信息，包括消息队列键值、用户ID、组ID、消息队列中消息数目等等，甚至记录了最近对消息队列读写进程的ID。读者可以访问这些信息，也可以设置其中的某些信息。 ​ ![](http://heketong.github.io/donate/消息队列结构图.png) - struct ipc_ids msg_ids是内核中记录消息队列的全局数据结构；struct msg_queue是每个消息队列的队列头 - 全局数据结构 struct ipc_ids msg_ids 可以访问到每个消息队列头的第一个成员：struct kern_ipc_perm - struct kern_ipc_perm 能够与具体的消息队列对应起来是因为在该结构中，有一个 key_t 类型成员 key，而 key 则唯一确定一个消息队列  struct kern_ipc_perm{ //内核中记录消息队列的全局数据结构msg_ids能够访问到该结构； key_t key; //该键值则唯一对应一个消息队列 uid_t uid; gid_t gid; uid_t cuid; gid_t cgid; mode_t mode; unsigned long seq; }\n - 管道中的数据没有分割为一个个独立单元 字节流上是连续的，但消息队列是数据分成了一个个独立的单元，每个独立单元称谓消息体，每一个消息体都是固定大小的存储区域，字节流上是不连续的 ### 相关API  int msgget(key_t key, int msgflg); //创建消息队列 int msgsnd(int msqid, const void *msgp, size_t msgsz, int msgflg);//发送 在发送消息的时候，是在消息体结构体中指定，当前的消息发送到消息队列集合中的哪一个消息队列上 消息体结构体中就必须包含一个 type 值，type 值是long类型，而且还必须是结构体的第一个成员。而结构体中的其他成员都被认为是要发送的消息体数据 ssize_t msgrcv(int msqid, void *msgp, size_t msgsz, long msgtyp,int msgflg);//接收\n无论是 msgsnd() 发送还是 msgrcv()接收时，只要操作系统内核发现新提供的 type 值对应的消息队列集合中的消息队列不存在，则立即为其创建该消息队列\n```\n注意事项  为了能够顺利的发送与接收，发送方与接收方需要约定规则\n 同样的消息体结构体； 发送方与接收方在发送和接收的数据块儿大小上要与消息结构体的具体数据部分保持一致， 否则将不会读出正确的数据。  如果结构体成员有指针 不会将指针指向空间中的数据发送 只是发送指针本身的值。\n 数组作为消息结构体成员是可以的 因为整个数组空间都在消息结构体中\n  Socket通信  unix域套接字 其它网络套接字  ","id":6,"section":"posts","summary":"高并发性能相关指标或术语回顾 连接相关 服务端能保持，管理，处理多少客户端的连接 活跃连接数：所有ESTABLISHED状态的TCP连接，某个瞬时","tags":["网络高并发"],"title":"网络高并发","uri":"http://heketong.github.io/2020/05/%E9%AB%98%E5%B9%B6%E5%8F%91/","year":"2020"},{"content":" 设计模式介绍 设计模式最关键的作用是为了可复用，减少开发工作量。\n模式就是针对现实世界重复出现的问题，给出核心解决方案，忽略掉一些不重要的细节。\n分解和抽象是2种解决现实问题的通用方法。\n底层思维是向下的，多数是理解计算机的，抽象是向上思维，多数是理解现实世界的。\n在现实工程开发中，要寻找需求频繁变化点，应用对应的设计模式，从而提高代码复用性，降低开发成本，测试成本。\n设计模式的应用不宜先入为主，最好是Refactoring to Patterns 也就是针对现实的痛点(变化点)，重构到设计模式\n重构的关键技巧  静态\u0026mdash;-动态 早绑定\u0026mdash;-晚绑定 继承\u0026mdash;\u0026ndash;组合 编译时依赖\u0026mdash;-运行时依赖 紧耦合\u0026mdash;-松耦合  面向对象设计原则 重新认识面向对象  理解隔离变化  宏观层面来看 面向对象的构建方式能够适应软件的变化，能将变化带来的影响减为最小\n 各司其职  微观层面来说，面向对象更强调独立的各个类\n需求变化带来的新增类 不应该改变原来类的功能，也就是每个类各司其职\n 对象到底是什么  从语言的角度来说，对象封装了代码和数据\n从规格层面来说，对象是一些列可以使用的公共接口\n从概念层面来说，对象是拥有某种责任的抽象\n1 依赖倒置原则(DIP)  高层模块(往往是稳定的)不应该依赖底层模块(往往是不停的变化的)，二者都应该依赖于抽象。\n 抽象(稳定)不应该依赖于实现细节(变化)，实现细节应该依赖于抽象(稳定)\n  2 开放封闭原则(OCP)  对于扩展是开放的，对于修改是封闭的 类模块应该是是可以扩展的，但是不能修改。  在设计之初应该考虑其扩展性，不应该因为新增一个功能，反而要更改原先的功能，应该让新增功能为扩展，不应该修改原先的代码。\n3 单一职责原则(SRP)  一个类应该仅有一个引起其变化的原因 其变化的原因 往往就是其该承担的责任。  4 Liskov替换原则(LSP)  子类必须能够替换它的父类(IS-A) 继承表达类型抽象  5 接口隔离原则(ISP)  不应该强迫客户程序依赖他们不使用的方法 接口应该小而完备  6 优先使用对象组合 而不是类继承  类继承通常是白箱复用 对象组合通常为黑箱复用 继承在某种程度上破坏了封装性，子类父类耦合度较高 对象组合只要求被组合的对象有良好的接口定义，耦合度低  7 封装变化点  使用封装来创建对象之间的分界层，让设计者可以在分界层一侧修改，不影响另外一侧，实现分层间的松耦合。\n 封装其实是封装变化点。\n  8 针对接口编程，不要针对实现编程  不将变量声明为特定的类，而是声明为接口。 客户程序不需要知道对象具体类型，只需要知道其开放的接口 减少各部分依赖关系，实现高内聚 松耦合 产业强盛 最好是接口相当标准化。  模版方法Template method\u0026mdash;组件协作 需求背景： 需要实现多个app，都需要5个操作步骤(5个步骤操作顺序也都是固定的),有3个已经有框架或者library库实现了，实现这个app\n传统结构化思想实现  结构化程序设计实现c++\n#include\u0026lt;iostream\u0026gt; using namespace std; class Library{//这里往往是库函数或者别人的实现 实现了3个方法 public: bool Step1(){ //... cout\u0026lt;\u0026lt;\u0026quot;Library::Step1()\u0026quot;\u0026lt;\u0026lt;endl; return true; } void Step3(){ cout\u0026lt;\u0026lt;\u0026quot;Library::Step3()\u0026quot;\u0026lt;\u0026lt;endl; //... } void Step5(){ cout\u0026lt;\u0026lt;\u0026quot;Library::Step5()\u0026quot;\u0026lt;\u0026lt;endl; //... } }; class App{//应用程序 实现Step2 Step4方法 这2个方法经常变化 不同的应用不一样的实现 public: void Step2(){ cout\u0026lt;\u0026lt;\u0026quot;App::Step2()\u0026quot;\u0026lt;\u0026lt;endl; //... } void Step4(){ cout\u0026lt;\u0026lt;\u0026quot;App::Step4()\u0026quot;\u0026lt;\u0026lt;endl; } }; int main(){//如果要实现另外一个程序 则需要重新再写一个main 重新写一个App类 实现Step2和Step4方法 App app; Library lib; //以下为程序实现逻辑 也就是算法框架结构 if(lib.Step1()){ app.Step2(); } lib.Step3(); for (int i=1;i\u0026lt;4;++i) { app.Step4(); } lib.Step5(); } //如果34--41的算法步骤整体是稳定的 只有Step2和Step4是经常变化的 可以考虑用TempalteMethod设计模式来实现  \n动机  某项任务 常常有稳定的整体操作结构，但是各个子步骤需要经常变化，或者由于固有的原因(框架和应用的关系)，无法和任务的整体结构同时实现 这就要思考如何确定稳定的操作结构的前提下，来灵活应对各个子步骤的变化或者晚期实现需求  模式定义  定义一个操作中的算法骨架(往往是稳定的)，将一些步骤(往往是变化了，前期确定不下来)延迟到子类中实现，Template Method使得子类可以不改变(复用)一个算法的结构即可重定义(Override重写)该算法的某些特定子步骤。  要点总结  tempalte method是一种非常基础性的设计模式 在面向对象系统中有大量的应用，机制非常简洁(虚函数的多态)，为很多应用程序的框架提供了灵活的扩展点(继承+虚函数多态度)，是代码复用的基本实现结构 不要调用我，让我来调用你 具体实现方面，被template method调用的虚方法可以有实现也可以没有实现，一般将被调用的方法设置为protectrd。因为这些被template method调用的虚方法离开了主流程往往没有意义，也不应该设置为public暴漏给外部。  几张图解 模版方法代码实现  TemplateMethod实现c++\n#include\u0026lt;iostream\u0026gt; using namespace std; class Library{ public: void run(){//template method //这里的run方法也就是所说的相对稳定的整体处理结构 Step2和Step4会根据不同的应用实现为不同的逻辑，所以声明为纯虚函数 if(Step1()){ Step2(); } Step3(); for (int i=1;i\u0026lt;4;++i) { Step4(); } Step5(); } virtual ~Library(){} protected: bool Step1(){ //... cout\u0026lt;\u0026lt;\u0026quot;Library::Step1()\u0026quot;\u0026lt;\u0026lt;endl; return true; } void Step3(){ cout\u0026lt;\u0026lt;\u0026quot;Library::Step3()\u0026quot;\u0026lt;\u0026lt;endl; //... } void Step5(){ cout\u0026lt;\u0026lt;\u0026quot;Library::Step5()\u0026quot;\u0026lt;\u0026lt;endl; //... } virtual void Step2()=0;//这里声明为纯虚函数 让子类去实现 virtual void Step4()=0; }; class App :public Library{//继承框架类 实现容易变化的2个函数 protected: void Step2(){ cout\u0026lt;\u0026lt;\u0026quot;App::Step2()\u0026quot;\u0026lt;\u0026lt;endl; //... } void Step4(){ cout\u0026lt;\u0026lt;\u0026quot;App::Step4()\u0026quot;\u0026lt;\u0026lt;endl; } }; int main(){ Library* pLib=new App(); pLib-\u0026gt;run(); delete pLib; return 0; }  \n策略模式 strategy\u0026mdash;组件协作 需求背景 需要实现一个类，计算各个国家的税，每个国家的计税算法不一样，后期可能修改或者增加一些国家的计税算法\n传统实现  结构化程序设计实现c++\n//传统解决方案 traditional solution enum TaxBase { CN_Tax, US_Tax, DE_Tax, FR_Tax //如果要增加支持法国税法就要修改 }; class SalesOrder{ TaxBase tax; public: double CalculateTax(){ //传统解决方案 直接ifelse 分而治之 需要经常修改这个函数 很可能出现引入新的需求 导致原先的实现方案引入bug if (tax == CN_Tax){ //CN*********** } else if (tax == US_Tax){ //US*********** } else if (tax == DE_Tax){ //DE*********** } else if (tax == FR_Tax){ //如果要增加支持法国税法就要修改 这个地方违背了开闭原则(用扩展的方式支持修改 而不是直接修改) //经验告诉我们，直接修改的方式 也比较容易引入bug } } };  \n动机  如果现实软件开发过程中，某一个对象使用了多种算法，而且这些算法可能经常改变，或者经常需要新增类似算法(比如计算不同国家的税)，这个时候如果将这些算法全部编码到对象中，这个对象就会变的非常复杂，容易出错，策略模式可以解决问题 更直观点 如果使用了大量if else或者switch case，而且不稳定，经常变化，就可以考虑用strategy模式改造 要考虑使用多态机制在运行时动态的使用相应的算法解决问题  模式的定义  定义一系列算法(动机章节提到的经常变化的算法)，把它们一个个封装起来(不同的子类)，并且使它们可互相替换(变化)\u0026ndash;(使用多态运行时决定使用哪种算法)。该模式使得算法可独立于使用它的客户程序(稳定)而变化(扩展，子类化)。——《设计模式》GoF  要点总结  Strategy及其子类为组件提供了一系列可重用的算法，从而可以使得类型在运行时方便地根据需要在各个算法之间进行切换(多态)。\n Strategy模式提供了用条件判断语句以外的另一种选择，消除条件判断语句，就是在解耦合。含有许多条件判断语句的代码通常都需 要Strategy模式。\n 如果Strategy对象没有实例变量，那么各个上下文可以共享同一个 Strategy对象，从而节省对象开销\n  图解 策略模式代码实现  策略模式实现c++\n//策略模式 class Context{}; class TaxStrategy{//策略类基类 public: virtual double Calculate(const Context\u0026amp; context)=0;//纯虚函数 不同的算法抽象 运行时调用相应的算法 virtual ~TaxStrategy(){} }; class StrategyFactory{//工厂类 根据现实情况生成不同的子类，解决想要的问题 public: TaxStrategy* NewStrategy(){ return nullptr;} }; class CNTax : public TaxStrategy{//子类 继承策略基类 实现虚方法 用于多态 public: virtual double Calculate(const Context\u0026amp; context){ //*********** } }; class USTax : public TaxStrategy{ public: virtual double Calculate(const Context\u0026amp; context){ //*********** } }; class DETax : public TaxStrategy{ public: virtual double Calculate(const Context\u0026amp; context){ //*********** } }; //这里如果新增一个法国的，就是扩展的方式支持 class FRTax : public TaxStrategy{ public: virtual double Calculate(const Context\u0026amp; context){ //......... } }; class SalesOrder{ private: TaxStrategy* strategy; public: SalesOrder(StrategyFactory* strategyFactory){ this-\u0026gt;strategy = strategyFactory-\u0026gt;NewStrategy(); } ~SalesOrder(){ delete this-\u0026gt;strategy; } double CalculateTax(){ //... Context context; double val = strategy-\u0026gt;Calculate(context); //多态调用 //... } };  \n观察者模式Observer\u0026mdash;组件协作 需求背景 需要实现一个文件分割业务，同时需要显示进度条，也就是文件分割时候达到一定状态需要通知某个类，后续很有可能还有通知多个类\n传统实现  传统解决方案\n//traditional solution传统解决方案 //分割大文件，显示或者打印处理进度 #include\u0026lt;string\u0026gt; #include\u0026lt;iostream\u0026gt; #include \u0026quot;common.h\u0026quot; using namespace std; class FileSplitter//该类是被依赖的对象，状态发生变化需要通知ProgressBar { string m_filePath; int m_fileNumber; ProgressBar* m_progressBar;//该类负责收到通知更新进度条 //如果要新增其它观察者，这里需要新增具体的实现类指针 ProgressBar1* 比较麻烦，这个业务类也要频繁改变 public: FileSplitter(const string\u0026amp; filePath, int fileNumber, ProgressBar* progressBar) : m_filePath(filePath), m_fileNumber(fileNumber), m_progressBar(progressBar){ } void split(){ //1.读取大文件 //2.分批次向小文件中写入 for (int i = 0; i \u0026lt; m_fileNumber; i++){ //... float progressValue = m_fileNumber; progressValue = (i + 1) / progressValue; m_progressBar-\u0026gt;setValue(progressValue); //从编译层面如果ProgressBar发生变化 也就是观察者发生变化，FileSplitter类也需要变化 重新编译 //从业务发展来看，如果需要新增观察者也是比较麻烦的 //这个违背了依赖倒置原则，高层模块不应该依赖此层模块变化，FileSplitter不应该依赖ProgressBar //个人觉得也违背了开闭原则，要用扩展的方式支持新增，不应该直接修改 } } }; //traditional solution传统解决方案 //分割大文件，显示或者打印处理进度 #include \u0026quot;common.h\u0026quot; class MainForm : public Form { TextBox* txtFilePath; TextBox* txtFileNumber; ProgressBar* progressBar; public: void Button1_Click(){ string filePath = txtFilePath-\u0026gt;getText(); int number = atoi(txtFileNumber-\u0026gt;getText().c_str()); FileSplitter splitter(filePath, number, progressBar); //从业务发展来看，如果需要新增观察者也是比较麻烦的 需要修改FileSplitter 构造方法，传入新增的观察者类指针 //也需要修改FileSplitter通知逻辑 增加对新增观察者的处理 splitter.split(); } };  \n动机  我们要为某些对象之间建立\u0026rdquo;通知依赖关系\u0026rdquo;，也就是一个对象状态发生变更，需要自动通知其它依赖与它的对象。如果这种依赖关系过于紧密，将使软件不能很好的抵御变化。\n 可以使用面向对象技术，将这种依赖关系弱化，形成一种较为稳定的依赖关系，从而实现松耦合。\n 大致实现，被依赖的对象需要包含一个集合(链表或者数组都可以),集合保存的是抽象接口基类(观察者的基类指针)，当自己状态变化的时候遍历集合，调用抽象接口基类的通知函数(多态实现运行时调用多个观察者的相应处理函数)。\n  模式的定义  定义对象见的一对多(变化也就是观察者)的依赖关系，以便当被依赖对象(Subject)的状态发生变化时，所有依赖与它的对象(观察者)都能得到通知并且自动更新  结构图解 要点总结  使用Observer观察者模式可以独立的改变目标和观察者，实现松耦合 目标发送通知的时候，无需指定具体的观察者，通知(也可以写态通知信息作为参数)会自动传播 观察者自己决定是否需要订阅通知，如果需要请调用Subject的添加观察者API，目标对象对此可以是透明的 当听到状态变更需要通知多个对象的场景就往往可以考虑Observer观察者模式了 Observer模式是基于事件的UI框架中非常常用的模式，也是MVC模式的一个重要组成部分  观察者模式代码实现  Observer观察者模式实现\n#include\u0026lt;string\u0026gt; #include\u0026lt;iostream\u0026gt; #include \u0026lt;list\u0026gt; using namespace std; class IProgress{//观察者抽象基类 public: virtual void DoProgress(float value)=0;//观察者需要实现的函数(收到通知后被调用) virtual ~IProgress(){} }; class FileSplitter { string m_filePath; int m_fileNumber; list\u0026lt;IProgress*\u0026gt; m_iprogressList; // 抽象通知机制，支持多个观察者 //这种机制就不再依赖具体的观察者 保证FileSplitter类处理逻辑相对稳定 public: FileSplitter(const string\u0026amp; filePath, int fileNumber) : m_filePath(filePath), m_fileNumber(fileNumber){ } void split(){ //1.读取大文件 //2.分批次向小文件中写入 for (int i = 0; i \u0026lt; m_fileNumber; i++){ //... float progressValue = m_fileNumber; progressValue = (i + 1) / progressValue; onProgress(progressValue);//发送通知 } } void addIProgress(IProgress* iprogress){//增加观察者API m_iprogressList.push_back(iprogress); } void removeIProgress(IProgress* iprogress){//移除观察者API m_iprogressList.remove(iprogress); } protected: virtual void onProgress(float value){//通知函数 list\u0026lt;IProgress*\u0026gt;::iterator itor=m_iprogressList.begin(); while (itor != m_iprogressList.end() ){ (*itor)-\u0026gt;DoProgress(value); //更新进度条 虚函数多态调用多个观察者的处理函数 itor++; } } }; #include \u0026quot;common.h\u0026quot; #include\u0026lt;string\u0026gt; using namespace std; class MainForm : public Form, public IProgress { TextBox* txtFilePath; TextBox* txtFileNumber; ProgressBar* progressBar; public: void Button1_Click(){ string filePath = txtFilePath-\u0026gt;getText(); int number = atoi(txtFileNumber-\u0026gt;getText().c_str()); ConsoleNotifier cn; FileSplitter splitter(filePath, number); splitter.addIProgress(this); //订阅通知 splitter.addIProgress(\u0026amp;cn)； //订阅通知 splitter.split(); splitter.removeIProgress(this); } virtual void DoProgress(float value){ progressBar-\u0026gt;setValue(value); } }; class ConsoleNotifier : public IProgress { public: virtual void DoProgress(float value){ cout \u0026lt;\u0026lt; \u0026quot;.\u0026quot;; } };  \n装饰模式Decorator\u0026mdash;单一职责 需求背景 需要实现文件流操作简易系统，支持的操作大概就多些 read seek write，存在普通文件流，网络流，内存流等等\n随着系统的发展，需要增加各种流的加密功能\n随着系统的发展，需要增加各种流的缓存功能\n随着系统的发展，需要增加各种流的加密同时缓存功能\n传统实现  传统解决方案，大量使用继承\n//业务操作 class Stream{//流操作基类，定义相关接口虚函数 public: virtual char Read(int number)=0; virtual void Seek(int position)=0; virtual void Write(char data)=0; virtual ~Stream(){} }; //文件流操作主体类 应该继承Stream基类 class FileStream: public Stream{ public: virtual char Read(int number){ //读文件流 } virtual void Seek(int position){ //定位文件流 } virtual void Write(char data){ //写文件流 } }; //网络流操作类 应该继承Stream基类 class NetworkStream :public Stream{ public: virtual char Read(int number){ //读网络流 } virtual void Seek(int position){ //定位网络流 } virtual void Write(char data){ //写网络流 } }; //内存流操作类 应该继承Stream基类 class MemoryStream :public Stream{ public: virtual char Read(int number){ //读内存流 } virtual void Seek(int position){ //定位内存流 } virtual void Write(char data){ //写内存流 } }; //扩展加密的功能 传统方案新增多个类 分别继承文件流、网络流、内存流操作类 大量子类生成 class CryptoFileStream :public FileStream{ public: virtual char Read(int number){ //额外的加密操作... 跟网络流、内存流代码存在大量重复 FileStream::Read(number);//读文件流 } virtual void Seek(int position){ //额外的加密操作... 跟网络流、内存流代码存在大量重复 FileStream::Seek(position);//定位文件流 //额外的加密操作... } virtual void Write(byte data){ //额外的加密操作... FileStream::Write(data);//写文件流 //额外的加密操作... } }; //扩展加密的功能 传统方案新增多个类 分别继承文件流、网络流、内存流操作类 class CryptoNetworkStream :public NetworkStream{ public: virtual char Read(int number){ //额外的加密操作... NetworkStream::Read(number);//读网络流 } virtual void Seek(int position){ //额外的加密操作... NetworkStream::Seek(position);//定位网络流 //额外的加密操作... } virtual void Write(byte data){ //额外的加密操作... NetworkStream::Write(data);//写网络流 //额外的加密操作... } }; //扩展加密的功能 传统方案新增多个类 分别继承文件流、网络流、内存流操作类 class CryptoMemoryStream : public MemoryStream{ public: virtual char Read(int number){ //额外的加密操作... MemoryStream::Read(number);//读内存流 } virtual void Seek(int position){ //额外的加密操作... MemoryStream::Seek(position);//定位内存流 //额外的加密操作... } virtual void Write(byte data){ //额外的加密操作... MemoryStream::Write(data);//写内存流 //额外的加密操作... } }; //扩展缓存的功能 传统方案新增多个类 分别继承文件流、网络流、内存流操作类 class BufferedFileStream : public FileStream{ //额外的缓存操作... 跟网络流、内存流代码存在大量重复 }; class BufferedNetworkStream : public NetworkStream{ //... }; class BufferedMemoryStream : public MemoryStream{ //... } //扩展加密+缓存组合的的功能 传统方案新增多个类 分别继承文件流、网络流、内存流操作类 class CryptoBufferedFileStream :public FileStream{ public: virtual char Read(int number){ //代码大量重复 生成大量子类 扩展一个功能非常不灵活，增加维护成本 FileStream::Read(number);//读文件流 } virtual void Seek(int position){ //额外的加密操作... //额外的缓冲操作... FileStream::Seek(position);//定位文件流 //额外的加密操作... //额外的缓冲操作... } virtual void Write(byte data){ //额外的加密操作... //额外的缓冲操作... FileStream::Write(data);//写文件流 //额外的加密操作... //额外的缓冲操作... } }; void Process(){ //编译时装配 也就是在编译的时候已经决定了要使用哪种扩展功能对应的子类 CryptoFileStream *fs1 = new CryptoFileStream(); BufferedFileStream *fs2 = new BufferedFileStream(); CryptoBufferedFileStream *fs3 =new CryptoBufferedFileStream(); }  \n动机  滥用继承来扩展对象的功能，由于继承为类型引入的静态特质，导致这种扩展方式变得非常不灵活，而且如果扩展的功能很多或者需要组合，将会产生大量的子类，对项目的维护成本大幅度增加。  模式的定义  不使用继承，改用组合的方式动态的给对象增加一些扩展功能。对于新增扩展功能而言，Decorator装饰模式比滥用继承的方式更加灵活(因为可以消除大量的重复代码同时减少子类的数量，减少维护的成本)  结构图解 要点总结  采用组合而不是继承的方式，Decorator装饰模式实现了在运行时动态扩展对象功能的能力，而且可以根据需要扩展多个功能，避免了大量的重复代码，同时大量的子类产生的问题 装饰类在接口上变现为is-a关系，也就是继承业务操作组件基类，但在实现上又是has-a组合的关系，成员拥有业务操作组件基类指针，在运行时动态的传入不同类别的业务操作子类，来实现相应操作，同时扩展功能 Decorator装饰模式的目的并不是解决“多子类衍生的多继承问题”，重要是在解决“主体类在多个方向上的扩展问题”  简易代码  Decorator装饰模式改造\n//业务操作 class Stream{//流操作基类，定义相关接口虚函数 public： virtual char Read(int number)=0; virtual void Seek(int position)=0; virtual void Write(char data)=0; virtual ~Stream(){} }; //文件流操作主体类 应该继承Stream基类 class FileStream: public Stream{ public: virtual char Read(int number){ //读文件流 } virtual void Seek(int position){ //定位文件流 } virtual void Write(char data){ //写文件流 } }; //网络流操作类 应该继承Stream基类 class NetworkStream :public Stream{ public: virtual char Read(int number){ //读网络流 } virtual void Seek(int position){ //定位网络流 } virtual void Write(char data){ //写网络流 } }; //内存流操作类 应该继承Stream基类 class MemoryStream :public Stream{ public: virtual char Read(int number){ //读内存流 } virtual void Seek(int position){ //定位内存流 } virtual void Write(char data){ //写内存流 } }; //扩展功能装饰基类 DecoratorStream: public Stream{//继承业务组件操作基类 主要是用于实现相关接口 protected: Stream* stream;//保存业务组件操作基类指针，运行时动态的传入相应的业务操作主体子类实现相关操作并扩展功能 DecoratorStream(Stream * stm):stream(stm){ } }; //加密扩展功能 class CryptoStream: public DecoratorStream {//继承装饰基类 public: CryptoStream(Stream* stm):DecoratorStream(stm){ } virtual char Read(int number){ //额外的加密操作... stream-\u0026gt;Read(number);//这里会多态的调用不同的流操作(文件、网络、内存) 没有重复代码 } virtual void Seek(int position){ //额外的加密操作... stream::Seek(position);//这里会多态的调用不同的流操作(文件、网络、内存)没有重复代码 //额外的加密操作... } virtual void Write(byte data){ //额外的加密操作... stream::Write(data);//这里会多态的调用不同的流操作(文件、网络、内存)没有重复代码 //额外的加密操作... } }; //不同流操作增加缓存功能 跟增加加密功能一样 只生成了一个类 同时在运行时多态的调用不同的流操作(文件、网络、内存)没有重复代码 class BufferedStream : public DecoratorStream{ Stream* stream;//... public: BufferedStream(Stream* stm):DecoratorStream(stm){ } //... }; void Process(){ //运行时装配 FileStream* s1=new FileStream(); //这里s1可以动态的传入文件流、网络流、内存流，来实现不同类别流操作的加密扩展 CryptoStream* s2=new CryptoStream(s1); //这里s1可以动态的传入文件流、网络流、内存流，来实现不同类别流操作的缓存扩展 BufferedStream* s3=new BufferedStream(s1); //这里s2可以动态的传入文件流、网络流、内存流，来实现不同类别流操作的加密缓存扩展 BufferedStream* s4=new BufferedStream(s2); }  \n桥模式Bridge\u0026mdash;单一职责 需求背景 需要实现多平台(pc、mobile、pad，tv)等等，这个是一个纬度，同时也要发布一个经典轻量版本和完美复杂版本(比如发文字消息的时候也播放声音)，这又是一个纬度的变化 下面看看经典的实现\n传统实现  传统解决方案\nclass Messager{ public: //下面是三个通用接口方法 virtual void Login(string username, string password)=0; virtual void SendMessage(string message)=0; virtual void SendPicture(Image image)=0; //下面是涉及不同的平台需要实现不同的方法 PlaySound方法只有完美版用到 virtual void PlaySound()=0; virtual void DrawShape()=0; virtual void WriteText()=0; virtual void Connect()=0; virtual ~Messager(){} }; //PC平台实现 class PCMessagerBase : public Messager{ public: virtual void PlaySound(){ //********** } virtual void DrawShape(){ //********** } virtual void WriteText(){ //********** } virtual void Connect(){ //********** } }; //手机平台实现 class MobileMessagerBase : public Messager{ public: virtual void PlaySound(){ //========== } virtual void DrawShape(){ //========== } virtual void WriteText(){ //========== } virtual void Connect(){ //========== } }; //业务抽象 经典轻量发布版本 本身是业务抽象纬度，但因为另外一个纬度也要变化(平台纬度) 所以经典发布版本也要有多个平台类的实现 class PCMessagerLite : public PCMessagerBase { public: virtual void Login(string username, string password){ PCMessagerBase::Connect(); //........ } virtual void SendMessage(string message){ PCMessagerBase::WriteText(); //........ } virtual void SendPicture(Image image){ PCMessagerBase::DrawShape(); //........ } }; //业务抽象 完美复杂版本 本身是业务抽象纬度，但因为另外一个纬度也要变化(平台纬度) 所以完美复杂版本也要有多个平台类的实现 class PCMessagerPerfect : public PCMessagerBase { public: virtual void Login(string username, string password){ PCMessagerBase::PlaySound(); //******** PCMessagerBase::Connect(); //........ } virtual void SendMessage(string message){ PCMessagerBase::PlaySound(); //******** PCMessagerBase::WriteText(); //........ } virtual void SendPicture(Image image){ PCMessagerBase::PlaySound(); //******** PCMessagerBase::DrawShape(); //........ } }; // class MobileMessagerLite : public MobileMessagerBase { public: virtual void Login(string username, string password){ MobileMessagerBase::Connect(); //........ } virtual void SendMessage(string message){ MobileMessagerBase::WriteText(); //........ } virtual void SendPicture(Image image){ MobileMessagerBase::DrawShape(); //........ } }; //业务抽象 经典轻量发布版本 本身是业务抽象纬度，但因为另外一个纬度也要变化(平台纬度) 所以经典发布版本也要有多个平台类的实现 //这里是手机平台实现 跟pc平台存在大量类似重复代码 class MobileMessagerPerfect : public MobileMessagerBase { public: virtual void Login(string username, string password){ MobileMessagerBase::PlaySound(); //******** MobileMessagerBase::Connect(); //........ } virtual void SendMessage(string message){ MobileMessagerBase::PlaySound(); //******** MobileMessagerBase::WriteText(); //........ } virtual void SendPicture(Image image){ MobileMessagerBase::PlaySound(); //******** MobileMessagerBase::DrawShape(); //........ } }; //实际调用 void Process(){ //编译时装配 需要指定不同平台的不用业务抽象 比如手机平台经典版本 手机平台完美版本等等 //所以这里如有一个纬度变化--业务抽象有M个(经典版本、完美版本...),另外一个纬度变化平台实现有N个(pc、mobile、pad、tv...) //那么类至少需要1(messager)+N(平台实现基类)+M*N(最终用于用于发布的类 比如下面的手机平台完美版本类) Messager *m =new MobileMessagerPerfect(); }  \n动机 某些类型的固有实现逻辑，使得它们有2个纬度的变化，或者多个纬度的变化\n 所以要利用面向对象技术使得类型可以轻松的沿着2个或者多个方向变化\n 假设需要实现一个发消息的业务，大致有三个方法login登录，sendMessage发文字消息 sendPicture发图片\n  模式定义  将抽象部分(业务功能)与实现部分(平台实现)分离，使它们 都可以独立地变化  结构图解 要点总结  Bridge模式使用“对象间的组合关系”解耦了抽象和实现之间固有的绑定关系，使得抽象和实现可以沿着各自的维度来变化。所谓 抽象和实现沿着各自纬度的变化，即“子类化”它们。\n Bridge模式有时候类似于多继承方案，但是多继承方案往往违背 单一职责原则(即一个类只有一个变化的原因)，复用性比较差。 Bridge模式是比多继承方案更好的解决方法。\n Bridge模式的应用一般在“两个非常强的变化维度”，有时一个 类也有多于两个的变化维度，这时可以使用Bridge的扩展模式\n  代码实现  Bridge桥模式实现c++\n//业务抽象基类 定义相关接口方法 class Messager{ protected: MessagerImp* messagerImp;//用于平台实现基类指针 在平台切换方面可以运行时灵活变化 public: virtual void Login(string username, string password)=0; virtual void SendMessage(string message)=0; virtual void SendPicture(Image image)=0; virtual ~Messager(){} }; //平台实现基类 定义相关接口方法 class MessagerImp{ public: virtual void PlaySound()=0; virtual void DrawShape()=0; virtual void WriteText()=0; virtual void Connect()=0; virtual MessagerImp(){} }; //不同平台实现子类 这里是pc class PCMessagerImp : public MessagerImp{ public: virtual void PlaySound(){ //********** } virtual void DrawShape(){ //********** } virtual void WriteText(){ //********** } virtual void Connect(){ //********** } }; //不同平台实现子类 这里是mobile class MobileMessagerImp : public MessagerImp{ public: virtual void PlaySound(){ //========== } virtual void DrawShape(){ //========== } virtual void WriteText(){ //========== } virtual void Connect(){ //========== } }; //业务抽象子类实现 这里是经典版本 class MessagerLite :public Messager { public: virtual void Login(string username, string password){ messagerImp-\u0026gt;Connect();//通过基类拥有的平台实现基类指针 在不同平台间灵活切换 //........ } virtual void SendMessage(string message){ messagerImp-\u0026gt;WriteText(); //........ } virtual void SendPicture(Image image){ messagerImp-\u0026gt;DrawShape(); //........ } }; //业务抽象子类实现 这里是完美版本 class MessagerPerfect :public Messager { public: virtual void Login(string username, string password){ messagerImp-\u0026gt;PlaySound();//通过基类拥有的平台实现基类指针 在不同平台间灵活切换 //******** messagerImp-\u0026gt;Connect(); //........ } virtual void SendMessage(string message){ messagerImp-\u0026gt;PlaySound(); //******** messagerImp-\u0026gt;WriteText(); //........ } virtual void SendPicture(Image image){ messagerImp-\u0026gt;PlaySound(); //******** messagerImp-\u0026gt;DrawShape(); //........ } }; void Process(){ //运行时装配 类的数量大幅减少 但是实现并没有打折扣，这里在运行是初始化想要的平台实现子类就可以动态灵活变化 MessagerImp* mImp=new PCMessagerImp(); Messager *m =new MessagerPerfect(mImp);//传入pc平台子类 实现pc完美版本 }  \n工厂模式factory\u0026mdash;对象创建 需求背景 我们需要实现一个文件分割器，支持分割多种类型文件(文本文件、普通二进制文件、图片、视频等等)，所以我们就要根据需求创建对象\n传统实现  传统解决方案c++\n//文件分割基类 文件分割实现 class ISplitter{ public: virtual void split()=0; virtual ~ISplitter(){} }; //文件分割子类 二进制文件、文本文件、图片、视频 class BinarySplitter : public ISplitter{ }; class TxtSplitter: public ISplitter{ }; class PictureSplitter: public ISplitter{ }; class VideoSplitter: public ISplitter{ }; // --------------- //高层调用模块 class MainForm : public Form { public: void Button1_Click(){ ISplitter * splitter=new BinarySplitter(); //依赖具体类 违反了依赖倒置原则 高层稳定模块应该依赖抽象而不应该依赖具体的实现类 //这里的依赖为编译时依赖 具体的实现类可能反复变化就会导致高层模块也需要跟着编译甚至修改 splitter-\u0026gt;split(); } };  \n动机  在软件系统中，经常面临着创建对象的工作;由于需求的变化， 需要创建的对象的具体类型经常变化 因为直接new会依赖具体的实现类 所以要想办法绕过new 运行时动态的new出相应的类 一般是接口抽象之后的第一步工作  模式定义  定义一个用于创建对象的接口，让子类决定实例化哪一个类。 Factory Method使得一个类的实例化延迟(目的:解耦， 手段:虚函数)到子类  工厂模式代码实现  factory工厂模式优化c++\n//业务抽象基类 与工厂抽象基类可以放在一起 class ISplitter{ public: virtual void split()=0; virtual ~ISplitter(){} }; //工厂抽象基类 class SplitterFactory{ public: virtual ISplitter* CreateSplitter()=0; virtual ~SplitterFactory(){} }; //------------------------------ //高层调用模块 class MainForm : public Form { SplitterFactory* factory;//工厂抽象基类 public: MainForm(SplitterFactory* factory){//通过构造方法 让更高层实际使用者 传入具体的工厂子类 this-\u0026gt;factory=factory; } void Button1_Click(){ ISplitter * splitter= factory-\u0026gt;CreateSplitter(); //多态new 通过具体的工厂子类实例化具体的业务子类 这里不再依赖具体的业务子类 依赖的是工厂基类 具体的工厂子类变化或者业务处理子类变化对这个类没有编译时的影响，相对稳定，变化少一般问题也少，有变化就带来了测试工作量 splitter-\u0026gt;split(); } }; //------------------------------------- //具体实现类和工厂子类放到同一个文件 class BinarySplitter : public ISplitter{ }; class TxtSplitter: public ISplitter{ }; class PictureSplitter: public ISplitter{ }; class VideoSplitter: public ISplitter{ }; //具体工厂子类 负责创建具体的业务处理子类 class BinarySplitterFactory: public SplitterFactory{ public: virtual ISplitter* CreateSplitter(){ return new BinarySplitter(); } }; class TxtSplitterFactory: public SplitterFactory{ public: virtual ISplitter* CreateSplitter(){ return new TxtSplitter(); } }; class PictureSplitterFactory: public SplitterFactory{ public: virtual ISplitter* CreateSplitter(){ return new PictureSplitter(); } }; class VideoSplitterFactory: public SplitterFactory{ public: virtual ISplitter* CreateSplitter(){ return new VideoSplitter(); } };  \n结构图解 要点总结  Factory Method模式用于隔离类对象的使用者和具体类型之间的 耦合关系。面对一个经常变化的具体类型，紧耦合关系(new)会导 致软件的脆弱。\n Factory Method模式通过面向对象的手法，将所要创建的具体对 象工作延迟到子类，从而实现一种扩展(而非更改)的策略，较好 地解决了这种紧耦合关系，只需要增加相应的业务子类和对应的工厂子类 使用者MainFrom无需更改\n Factory Method模式解决“单个对象”的需求变化。缺点在于要 求创建方法/参数相同。\n  抽象工厂AbstractFactory\u0026mdash;对象创建 需求背景 需要写一个Dao数据访问层，刚开始只有oracle，后面要支持mysql，sqlserver db2等等,每个数据库系列都有相关的多个对象(connection、command、dataReader\u0026hellip;)，这些对象时相关的，有依赖的，不能传一个oracle的connection给mysql的command\n传统解决方案  传统解决方案\nclass EmployeeDAO{ public: vector\u0026lt;EmployeeDO\u0026gt; GetEmployees(){ //刚开始只有一种数据库 后面可能要新增其它数据库 所以这里可能会写成if else来创建对象 给个入参来判断不同的类型 //这就是依赖了底层具体的对象 违反了依赖倒置原则DIP 应该依赖抽象 SqlConnection* connection = new SqlConnection(); connection-\u0026gt;ConnectionString = \u0026quot;...\u0026quot;; SqlCommand* command = new SqlCommand(); command-\u0026gt;CommandText=\u0026quot;...\u0026quot;; command-\u0026gt;SetConnection(connection); SqlDataReader* reader = command-\u0026gt;ExecuteReader(); while (reader-\u0026gt;Read()){ } } };  \n用原始工厂方法模式改造  原始工厂方法改造\n//数据库访问有关的基类 class IDBConnection{ }; class IDBConnectionFactory{ public: virtual IDBConnection* CreateDBConnection()=0; }; class IDBCommand{ }; class IDBCommandFactory{ public: virtual IDBCommand* CreateDBCommand()=0; }; class IDataReader{ }; class IDataReaderFactory{ public: virtual IDataReader* CreateDataReader()=0; }; //支持SQL Server class SqlConnection: public IDBConnection{ }; class SqlConnectionFactory:public IDBConnectionFactory{ }; class SqlCommand: public IDBCommand{ }; class SqlCommandFactory:public IDBCommandFactory{ }; class SqlDataReader: public IDataReader{ }; class SqlDataReaderFactory:public IDataReaderFactory{ }; //支持Oracle class OracleConnection: public IDBConnection{ }; class OracleCommand: public IDBCommand{ }; class OracleDataReader: public IDataReader{ }; //如果系列对象(有相关性的多个对象)有3个 使用者就拥有3个对应的工厂基类对象指针 class EmployeeDAO{ IDBConnectionFactory* dbConnectionFactory; IDBCommandFactory* dbCommandFactory; IDataReaderFactory* dataReaderFactory; public: vector\u0026lt;EmployeeDO\u0026gt; GetEmployees(){ IDBConnection* connection = dbConnectionFactory-\u0026gt;CreateDBConnection(); connection-\u0026gt;ConnectionString(\u0026quot;...\u0026quot;); IDBCommand* command = dbCommandFactory-\u0026gt;CreateDBCommand(); command-\u0026gt;CommandText(\u0026quot;...\u0026quot;); command-\u0026gt;SetConnection(connection); //关联性 //这里没法保证传给oracle的command的connection是mysql类型的工厂初始化的 这个时候就会出现错误 IDBDataReader* reader = command-\u0026gt;ExecuteReader(); //关联性 while (reader-\u0026gt;Read()){ } } };  \n因为系列对象彼此间有相关性，会产生依赖，所以直接多个工厂基类的方法，无法建立其相关性，拿这里的例子来说，法保证传给oracle的command的connection是mysql类型的工厂初始化的 这个时候就会出现错误。\n动机  在软件系统中，经常面临着“一系列相互依赖的对象”的创建工 作;同时，由于需求的变化，往往存在更多系列对象的创建工作  模式定义  供一个接口，让该接口负责创建一系列“相关或者相互依 赖的对象”，无需指定它们具体的类  结构图解 要点总结  如果没有应对“多系列对象构建”的需求变化，则没有必要使用 Abstract Factory模式，这时候使用简单的工厂完全可以。\n “系列对象”指的是在某一特定系列下的对象之间有相互依赖、 或作用的关系。不同系列的对象之间不能相互依赖。\n Abstract Factory模式主要在于应对“新系列”的需求变动。其缺 点在于难以应对“新对象”的需求变动\n  代码实现  抽象工厂代码实现c++\n//数据库访问有关的基类 class IDBConnection{ }; class IDBCommand{ }; class IDataReader{ }; //支持SQL Server class SqlConnection: public IDBConnection{ }; class SqlCommand: public IDBCommand{ }; class SqlDataReader: public IDataReader{ }; class SqlDBFactory:public IDBFactory{ public: virtual IDBConnection* CreateDBConnection()=0; virtual IDBCommand* CreateDBCommand()=0; virtual IDataReader* CreateDataReader()=0; }; class IDBFactory{ public: virtual IDBConnection* CreateDBConnection()=0; virtual IDBCommand* CreateDBCommand()=0; virtual IDataReader* CreateDataReader()=0; }; //支持Oracle 类似操作 增加相关类即可 class OracleConnection: public IDBConnection{ }; class OracleCommand: public IDBCommand{ }; class OracleDataReader: public IDataReader{ }; class EmployeeDAO{ IDBFactory* dbFactory; public: vector\u0026lt;EmployeeDO\u0026gt; GetEmployees(){ IDBConnection* connection = dbFactory-\u0026gt;CreateDBConnection(); connection-\u0026gt;ConnectionString(\u0026quot;...\u0026quot;); IDBCommand* command = dbFactory-\u0026gt;CreateDBCommand(); command-\u0026gt;CommandText(\u0026quot;...\u0026quot;); command-\u0026gt;SetConnection(connection); //关联性解决了多对象之间的依赖关系 因为是同一个工厂创建的 IDBDataReader* reader = command-\u0026gt;ExecuteReader(); //关联性 while (reader-\u0026gt;Read()){ } } };  \n原型模式 prototype\u0026mdash;对象创建 需求背景及动机 ​ 如果需要初始化一个比较复杂的对象，这个对象刚开始初始化的状态不是你想要的状态，这个时候用原始工厂模式初始化就比较尴尬了，或者更直白的说就是需要一个对象运行一段时间后，达到了某种状态后，我才要这个对象去做一些处理，就可以用原型模式，用拷贝对象的方式创建一个对象。\n​ 如果创建对象只是非常简单原始的new即可，那原始工厂模式足够了，如果在最开始很难创建出来或者你希望对象运行到一定状态后要保留这个状态就可以考虑原型模式\n模式定义 使用原型实例指定创建对象的种类，然后通过拷贝这些原型来创建新的对象，达到保存某种状态的目的。\n是专门用来初始化相对很复杂的对象的时候用的，是工厂模式的变形。\n现实项目用的不多\n结构图解 要点总结  同样用于隔离类对象的使用者和具体类型(易变类)之间的耦合关系，同样要求这些“易变类”拥有“稳定的接口” 使用原型克隆的方法来实现创建一个包含有中间状态的对象 Clone方法要是深拷贝 c++可以用拷贝构造函数实现  代码实现 对比工厂模式看  原型模式Prototype c++\n//原型基类包含克隆具体子类的虚函数 也包括其它一些业务函数 class ISplitter{ public: virtual void split()=0;//实际业务虚函数 virtual ISplitter* clone()=0; //通过克隆自己来创建对象 virtual ~ISplitter(){} }; //具体的业务子类 继承原型基类 要实现clone自己的虚函数 class BinarySplitter : public ISplitter{ public: virtual ISplitter* clone(){ return new BinarySplitter(*this); } }; class TxtSplitter: public ISplitter{ public: virtual ISplitter* clone(){ return new TxtSplitter(*this); } }; class PictureSplitter: public ISplitter{ public: virtual ISplitter* clone(){ return new PictureSplitter(*this); } }; class VideoSplitter: public ISplitter{ public: virtual ISplitter* clone(){ return new VideoSplitter(*this); } }; //使用者----------------- class MainForm : public Form{ ISplitter* prototype;//原型基类指针 public: MainForm(ISplitter* prototype){ this-\u0026gt;prototype=prototype;//传入含有中间状态的子类对象(或者本身很难初始化完全) } void Button1_Click(){ ISplitter * splitter= prototype-\u0026gt;clone(); //克隆原型 深拷贝一个已经运行了一段时间的对象 保存其中间状态 splitter-\u0026gt;split(); } };  \n构建器模式Builder\u0026mdash;对象创建 需求背景 //支持建不同房子 都需要几个共同的步骤，但是不同房子每个步骤实现不一样\n//我们可以将这些稳定的步骤抽象出来，下面的init函数就是这样\n传统实现  传统解决方案\n//支持建不同房子 都需要几个共同的步骤，但是不同房子每个步骤实现不一样 //我们可以将这些稳定的步骤抽象出来，下面的init函数就是这样 class House{ public: void init(){ this-\u0026gt;BuildPart1(); for (int i = 0; i \u0026lt; 4; i++){ this-\u0026gt;BuildPart2(); } bool flag=this-\u0026gt;BuildPart3(); if(flag){ this-\u0026gt;BuildPart4(); } this-\u0026gt;BuildPart5(); } virtual ~House(){} protected: virtual void BuildPart1()=0; virtual void BuildPart2()=0; virtual bool BuildPart3()=0; virtual void BuildPart4()=0; virtual void BuildPart5()=0; //.... }; // 建造石头房子 override5个建造房子的步骤 class StoneHouse: public House{ protected: virtual void BuildPart1(){} virtual void BuildPart2(){} virtual bool BuildPart3(){} virtual void BuildPart4(){} virtual void BuildPart5(){} }; int main(){ House *p=new StoneHouse(); p-\u0026gt;init(); //p的其它操作 }  \n传统解决方案，将构建房子的方法都写到房子类本身中，如果构建房子的方法经常改变，那么我们就应该将构建部分拆分出去，否则修改原先的代码很有可能导致房子本身除了构建的其它逻辑出现bug。\n有时候构建一个对象需要的传入大量的参数，然后又要执行很复杂的多个方法调用，而且还经常变化，这个时候应该改考虑将构建对象的工作单独拆分出去。\n动机 软件系统中，有时候面临着“一个复杂对象”的创建工作，其 通常由各个部分的子对象用一定的算法构成;由于需求的变化，这 个复杂对象的各个部分经常面临着剧烈的变化，但是将它们组合在 一起的算法却相对稳定\n比如盖房子的大致流程固定，但是盖不同的房子每个子流程的实现各不相同，还可能经常变化。\n模式定义 将一个复杂对象的构建与其表示相分离，使得同样的构建过 程(稳定)可以创建不同的表示(变化)\n结构图解 代码实现  Builder构建器模式 c++ //产品基类 定义房子除了构建本身的其它接口 class House{ //\u0026hellip;. }; //产品构建器基类 负责定义相关共有子接口 不实现 class HouseBuilder { public: House* GetResult(){ return pHouse; } virtual ~HouseBuilder(){} protected: House* pHouse; virtual void BuildPart1()=0; virtual void BuildPart2()=0; virtual void BuildPart3()=0; virtual void BuildPart4()=0; virtual void BuildPart5()=0; }; //石头房子 继承房子，实现除了构建工作外的的其它方法 class StoneHouse: public House{ }; //石头房子构建器 实现构建房子对象需要的几个共有的抽象接口，届时会组合这些接口生成石头房子 class StoneHouseBuilder: public HouseBuilder{ protected: virtual void BuildPart1(){ //pHouse-\u0026gt;Part1 = \u0026hellip;; } virtual void BuildPart2(){\n} virtual void BuildPart3(){ } virtual void BuildPart4(){ } virtual void BuildPart5(){ } }; //监工 含有产品builder基类指针 传入不同产品的builder子类，就会构建出来不同的产品 //当然这里也要定义实现共用的构建算法(不同房子的建造流程是一直的 都要先打地基 然后\u0026hellip;.) //如果项目发展后期需要建造一个更新奇的房子 不需要先打地基，而是先筑地梁 那就搞一个新的监工实现不同的构建算法 class HouseDirector{ public: HouseBuilder* pHouseBuilder;//基类builder指针 HouseDirector(HouseBuilder* pHouseBuilder){ this-\u0026gt;pHouseBuilder=pHouseBuilder; } //统一的构建方法 House* Construct(){ pHouseBuilder-\u0026gt;BuildPart1(); for (int i = 0; i \u0026lt; 4; i++){ pHouseBuilder-\u0026gt;BuildPart2(); } bool flag=pHouseBuilder-\u0026gt;BuildPart3(); if(flag){ pHouseBuilder-\u0026gt;BuildPart4(); } pHouseBuilder-\u0026gt;BuildPart5(); return pHouseBuilder-\u0026gt;GetResult(); } }; \n要点总结  builder 模式主要用于“分步骤构建一个复杂的对象”。在这其中 “分步骤”是一个稳定的算法，而复杂对象的各个部分则经常变化 变化点在哪里，封装哪里—— Builder模式主要在于应对“复杂对 象各个部分”的频繁需求变动。其缺点在于难以应对“分步骤构建 算法”的需求变动 builder模式跟模版方法有点类似，但builder模式往往只是为了解决构建对象困难而产生的，而且builder模式有一个监工，模版方法的监工其实是父类。  单例模式singleton\u0026mdash;性能问题 动机 实际开发项目中中就是需要一些这样的类，保证它们在系统中只有一个实例 ，才能保证逻辑正确性，或者大部分时候也是为了提高性能，因为频繁的产生多个实例，会带来性能下降，内存消耗等等\n代码实现  饿汉 进入main函数前就初始化 不管用不用\nclass Singleton { private: Singleton() {cout \u0026lt;\u0026lt; \u0026quot;Singleton construct\\n\u0026quot;;} Singleton(const Singleton\u0026amp; s) = delete; // 禁用拷贝构造函数 Singleton\u0026amp; operator=(const Singleton\u0026amp; s) = delete; // 禁用拷贝赋值操作符 static Singleton m_singleton; public: static Singleton* getInstance(){ return \u0026amp;m_singleton; } }; //这种模式绝对是ok的，只是有些人会说有一定的内存浪费，因为即使后面不使用也会生成相应对象 //类的静态变量在类外部初始化 而且是存放在静态存储区 进入main函数之前就已经执行了 Singleton Singleton::m_singleton; int main(){ Singleton *a=Singleton::getInstance(); Singleton *b=Singleton::getInstance(); Singleton *c=Singleton::getInstance(); Singleton *d=Singleton::getInstance(); }  \n 多线程不安全版本 不推荐\nclass Singleton { public: static Singleton* getInstance(){ //如果线程1 执行到下面一行(还没有new出来) cpu让给线程2，线程2也到这行 最后2个线程都会new出来 if ( m_singleton==nullptr){ //线程不安全 可能会出现new出多个的情况 return new Singleton(); } return m_singleton; } private: Singleton() {cout \u0026lt;\u0026lt; \u0026quot;Singleton construct\\n\u0026quot;;} Singleton(const Singleton\u0026amp; s) = delete; // 禁用拷贝构造函数 Singleton\u0026amp; operator=(const Singleton\u0026amp; s) = delete; // 禁用拷贝赋值操作符 static Singleton *m_singleton; }; //类的静态变量在类外部初始化 而且是存放在静态存储区 进入main函数之前就已经执行了 Singleton* Singleton::m_singleton=nullptr; }  \n 多线程安全版本 初始化后还要每次加锁 性能有问题 不推荐\nclass Singleton { public: static Singleton* getInstance(){ m_lock.lock(); //还没有初始化的这个地方是要加锁的 但是如果已经new出来了 多个线程每次调用都要加锁就会影响性能 if ( m_singleton==nullptr){ m_singleton= new Singleton(); } m_lock.unlock(); return m_singleton; } private: Singleton() {cout \u0026lt;\u0026lt; \u0026quot;Singleton construct\\n\u0026quot;;} Singleton(const Singleton\u0026amp; s) = delete; // 禁用拷贝构造函数 Singleton\u0026amp; operator=(const Singleton\u0026amp; s) = delete; // 禁用拷贝赋值操作符 static Singleton *m_singleton; static mutex m_lock; }; //类的静态变量在类外部初始化 而且是存放在静态存储区 进入main函数之前就已经执行了 Singleton* Singleton::m_singleton=nullptr; mutex Singleton::m_lock;  \n 多线程安全版本 双检查为空并加锁 因为内存读写reorder问题 不推荐\nclass Singleton { public: static Singleton* getInstance(){ if ( m_singleton==nullptr){//如果已经初始化 则直接返回即可 m_lock.lock(); //还没有初始化的这个地方是要加锁的 //再次检查是否new过了 下面判空逻辑不能去掉 去掉了还是会new出多个实例 因为如果2个线程同时进入上面的盼空后 就会出现 if ( m_singleton==nullptr){ m_singleton= new Singleton(); // 对象的new不是原子操作 1、分配内存，2 调用构造，3 赋值操作，到第3步的时候才是m_singleton非空 //1、分配内存，2 赋值操作 3 调用构造，到第2步的时候才是m_singleton非空 //如果顺序是先2在3 2做完后 另外一个线程就判断非空 直接使用但还没有调用构造函数这个时候就会让另外线程出错 } m_lock.unlock(); } return m_singleton; } private: Singleton() {cout \u0026lt;\u0026lt; \u0026quot;Singleton construct\\n\u0026quot;;} Singleton(const Singleton\u0026amp; s) = delete; // 禁用拷贝构造函数 Singleton\u0026amp; operator=(const Singleton\u0026amp; s) = delete; // 禁用拷贝赋值操作符 static Singleton *m_singleton; static mutex m_lock; }; //类的静态变量在类外部初始化 而且是存放在静态存储区 进入main函数之前就已经执行了 Singleton* Singleton::m_singleton=nullptr; mutex Singleton::m_lock;  \n 多线程安全版本 双检查为空并加锁 利用atomic库消除内存读写reorder问题 相对实现复杂 可以使用\nclass Singleton { public: static Singleton* getInstance(){ Singleton* tmp = m_singleton.load(std::memory_order_relaxed); std::atomic_thread_fence(std::memory_order_acquire);//获取内存fence if ( tmp==nullptr){//如果已经初始化 则直接返回即可 std::lock_guard\u0026lt;std::mutex\u0026gt; lock(m_lock);; //还没有初始化的这个地方是要加锁的 if ( tmp==nullptr){//再次检查是否new过了 这行不能去掉 去掉了还是会new出多个实例 因为如果2个线程同时进入67行代码 就会出现 tmp = new Singleton(); // 1、分配内存，2 调用构造，3 赋值操作 这里不会再出现内存读写reorder问题 std::atomic_thread_fence(std::memory_order_release);//释放内存fence m_singleton.store(tmp, std::memory_order_relaxed); } } return tmp; } private: Singleton() {cout \u0026lt;\u0026lt; \u0026quot;Singleton construct\\n\u0026quot;;} Singleton(const Singleton\u0026amp; s) = delete; // 禁用拷贝构造函数 Singleton\u0026amp; operator=(const Singleton\u0026amp; s) = delete; // 禁用拷贝赋值操作符 static std::atomic\u0026lt;Singleton*\u0026gt; m_singleton; static mutex m_lock; }; //类的静态变量在类外部初始化 而且是存放在静态存储区 进入main函数之前就已经执行了 std::atomic\u0026lt;Singleton*\u0026gt; Singleton::m_singleton; mutex Singleton::m_lock;  \n 通过返回局部静态变量方式实现 线程安全 写法简单 推荐使用\nclass Singleton { public: static Singleton* getInstance(){ static Singleton instance; //这种相对于使用atomic的写法更简洁 而且又是懒汉模式 使用的时候才生成 推荐使用 //局部静态变量初始化是会加锁的 也就是线程安全的,而且是c++和编译器保证的 推荐使用 return \u0026amp;instance; } private: Singleton() {cout \u0026lt;\u0026lt; \u0026quot;Singleton construct\\n\u0026quot;;} Singleton(const Singleton\u0026amp; s) = delete; // 禁用拷贝构造函数 Singleton\u0026amp; operator=(const Singleton\u0026amp; s) = delete; // 禁用拷贝赋值操作符 static Singleton* m_singleton; }; //类的静态变量在类外部初始化 而且是存放在静态存储区 进入main函数之前就已经执行了 Singleton* Singleton::m_singleton=nullptr;  \n享元模式FlyWeight\u0026mdash;性能问题 动机 如果一切皆对象，有些对象在系统中大量存在(万、十万、百万、千万等)，这个时候就会带来大量的运行时开销，大部分情况下可能是内存浪费。比如设计围棋游戏，每一个黑旗、白棋都搞成对象，成千上万的人在玩，那就是十万甚至百万个对象，比如设计字体处理软件，每个有大量的字符，每个字符又有大量的字体，每个字符每个字体都生成1个对象，最终占用内存将是非常夸张的，而大部分时候是不需要，因为这些对象都是只读的，完全可以用池的概念来共享，如果已经创建过了，则直接使用 不再创建，否则就创建并且加到共享池中。\n模式定义 通过共享技术有效支持大量细粒度的对象。\n代码  享元模式FlyWeight\nclass Font { private: //unique object key string key; //object state //.... public: Font(const string\u0026amp; key){ //... } }; //对象生成工厂 用map实现共享池 class FontFactory{ private: map\u0026lt;string,Font* \u0026gt; fontPool; public: Font* GetFont(const string\u0026amp; key){ map\u0026lt;string,Font*\u0026gt;::iterator item=fontPool.find(key); if(item!=footPool.end()){ return fontPool[key]; } else{ Font* font = new Font(key); fontPool[key]= font; return font; } } void clear(){ //... } };  \n要点总结 享元模式主要是解决大量对象带来的内存消耗问题，如果评估不可能发生，也没有必要使用。\n门面模式 facade\u0026mdash;接口隔离 需求背景与动机 项目中用到了多种数据库，比如mysql、oracle、DB2、Timesten等等，如果多个程序直接与这些数据库打交道，每个程序都会非常复杂，二期如果数据库升级，数据库接口变动，相关的程序都需要改动，这个时候就需要一个数据访问层(提供固定的数据访问接口)，给外部提供统一的访问接口，将各个数据库的处理细节屏蔽，即使数据库升级改动，只修改接口实现，外部程序不用改动。\n模式定义 为系统中的一组接口提供一个一致稳定的界面，facade模式定义一个高层接口，使得系统外部使用者更加易用，稳定，不用频繁变化。\n要点总结  facade模式没有固定的代码模式，更多的是一种架构思维 facade模式内部必须是高相关的组件，不能什么都放  代理模式Proxy\u0026mdash;接口隔离 需求背景和动机 由于一些实际的现实原因，不能直接使用某个对象(比如使用之前要做一些安全控制，或者说直接创建某个对象的开销太大，又或者根本无法直接创建[访问一些分布式机器上的资源])，所以直接访问会给使用者或者系统架构的设计代码麻烦，所以就需要一种代理，就像现实世界的代理一样，不用管一些细节，只要它们提供相应的服务即可(软件层面可能就是提供一些可用的接口)。\n代理的操作往往跟直接操作对象一致，可以理解增加了一个间接层也就是代理，来实现控制这些对象。\n模式定义 为其它对象提供一种代理以控制(隔离，使用接口)对这个对象的访问。\n我的理解就是增加一个间接层 不让直接使用，这个有很多好处，跟门面模式一样，可以隔离很多变化。\n结构图解 代码  传统实现\nclass ISubject{ public: virtual void process(); }; class RealSubject: public ISubject{ public: virtual void process(){ //.... } }; //客户端直接使用某个对象 如果现实中不能让直接使用 比如要增加安全控制 //合法的client才能使用就要考虑改造了 而且不能对每个client都改造 所以最后实现起可能比较复杂混乱 class ClientApp{ ISubject* subject; public: ClientApp(){ subject=new RealSubject(); } void DoTask(){ //... subject-\u0026gt;process(); //.... } };  \n 代理模式简易代码c++\nclass ISubject{ public: virtual void process(); }; class RealSubject: public ISubject{ public: virtual void process(){ //.... } }; //Proxy的设计 继承ISubject实现 一致性的接口 class SubjectProxy: public ISubject{ public: virtual void process(){ //对RealSubject的一种间接访问 比如调用前做安全控制 统计下调用次数，使用rpc访问别的机器等等 //.... } }; //客户端使用代理跟直接使用RealSubject没有太大区别 class ClientApp{ ISubject* subject; public: ClientApp(){ subject=new SubjectProxy(); } void DoTask(){ //... subject-\u0026gt;process(); //.... } };  \n要点总结  “增加一个中间层”是软件系统对许多复杂问题的一种常见解决方案，如果直接使用某个对象会带来很多麻烦，就尝试使用代理模式 具体proxy设计模式的实现方法，千差万别。  适配器模式Adapter\u0026mdash;接口隔离 需求背景、动机 ​ 现实项目中由于应用环境的变化，常常需要将“一些现存的对象”放在新环境使用，但是新环境要求的接口又是一些老对象所不能直接满足的，这个时候就会想到适配器模式，简单来说就是定义一个适配器类继承新接口的基类，但是用对象组合的方式拥有老对象的基类或者子类，用老对象的某些方法实现新的接口。\n​ 现实生活中也有很多适配器，比如电源的适配器，HTMI转VGA等等，说白了就是把一个老的接口转成新的接口。\n模式定义 将一个类的接口转换成客户希望的另外一个新接口。Adapter模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。\n结构图解 要点总结  Adapter模式主要应用于“希望复用一些现存的类”，但接口又与复用环境要求的不一致，在遗留代码复用，类库迁移等方面非常有用。 GoF23定义的适配器有2种，对象适配器(上图的这种)和类适配器(直接多继承老对象)，类适配器不推荐使用，因为使用了多继承，一般都是被摒弃的。对象组合的方式更符合松耦合精神 其实实际项目中完全也不用拘泥于书中定义的结构，即使把老对象作为新对象新接口的参数也是一样的。  代码  Adapter适配器模式 c++\n//目标接口（新接口） class ITarget{ public: virtual void process()=0; }; //遗留接口（老接口） class IAdaptee{ public: virtual void foo(int data)=0; virtual int bar()=0; }; //遗留类型 class OldClass: public IAdaptee{ //.... }; //对象适配器 class Adapter: public ITarget{ //继承新接口基类 protected: IAdaptee* pAdaptee;//组合方式拥有老对象 这样就可以通过加工老对象的方法实现新接口 public: Adapter(IAdaptee* pAdaptee){ this-\u0026gt;pAdaptee=pAdaptee; } virtual void process(){ int data=pAdaptee-\u0026gt;bar(); pAdaptee-\u0026gt;foo(data); } }; //类适配器 class Adapter: public ITarget, protected OldClass{ //多继承 不推荐使用 }; int main(){ IAdaptee* pAdaptee=new OldClass(); ITarget* pTarget=new Adapter(pAdaptee); pTarget-\u0026gt;process(); } //stl的栈和队列 大致也是通过对象组合的方式实现的 也可以理解为Adapter模式 class stack{ deqeue container; }; class queue{ deqeue container; };  \n中介者Mediator\u0026mdash;接口隔离 需求背景和动机  如果现实项目中出现了多个对象互相关联交互的情况，它们彼此之间徐奥维持一种复杂的引用关系，A变了 BC也要变，C变了D也要变，D变了可能A又要跟着做相应变化，这个时候如果遇到需求变更，改动起来将会非常麻烦，而且容易出错。\n 这个时候就可以考虑引入一个中介者，让它们彼此的引用拆开，变成都给中介者打交道，A变了如果要改变B或者C，就通知中介者，然后中介去通知BC做改变，当然要建立良好的通知机制和协议。\n 如果中介者最后非常庞大或者复杂，也要考虑继续拆分中介者\n  模式定义 用中介对象来封装(变化)一些列的对象交互，让原先各个对象不需要显示相互引用(编译时依赖\u0026mdash;\u0026gt;运行时依赖)，从而使其耦合松散，便于管理变化，而且可以独立的改变它们之间的交互。\n结构图解 要点总结  将多个对象复杂的关联关系解耦，Mediator模式将多个对象间的控制逻辑进行统一管理，将“多个对象互相关联”变成了\u0026rdquo;多个对象都和中介者关联“，简化了系统的维护，抵御了可能的变化。 如果Mediator变得太多复杂也要对其拆分处理 facade模式是解耦系统间(单向)的对象关联关系，但Mediator模式是解耦系统内各个对象之间的(双向)关联关系。  状态模式State\u0026mdash;状态变化 需求背景、动机  在软件构建过程中，某些对象的状态如果改变，其行为也会随之发生变化，比如文档处于只读状态，则支持行为和读写状态的行为可能就完全不同了\n 如何在运行时根据对象的状态来透明的更改对象的行为？而且不会为对象操作和状态转化之间引入耦合？\n  例子 假设有一个网络状态处理类，大致有3种操作，但是对于每种操作，不同的状态有不同的处理，而且处理后要切换到对应的状态\n 传统解决方案 c++\n//枚举值 定义网络的多种状态 未来可能会新增状态的处理 enum NetworkState { Network_Open, Network_Close, Network_Connect, }; //网络处理类 class NetworkProcessor{ NetworkState state; public: //针对操作1 不同的状态会发生不同的行为，同时操作后状态要切换 这里面后续可能还要增加状态 一来修改可能引入bug，二来修改起来往往比较困难，因为太多ifelse了容易晕 void Operation1(){ if (state == Network_Open){ //********** state = Network_Close; } else if (state == Network_Close){ //.......... state = Network_Connect; } else if (state == Network_Connect){ //$$$$$$$$$$ state = Network_Open; } } //针对操作2 不同的状态会发生不同的行为，同时操作后状态要切换 public void Operation2(){ if (state == Network_Open){ //********** state = Network_Connect; } else if (state == Network_Close){ //..... state = Network_Open; } else if (state == Network_Connect){ //$$$$$$$$$$ state = Network_Close; } } //针对操作3 不同的状态会发生不同的行为，同时操作后状态要切换 public void Operation3(){ //。。。。。 } };  \n模式定义  允许一个对象在其内部状态改变的时候改变它的行为，从而使对象看起来似乎修改了其行为。  结构图解 要点总结  State模式核心是将所有与一个特定状态相关的行为都放入一个State的子类对象中，在对象状态切换的时候，其实是切换了不同的子类对象指向，但同时维持State的接口(都继承同一个基类)，这样就实现了具体的操作和状态转换之间的解耦。 为不同的状态引入不同的对象使得状态转换变得更加明确，而且可以保证不会出现状态不一致的情况，因为转换是源自行的，要么彻底转换过来，要么不转换。 如果State对象没有实例变量，可以用singetone模式共享同一个对象，从而节省对象开销  代码  采用状态模式优化c++\n//状态基类，将不同的状态改为不同的类(对象)，实现同样的接口 class NetworkState{ public: NetworkState* pNext; virtual void Operation1()=0; virtual void Operation2()=0; virtual void Operation3()=0; virtual ~NetworkState(){} }; //打开状态类 要实现不同的操作对应应该怎么处理 同时操作后应该切换到什么状态 class OpenState :public NetworkState{ static NetworkState* m_instance; public: static NetworkState* getInstance(){ if (m_instance == nullptr) { m_instance = new OpenState(); } return m_instance; } //这里将只关注打开状态在Operation1时如何处理，不容易混淆，同时切换状态其实是切换子类指针指向，是有原子性的 void Operation1(){ //********** pNext = CloseState::getInstance(); } void Operation2(){ //.......... pNext = ConnectState::getInstance(); } void Operation3(){ //$$$$$$$$$$ pNext = OpenState::getInstance(); } }; //关闭状态类 要实现不同的操作对应应该怎么处理 同时操作后应该切换到什么状态 class CloseState:public NetworkState{ }; //.. class NetworkProcessor{ NetworkState* pState; public: //状态类初始化后 针对不同的状态 操作接口是类似的，那就是执行想要的操作，切换到下一个状态， //代码保持稳定，即使新增状态，如果接口不改变 NetworkProcessor类代码无需改变 NetworkProcessor(NetworkState* pState){ this-\u0026gt;pState = pState; } void Operation1(){ //... pState-\u0026gt;Operation1(); pState = pState-\u0026gt;pNext; //... } void Operation2(){ //... pState-\u0026gt;Operation2(); pState = pState-\u0026gt;pNext; //... } void Operation3(){ //... pState-\u0026gt;Operation3(); pState = pState-\u0026gt;pNext; //... } };  \n备忘录Memento\u0026mdash;-状态变化 需求背景、动机  现实软件系统有时候需要保存某个对象的状态，相当于给当下的对象来个快照保存起来，以便未来某个时间恢复这个状态做相应的处理，又不能破坏对象的封装性，不能暴漏公共接口给外部。 最开始的时候就想到了备忘录模式，所谓备忘录简单理解就是深拷贝一个对象，保存起来，未来某个时间再拿这个备忘录重建对象，实现某些特定的功能。  模式定义  不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。这样以后就可以将该对象恢复到原先保存的状态，以实现特定的功能。  结构图解 要点总结  备忘录Memento需要存储原发器Originator对象的内部状态，以备需要时恢复原发器Originator的状态 Memento的核心是信息隐藏 因为设计模式是94年提出了，现在这个模式有点过时，因为很多高级语言都提供了序列化、反序列化的技术，但是思想是一样的。  代码  Memento备忘录模式c++\n//备忘录类 class Memento { string state; //.. 这里为了保存内部的状态 可能实现比较复杂 仅为示意代码 public: Memento(const string \u0026amp; s) : state(s) {} string getState() const { return state; } void setState(const string \u0026amp; s) { state = s; } }; //原发器类 class Originator { string state; //.... public: Originator() {} //创建备忘录 Memento createMomento() { Memento m(state); return m; } //用备忘录恢复原始状态 void setMomento(const Memento \u0026amp; m) { state = m.getState(); } }; int main() { Originator orginator; //..做相应处理 改变状态 //捕获对象状态，存储到备忘录 Memento mem = orginator.createMomento(); //... 改变orginator状态 //从备忘录中恢复 orginator.setMomento(mem); }  \n组合模式Composit\u0026mdash;数据结构 需求背景和动机  如何客户代码过多的依赖对象容器复杂的内部实现的数据结构，对象容器内部的实现结构(不是抽象接口)如果发生变化，那么客户代码也会频繁变化，就带来了代码的维护性，扩展性等弊端 所以需要将客户代码与复杂的对象容器结构解耦，让客户不管是处理什么样的结构都调用统一的接口简单处理，不会因为对象内部数据结构的变化而发生变化 假设有一个需求需要处理单个叶子节点，也要复杂节点(list集合 装有多个节点)  模式定义 ​ 将对象祖辈成属性结构以表示“部分-整体”的层次结构，Composite是的用户对单个对象还是组合对象的使用具有一致性(稳定)。\n 其实就是单个对象 组合对象都继承同一个基类，实现同一个公共接口，这样用多态实现，客户端的调用就是一致的，不用频繁改变。  结构图解 代码  Composite组合模式c++\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;algorithm\u0026gt; using namespace std; //组件基类 定义公用接口 这些接口往往是直接暴漏给客户的 class Component { public: virtual void process() = 0; virtual ~Component(){} }; //支持复杂结构的处理 继承组件基类 实现process公共外部接口 class Composite : public Component{ string name; list\u0026lt;Component*\u0026gt; elements; public: Composite(const string \u0026amp; s) : name(s) {} //因为内部是一个list集合，所以需要add remove方法 add的可以是简单节点 也可以还是一个list void add(Component* element) { elements.push_back(element); } void remove(Component* element){ elements.remove(element); } //实现公共外部接口 void process(){ //1. process current node //2. process leaf nodes 循环对list内部的每个节点都处理 for (auto \u0026amp;e : elements) e-\u0026gt;process(); //多态调用 } }; //叶子节点 简单节点 也实现process公共接口 class Leaf : public Component{ string name; public: Leaf(string s) : name(s) {} //实现公共process接口 void process(){ //process current node } }; // 客户端的调用 void Invoke(Component \u0026amp; c){ //... c.process();//这里客户端不用关心组件到底是简单节点还是集合复杂节点 用多态实现了统一的处理 //如果这里不用多态，客户就要区分到底是简单节点还是list集合，针对list集合要做想要的循环遍历处理，把对象的更多细节暴漏给客户 //同时如果list数据结构发生了变化 比如改为了set实现，那么客户端的代码也要跟着改变 这是非常糟糕的。 } int main() { Composite root(\u0026quot;root\u0026quot;); Composite treeNode1(\u0026quot;treeNode1\u0026quot;); Composite treeNode2(\u0026quot;treeNode2\u0026quot;); Composite treeNode3(\u0026quot;treeNode3\u0026quot;); Composite treeNode4(\u0026quot;treeNode4\u0026quot;); Leaf leat1(\u0026quot;left1\u0026quot;); Leaf leat2(\u0026quot;left2\u0026quot;); root.add(\u0026amp;treeNode1); treeNode1.add(\u0026amp;treeNode2); treeNode2.add(\u0026amp;leaf1); root.add(\u0026amp;treeNode3); treeNode3.add(\u0026amp;treeNode4); treeNode4.add(\u0026amp;leaf2); //客户端不论是处理复杂节点还是叶子节点 代码保持一直稳定 不用理会组件对象内部数据结构容器实现的变化 Invoke(root); Invoke(leaf2); Invoke(treeNode3); }  \n要点总结  Composite模式采用树形结构实现部片存在的对象容器，从而将一对多 变为“一对一”，其实也就是原先对多个对象，现在变为对一个基类，让原先的多个对象都继承同一个基类((拥有同样的公共接口))，这样客户就不用关心某个复杂对象内部的数据结构实现，也不会因为其数据结构的变动而导致客户端代码修改。 Composite模式在具体实现中，可以让负对象中的子对象反向追溯，如果负对象有频繁的遍历需求，可以使用缓存来改善效率  迭代器模式Iterator\u0026mdash;数据结构 需求背景和动机  软件构建过程中，集合对象内部结构常常变化各异，但对于这些集合对象，我们不希望暴漏其内部数据结构，而且希望提供一个一致的接口让客户访问，同时如果提供统一的接口，就有可能提供统一的算法 使用面向对象技术(也就是多态 有个迭代器基类，定义统一的几个接口，让不同的集合迭代器对象都继承这个基类，实现其方法即可)  模式定义  提供一种方法顺序访问一个聚合对象中的各个元素，而不暴漏(稳定)该对象内部的表示(实现细节 比如某些数据结构)  结构图解 代码  多态实现迭代器c++\n//迭代器基类 定义公共操作接口 对客户暴漏 template\u0026lt;typename T\u0026gt; class Iterator { public: virtual void first() = 0; virtual void next() = 0; virtual bool isDone() const = 0; virtual T\u0026amp; current() = 0; }; //生成某一个类型的迭代器 template\u0026lt;typename T\u0026gt; class MyCollection{ public: Iterator\u0026lt;T\u0026gt; GetIterator(){ //... } }; //具体的迭代其子类实现 继承迭代器基类 实现公共接口 template\u0026lt;typename T\u0026gt; class CollectionIterator : public Iterator\u0026lt;T\u0026gt;{ MyCollection\u0026lt;T\u0026gt; mc; public: CollectionIterator(const MyCollection\u0026lt;T\u0026gt; \u0026amp; c): mc(c){ } void first() override { } void next() override { } bool isDone() const override{ } T\u0026amp; current() override{ } }; //调用 void MyAlgorithm() { MyCollection\u0026lt;int\u0026gt; mc;//某一个集合 Iterator\u0026lt;int\u0026gt; iter= mc.GetIterator();//针对某一个集合创建迭代器对象 for (iter.first(); !iter.isDone(); iter.next()){//遍历 cout \u0026lt;\u0026lt; iter.current() \u0026lt;\u0026lt; endl; } //这里每次调用都是多态 就要找到虚函数指针 如果量太大， //这个效率就会有问题 所以c++ STL的迭代器都是用模版实现了 也就是编译时多态，而不是运行时多态 }  \n要点总结  因为虚函数在性能上的消耗，现代c++ STL库的迭代器都是用模版实现的，也就是编译时多态，而不是运行时多态 但思想时一致的 迭代多态为遍历不同的集合结构提供了一个统一的接口，从而支持同样的算法在不同和集合结构上操作 使用迭代器一定要考虑健壮性，遍历的同时如果更改了所在的集合结构，很可能出问题，因为内存已经发生变化，大部分迭代器是只读的。  职责链ChainOfResponsibility\u0026mdash;数据结构 需求背景、动机  如果你的项目中一个请求可能会被多个对象处理，但是每个请求在运行时只能有一个接收者，如果显示指定，将必不可少的带来情趣发送者与接受者的紧耦合 如何让请求的发送者不需要指定具体的接受者？  模式定义  定义一个请求处理基类，定义公共处理接口，同时有一个基类指针next 运行时可以指向具体的请求处理子类，这样就可以形成一个链条，第一个不处理扔给下一个，对每个具体的处理子类都有这样的处理逻辑，这样做就达到了不必指定具体的处理者。 沿着对象的一条链 传递请求，直到一个对象处理它为止，就想数据结构的链表一样。  结构图解 代码  ChainOfResponsibility职责链模式 c++\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; //请求枚举类型 enum class RequestType { REQ_HANDLER1, REQ_HANDLER2, REQ_HANDLER3 }; //请求对象定义 class Reqest { string description; RequestType reqType; public: Reqest(const string \u0026amp; desc, RequestType type) : description(desc), reqType(type) {} RequestType getReqType() const { return reqType; } const string\u0026amp; getDescription() const { return description; } }; //职责链基类 定义接口 有个指向自己的指针(运行时灵活指派下一个处理责任主体) class ChainHandler{ ChainHandler *nextChain; //将请求发送个链条上下一个处理责任主体 void sendReqestToNextHandler(const Reqest \u0026amp; req) { if (nextChain != nullptr) nextChain-\u0026gt;handle(req); } protected: virtual bool canHandleRequest(const Reqest \u0026amp; req) = 0; virtual void processRequest(const Reqest \u0026amp; req) = 0; public: ChainHandler() { nextChain = nullptr; } void setNextChain(ChainHandler *next) { nextChain = next; } //公共处理接口 void handle(const Reqest \u0026amp; req) { if (canHandleRequest(req))//如果自己能处理 则直接处理请求 processRequest(req); else sendReqestToNextHandler(req);//否则传递给下一个处理责任主体 } }; //实际处理主体1 继承职责链处理基类 class Handler1 : public ChainHandler{ protected: bool canHandleRequest(const Reqest \u0026amp; req) override { return req.getReqType() == RequestType::REQ_HANDLER1; } void processRequest(const Reqest \u0026amp; req) override { cout \u0026lt;\u0026lt; \u0026quot;Handler1 is handle reqest: \u0026quot; \u0026lt;\u0026lt; req.getDescription() \u0026lt;\u0026lt; endl; } }; //实际处理主体2 继承职责链处理基类 class Handler2 : public ChainHandler{ protected: bool canHandleRequest(const Reqest \u0026amp; req) override { return req.getReqType() == RequestType::REQ_HANDLER2; } void processRequest(const Reqest \u0026amp; req) override { cout \u0026lt;\u0026lt; \u0026quot;Handler2 is handle reqest: \u0026quot; \u0026lt;\u0026lt; req.getDescription() \u0026lt;\u0026lt; endl; } }; //实际处理主体3 继承职责链处理基类 class Handler3 : public ChainHandler{ protected: bool canHandleRequest(const Reqest \u0026amp; req) override { return req.getReqType() == RequestType::REQ_HANDLER3; } void processRequest(const Reqest \u0026amp; req) override { cout \u0026lt;\u0026lt; \u0026quot;Handler3 is handle reqest: \u0026quot; \u0026lt;\u0026lt; req.getDescription() \u0026lt;\u0026lt; endl; } }; //调用示意 int main(){ Handler1 h1; Handler2 h2; Handler3 h3; h1.setNextChain(\u0026amp;h2); h2.setNextChain(\u0026amp;h3); Reqest req(\u0026quot;process task ... \u0026quot;, RequestType::REQ_HANDLER3);//这里看着简单 运行着这个对象可能表复杂 或者比较多，都直接显示指定耦合太多 h1.handle(req);//调用的时候不用指定具体的责任主体 return 0; }  \n要点总结  职责链模式的应用，让对象职责分派更具有灵活性 如果最后一个请求处理主体也不能处理，应该有一个告警或者缺省的处理机制。这也是每一个接受请求对象的责任，而不是发送请求对象的责任 当然责任链模式很容易直接用数据结构实现了，所以也是这个模式不怎么流行的原因 比较简答 但思想可以借鉴  命令模式Command\u0026mdash;行为变化 需求背景、动机  软件构建过程中，“行为请求者”和“行为实现者”通常呈现一种紧耦合(对象和成员函数)，但在某些场合，比如要对行为进行“记录、撤销、重做(undo/redo)、事务”等处理，这种紧耦合无法抵御变化。 怎么样才能将“行为请求者”与“行为实现者”解耦？  模式定义  将一个请求(行为、或者直接说成员函数)封装成一个对象，从而使你可用不同的请求对客户进行参数化，请请求排队或者记录日志、撤销等等。  结构图解 代码  Command命令模式c++\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; //命令基类定义接口方法 class Command { public: virtual void execute() = 0; }; //命令1实现 class ConcreteCommand1 : public Command { string arg; public: ConcreteCommand1(const string \u0026amp; a) : arg(a) {} void execute() override { cout\u0026lt;\u0026lt; \u0026quot;#1 process...\u0026quot;\u0026lt;\u0026lt;arg\u0026lt;\u0026lt;endl; } }; //命令2实现 class ConcreteCommand2 : public Command { string arg; public: ConcreteCommand2(const string \u0026amp; a) : arg(a) {} void execute() override { cout\u0026lt;\u0026lt; \u0026quot;#2 process...\u0026quot;\u0026lt;\u0026lt;arg\u0026lt;\u0026lt;endl; } }; //组合命令实现 class MacroCommand : public Command { vector\u0026lt;Command*\u0026gt; commands; public: void addCommand(Command *c) { commands.push_back(c); } void execute() override { for (auto \u0026amp;c : commands) { c-\u0026gt;execute(); } } }; int main() { //执行某些命令操作就变成了 构造某些对象 然后执行其相应方法 ConcreteCommand1 command1(receiver, \u0026quot;Arg ###\u0026quot;); ConcreteCommand2 command2(receiver, \u0026quot;Arg $$$\u0026quot;); MacroCommand macro; macro.addCommand(\u0026amp;command1); macro.addCommand(\u0026amp;command2); macro.execute(); }  \n要点总结  Command模式目的是将“行为请求者”和”行为实现者“解耦，在面向对象语言中，常见的手段是\u0026rdquo;\u0026ldquo;将行为抽象为对象\u0026rdquo; 这个模式跟c++的函数对象又些类似，相比Command模式接口更规范，但函数对象使用更加灵活，现代工程函数对象用的更多 所谓函数对象就是一个class对象重载了()运算符，所以对象名称加上()就相当于调用了一个函数  访问器模式Visitor\u0026mdash;-行为变化 需求背景、动机  由于需求的改变、某些类层次结构常常需要增加新的行文(对象成员方法)，如果考虑基类子类的实现方式，需要在基类、子类都添加对应的方法，如果直接在基类修改，将会给子类带来繁重的负担，甚至破坏原设计 如何在不改变类层次结构的前提下，在运行时透明地为类层次结构的各个类动态的添加新的行为操作？  模式定义  表示一个作用于某个对象结构中的各元素的操作，使得可以在不改变(稳定)个元素的类的前提下定义(扩展)作用于这些元素的新操作(行为) 采用二次分发的方式实现 但前提是基类的子类非常确定 不会经常变化，是子类的行为经常变化。  结构图解 代码  传统解决方案\n#include \u0026lt;iostream\u0026gt; using namespace std; //业务基类 刚开始有2个方法 class Element { public: virtual void Func1() = 0; virtual void Func2(int data)=0; virtual void Func3(int data)=0;//随着项目发展 要不停的增加方法 那么就需要修改基类然后修改每一个子类 //... virtual ~Element(){} }; class ElementA : public Element { public: void Func1() override{ //... } void Func2(int data) override{ //... } //这里添加Func3 }; class ElementB : public Element { public: void Func1() override{ //*** } void Func2(int data) override { //*** } //这里添加Func3 Func4.... };  \n Visitor访问器模式\n#include \u0026lt;iostream\u0026gt; using namespace std; //先声明 class Visitor; //业务基类 class Element { public: virtual void accept(Visitor\u0026amp; visitor) = 0; //第一次多态辨析 virtual ~Element(){} }; //业务子类A class ElementA : public Element { public: void accept(Visitor \u0026amp;visitor) override { visitor.visitElementA(*this); } }; //业务子类B class ElementB : public Element { public: void accept(Visitor \u0026amp;visitor) override { visitor.visitElementB(*this); //第二次多态辨析 } }; //访问器基类 定义好访问每个子业务类的接口 后面有各个访问器实现(为每个子类增加成员方法) class Visitor{ public: virtual void visitElementA(ElementA\u0026amp; element) = 0; virtual void visitElementB(ElementB\u0026amp; element) = 0; virtual ~Visitor(){} }; //==========================上述如果只有2个子类 随便添加方法 以上稳定============================== //扩展1 为子类增加一个成员方法 class Visitor1 : public Visitor{ public: void visitElementA(ElementA\u0026amp; element) override{ cout \u0026lt;\u0026lt; \u0026quot;Visitor1 is processing ElementA\u0026quot; \u0026lt;\u0026lt; endl; } void visitElementB(ElementB\u0026amp; element) override{ cout \u0026lt;\u0026lt; \u0026quot;Visitor1 is processing ElementB\u0026quot; \u0026lt;\u0026lt; endl; } }; //扩展2 为子类增加再一个成员方法 class Visitor2 : public Visitor{ public: void visitElementA(ElementA\u0026amp; element) override{ cout \u0026lt;\u0026lt; \u0026quot;Visitor2 is processing ElementA\u0026quot; \u0026lt;\u0026lt; endl; } void visitElementB(ElementB\u0026amp; element) override{ cout \u0026lt;\u0026lt; \u0026quot;Visitor2 is processing ElementB\u0026quot; \u0026lt;\u0026lt; endl; } }; //扩展3 为子类增加再一个成员方法 class Visitor3 : public Visitor{}; int main() { Visitor2 visitor; ElementB elementB; elementB.accept(visitor);// double dispatch 目的实现调用elementB对应Visitor2定义的成员方法 ElementA elementA; elementA.accept(visitor);// double dispatch 目的实现调用elementA对应Visitor2定义的成员方法 return 0; }  \n要点总结  通过双重分发机制(double dispatch)来实现在不更新业务类(Element)类层次结构的前提下，运行时透明的为各个业务类增加方法 最大缺点 业务类的子类数量要确定 这就导致在现实世界很难用到 只能用于哪些子类个数不频繁变化，但是每个子类行为频繁变化的情况  解析器模式Interpreter\u0026mdash;领域规则 需求背景、动机  如果在某一特定领域的问题比较复杂，类似的结构又不断重复出现，如果使用普遍的变成方式实现将面临非常频繁的变化 如果能够将这个特定领域的问题表达为某种语法规则，然后构建一个解析器解释这样的情况，从而解决问题 比如要实现一个加减法的表达式问题 a+b-c+d  模式定义  给定一个语言，定义的文法表示，并实现一个解释器来解决  结构图解 代码  Interpreter解析器模式c++\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;map\u0026gt; #include \u0026lt;stack\u0026gt; using namespace std; //表达式基类 class Expression { public: //主要接口 解析表达式 virtual int interpreter(map\u0026lt;char, int\u0026gt; var)=0; virtual ~Expression(){} }; //变量表达式 class VarExpression: public Expression { char key; public: VarExpression(const char\u0026amp; key) { this-\u0026gt;key = key; } //变量表达式的解析就直接返回其内存值即可 int interpreter(map\u0026lt;char, int\u0026gt; var) override { return var[key]; } }; //符号表达式基类 class SymbolExpression : public Expression { // 运算符左右两个参数 抽象语法就是有左右2个表达式 protected: Expression* left; Expression* right; public: SymbolExpression( Expression* left, Expression* right): left(left),right(right){ } }; //加法运算表达式实现 class AddExpression : public SymbolExpression { public: AddExpression(Expression* left, Expression* right): SymbolExpression(left,right){ } //解析规则就是左右两个表达式的解析值相加 这中间会涉及多态递归调用 int interpreter(map\u0026lt;char, int\u0026gt; var) override { return left-\u0026gt;interpreter(var) + right-\u0026gt;interpreter(var); } }; //减法运算 class SubExpression : public SymbolExpression { public: SubExpression(Expression* left, Expression* right): SymbolExpression(left,right){ } //解析规则就是左右两个表达式的解析值相减 这中间会涉及多态递归调用 int interpreter(map\u0026lt;char, int\u0026gt; var) override { return left-\u0026gt;interpreter(var) - right-\u0026gt;interpreter(var); } }; //定义解析器 Expression* analyse(string expStr) { stack\u0026lt;Expression*\u0026gt; expStack; Expression* left = nullptr; Expression* right = nullptr; for(int i=0; i\u0026lt;expStr.size(); i++) { switch(expStr[i]) { case '+': // 加法运算 left = expStack.top(); right = new VarExpression(expStr[++i]); expStack.push(new AddExpression(left, right)); break; case '-': // 减法运算 left = expStack.top(); right = new VarExpression(expStr[++i]); expStack.push(new SubExpression(left, right)); break; default: // 变量表达式 expStack.push(new VarExpression(expStr[i])); } } Expression* expression = expStack.top(); return expression; } void release(Expression* expression){ //释放表达式树的节点内存... } int main(int argc, const char * argv[]) { string expStr = \u0026quot;a+b-c+d-e\u0026quot;; map\u0026lt;char, int\u0026gt; var; var.insert(make_pair('a',5)); var.insert(make_pair('b',2)); var.insert(make_pair('c',1)); var.insert(make_pair('d',6)); var.insert(make_pair('e',10)); Expression* expression= analyse(expStr);//将字符串解析成对象 int result=expression-\u0026gt;interpreter(var);//多态调用解析最终值 解决问题 cout\u0026lt;\u0026lt;result\u0026lt;\u0026lt;endl; release(expression); return 0; }  \n要点总结  现实项目中用到的不多 只能解决语法相对简单的问题 否则多态虚函数调用过多会产生很多性能问题  23种设计模式总结 目标不能忘记 管理变化，提高复用 两者主要的手段 分解和抽象 深刻立刻8大原则和重构的5种技巧 设计模式最终可能的对象模型 时刻要注意关注变化点和稳定点 哪些场景不太适合用模式  代码可读性很差的时候 不建议直接使用 要首先保证代码有良好的可读性 这个是前提条件 需求理解的不深刻时 此时不能深刻理解哪些是稳定点和变化点 变化没有显现的时候 也是无法深刻理解变化点的 根本就不是系统的关键依赖点 可以不用花大的精力来折腾设计模式 项目本身没有任何复用价值 没有复用价值也就不用考虑设计模式了 项目即将发布的时候 就不要在折腾设计模式了 别再整出一大堆bug  一些经验之谈  不要为了模式而模式 要重视抽象类和接口 理清楚变化点和稳定点非常重要 经常审视类之间的依赖关系非常重要 Framework和Application的区隔思维要有 良好的设计都是慢慢演化的结果 不能一蹴而就  成长之路  “手中无剑，心中无剑”： 见到模式不认识 “手中有剑，心中无剑”: 可以识别不同的模式 作为应用开发人员可以使用 \u0026ldquo;手中有剑，心中有剑\u0026rdquo;： 可以作为框架开发人员应用设计模式 让别人用你开发的产品框架 “手中无剑，心中有剑”： 已经忘记了死板的设计模式，深刻理解原则，甚至能够创造模式  ","id":7,"section":"posts","summary":"设计模式介绍 设计模式最关键的作用是为了可复用，减少开发工作量。 模式就是针对现实世界重复出现的问题，给出核心解决方案，忽略掉一些不重要的细节。","tags":["设计模式"],"title":"设计模式","uri":"http://heketong.github.io/2020/05/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","year":"2020"}],"tags":[{"title":"marathons","uri":"http://heketong.github.io/tags/marathons/"},{"title":"TCP/IP","uri":"http://heketong.github.io/tags/tcp/ip/"},{"title":"分布式","uri":"http://heketong.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"title":"排序","uri":"http://heketong.github.io/tags/%E6%8E%92%E5%BA%8F/"},{"title":"搭建博客","uri":"http://heketong.github.io/tags/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"},{"title":"数据结构","uri":"http://heketong.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"title":"算法","uri":"http://heketong.github.io/tags/%E7%AE%97%E6%B3%95/"},{"title":"网络高并发","uri":"http://heketong.github.io/tags/%E7%BD%91%E7%BB%9C%E9%AB%98%E5%B9%B6%E5%8F%91/"},{"title":"设计模式","uri":"http://heketong.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]}